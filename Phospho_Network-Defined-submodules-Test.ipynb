{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational phospho-proteomic network inference pipeline\n",
    "####  by Matt Macgilvary\n",
    "\n",
    "###### This pipeline turns a list of S. cerevesiae phospho-peptides that exhibit stress responsive abundance changes, as measured by mass spectrometry, into a hierarchical signaling network, connecting upstream kinases and phosphatases to their downstream targets. Our computational pipeline is based on the premise that kinases and phosphatases recognize target substrates through specific amino acid sequences at the phosphorylated residue, called phosphorylation motifs. This pipeline groups phospho-peptides with similar abundance changes and the same phosphorylation motif into modules. Modules are partitioned into smaller groups, called submodules, based on differences in phospho- peptide abundance in mutant strain(s) (sources). Candidate submodule regulators, called shared interactors, are identified through enrichment analysis using a protein interaction network in yeast (Chasman et al., 2014). Shared interactor-submodule pairs serve as inputs for a previously developed Integer Programming (IP) approach that connects the sources to their downstream target submodules (Chasman et al., 2014).\n",
    "\n",
    "###### Please see our bioRxiv preprint for additional information:\n",
    "    Network inference reveals novel connections in pathways regulating growth and defense in the yeast salt response.   Matthew E. MacGilvray+, Evgenia Shishkova+, Deborah Chasman, Michael Place, Anthony Gitter, Joshua J. Coon, Audrey P. Gasch. bioRxiv 2017. doi:10.1101/176230\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "### The user should define differentially changing phospho-peptides in the \"WT\" or \"Parent\" strain using their own criteria (eg; fold-change, p-value, etc.), followed by grouping/clustering phospho-peptides based on similar directionality of abundance change.\n",
    "\n",
    "# __This pipeline is for the user who has already run Motifx and defined the modules manually.__\n",
    "\n",
    "\n",
    "# If you wish to run Motifx here and then manually define your modules execute the Motifx.py cell just below.\n",
    "\n",
    "# Identify motifs by Calling Motifx.py\n",
    "    \n",
    "    This automates submitting jobs to the Motif-x Website (http://motif-x.med.harvard.edu/)\n",
    "\n",
    "### Expected Input  : A single Plain text file (called inputfiles in the next cell) listing excel files to process, one excel file name per line.\n",
    "\n",
    "    text file:\n",
    "    data_sheet1.xlsx\n",
    "    data_sheet2.xlsx\n",
    "\n",
    "\tThe Excel file format:\n",
    "\tPpep\tGroup\tLocalized_Sequence\tMotif_X_Input_Peptide\n",
    "\tYGL076C_T8_S11\tInduced\tAAEKILtPEsQLKK\tAAEKILT*PES*QLKK\n",
    "\n",
    "\tColumn order is unimportant, column names must match above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'Motifx.py' -f 'inputfiles' -u 'reference/orf_trans_all.20150113.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required python libraries\n",
    "import Bio\n",
    "import glob\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from scipy.stats import hypergeom\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio import motifs\n",
    "from Bio.Alphabet import IUPAC\n",
    "\n",
    "current_dir = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Identify_Modules_and_Submodules step.\n",
    "\n",
    "### This step can be skipped if the user has already defined submodules\n",
    "\n",
    "This script identifies co-regulated groups of phospho-peptides using the following approach:\n",
    "\n",
    "1) First, the script identifies 'modules', which are groups of phospho-peptides that exhibit the same directionality in stress-dependent abundance change (ie, increased 'Induced', or decreased 'Repressed') and the same motif. The module nomenclature is as follows: Induced/Repressed- motif (ex: Induced..RK.s....).\n",
    "\n",
    "2) Next, the script partitions modules into 'submodules' based on their phospho-peptide constituents dependency on a protein(s) for stress-dependent abundance changes (ie, phospho-peptides that exhibit increased 'amplified' or decreased 'defective' abundance in a deletion strain compared to the 'WT' or 'Parental' type strain). These phenotypes are user defined. If two or more mutant phenotypes are recorded for a phospho-peptide then it's placed into two separate subModules (one for each mutant phenotype). If there was not a mutant phenotype at a user defined threshold then the phenotype is 'No-Phenotype'\n",
    "\n",
    "The submodule nomenclature is as follows: module name-mutant phenotype/No-Phenotype (ex: Induced..RK.s....Mutant_Defective).\n",
    "\n",
    "Possible submodule phenotypes: Induced-Defective, Induced-Amplified, Repressed-Defective, Repressed-Amplified, Induced-No-Phenotype, Repressed-No-Phenotype\n",
    "\n",
    "idModules.csv file looks like:\n",
    "\n",
    "> Ppep,Cluster,Motif,Peptide,ire1,mkk1_2<br>\n",
    "> YGR240C_S895,Induced,......SP.....,NKKNEASPNTDAK,Induced_Amplified,Induced_Defective<br>\n",
    "> YMR005W_S80,Induced,...K..SP.....,VLPKNVSPTTNLR,Induced_Amplified,Induced_Defective<br>\n",
    "> YPL242C_S7,Induced,......SP.....,MTAYSGSPSKPGN,Induced_Amplified, <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "Data=pd.read_csv('idModules.csv') # Define path to input file\n",
    "\n",
    "def Slicedataframe():\n",
    "    '''Define a function that slices the input dataframe into independent dataframes based on the Cluster names. Next, slice these dataframes based on the presence of the same motif, generating 'modules' '''  \n",
    "    ClusterLST=Data['Cluster'].unique().tolist()                            # generate a list of unique Cluster names (ie, 'Induced' and 'Repressed')\n",
    "    lst=[]                                                                 \n",
    "    DF=Data.copy()                                                         \n",
    "    for cluster in ClusterLST:                                              # Select the first 'cluster' on the list \n",
    "        DF2=DF.loc[DF['Cluster']== cluster]                                 # Create a new dataframe by selecting only those rows that contain the selected 'cluster' in the 'Cluster' column \n",
    "        MotifLST=DF2['Motif'].unique().tolist()                             # From the newly created dataframe, place each instance of a unique motif into a list\n",
    "        cleanedMotifLST = [x for x in MotifLST if str(x) != 'nan']          # drop the string 'nan' from the list. 'nan' occurs for Ppeps that did not have an identified Motif from Motif-X. \n",
    "        for motif in cleanedMotifLST:                                       # Select a motif in the list\n",
    "            DF3=DF2.loc[DF['Motif']== motif]                                # Filter the dataframe, selecting only those rows that contain 'motif' in the Motif column\n",
    "            DF3['freq'] = DF3.groupby('Motif')['Motif'].transform('count')  # Produce a new column, called 'freq' that contains the number of rows, and thus phospho-peptides, that contain a given motif.\n",
    "            lst.append(DF3) \n",
    "        \n",
    "    return lst\n",
    "\n",
    "SlicedDF_lst=Slicedataframe()\n",
    "\n",
    "def ConcatenateDFs():\n",
    "    ''' Define a function that appends the dataframes in the SlicedDF_list together. '''\n",
    "    EmptyDF = pd.DataFrame()                                                # create an empty dataframe\n",
    "    for df in SlicedDF_lst:                                                \n",
    "        df=df.copy() \n",
    "        EmptyDF=EmptyDF.append(df)                                          # append to the empty DF the dataframe selected and overwrite the empty dataframe\n",
    "    return EmptyDF\n",
    "\n",
    "Final_DF=ConcatenateDFs()\n",
    "FinalDFV2=Final_DF.fillna(0)                                                #  fill any NaN values with '0'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "def Module_Motif_NoMutantPhenotypeExists(df):\n",
    "    ''' Define a function that assigns no-phenotype submodules'''\n",
    "    if(df['ire1'] ==0) & (df['mkk1_2']==0):\n",
    "        return 'No_Phenotype_Exists'\n",
    "    \n",
    "FinalDFV2['Phenotype']=FinalDFV2.apply(Module_Motif_NoMutantPhenotypeExists, axis=1) \n",
    "FinalDFV2=FinalDFV2.loc[FinalDFV2['Phenotype']=='No_Phenotype_Exists']        # Select all rows for which \"No_Phenotype_Exists\" in the 'Phenotype' column.\n",
    "FinalDFV2['subModule']=FinalDFV2.Cluster.map(str) + \"_\" + FinalDFV2.Motif + \"_\" + FinalDFV2.Phenotype                                   # create a new column, called submodule, that contains the concatenated strings in the 'Cluster', 'Motif', and 'Phenotype' columns.\n",
    "\n",
    "# CHANGE GENE NAMES HERE\n",
    "FinalDF=Final_DF.dropna(subset = ['ire1', 'mkk1_2'], how='all')        # Remove rows that have NaN in all 3 columns representing mutant phenotpes. This steps removes theNo-phenotype submodules which were creat                                                                               # ed above. \n",
    "FinalDF=FinalDF.fillna(0)                                                     # fill any NaN that remain with '0'\n",
    "lstCols=['ire1', 'mkk1_2']                                             # make a list that contains the column headers for the 3 mutants. \n",
    "\n",
    "\n",
    "\n",
    "def DefineMutantContribution(row):\n",
    "    ''' Define a function that identifies for each phospho-peptide if it has a phenotype in more than one mutant strain'''\n",
    "    dictData={} \n",
    "    for colname in lstCols:    \n",
    "        if not row[colname]==0:                                                # if value is not equal to zero, there is a mutant phenotype (ex; Induced_defective)\n",
    "            dictData[colname]=row[colname]  \n",
    "    if len(dictData.keys())==0: return 0  \n",
    "    else:\n",
    "        return \":\".join(dictData.keys())\n",
    "    \n",
    "FinalDF['Contribution']=FinalDF.apply(lambda x: DefineMutantContribution(x), axis=1) \n",
    "\n",
    "\n",
    "\n",
    "def DefinePhenotypeFromMutants(row):\n",
    "    ''' Define a function that captures the mutant phenotype for Ppeps with multiple phenotypes and places it within a column'''\n",
    "    dictData={}  \n",
    "    for colname in lstCols:   \n",
    "        if not row[colname]==0:\n",
    "            dictData[colname]=row[colname] \n",
    "    if len(dictData.keys())==0: return 0 \n",
    "    else:\n",
    "        return \":\".join(dictData.values()) \n",
    "    \n",
    "FinalDF['Phenotype']=FinalDF.apply(lambda x: DefinePhenotypeFromMutants(x), axis=1)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "''' Determine all Ppeps that have 2 or more mutant phenotypes (ire1/mkk1_2 phenotypes), then the script produces a new column with individual subModule names for \n",
    "the ire1 phenotype''' \n",
    "\n",
    "FinalDF_multiplePhenotypes=FinalDF[FinalDF['Contribution'].str.contains(\":\")]     # Select 'contribution column rows that contain \":\", which means the Ppep has two mutant phenotypes since this is a separator between gene names\n",
    "FinalDF_multiplePhenotypes_ire1=FinalDF_multiplePhenotypes[FinalDF_multiplePhenotypes['Contribution'].str.contains(\"ire1\")] \n",
    "FinalDF_multiplePhenotypes_ire1['Ire1']='ire1' \n",
    "FinalDF_multiplePhenotypes_ire1['subModule']=FinalDF_multiplePhenotypes_ire1.Cluster.map(str) + \"_\" + FinalDF_multiplePhenotypes_ire1.Motif + \"_\" + FinalDF_multiplePhenotypes_ire1.Ire1 + \"_\" + FinalDF_multiplePhenotypes_ire1.ire1\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "''' Define all Ppeps that have 2 or more mutant phenotypes (ire1/mkk1_2 phenotypes), then the script produces a new column with individual subModule names for \n",
    "the mkk1_2 phenotype''' \n",
    "FinalDF_multiplePhenotypes_mkk1_2=FinalDF_multiplePhenotypes[FinalDF_multiplePhenotypes['Contribution'].str.contains(\"mkk1_2\")]\n",
    "FinalDF_multiplePhenotypes_mkk1_2['Mkk1_2']='mkk1_2'\n",
    "FinalDF_multiplePhenotypes_mkk1_2['subModule']=FinalDF_multiplePhenotypes_mkk1_2.Cluster.map(str) + \"_\" + FinalDF_multiplePhenotypes_mkk1_2.Motif + \"_\" + FinalDF_multiplePhenotypes_mkk1_2.Mkk1_2 + \"_\" + FinalDF_multiplePhenotypes_mkk1_2.mkk1_2\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "''' Define all Ppeps that have 2 or more mutant phenotypes (ire1/mkk1_2 phenotypes), then the script produces a new column with individual subModule names for \n",
    "the cdc14 phenotype'''\n",
    "\n",
    "#FinalDF_multiplePhenotypes_cdc14=FinalDF_multiplePhenotypes[FinalDF_multiplePhenotypes['Contribution'].str.contains(\"cdc14\")]\n",
    "#FinalDF_multiplePhenotypes_cdc14['Cdc14']='cdc14'\n",
    "#FinalDF_multiplePhenotypes_cdc14['subModule']=FinalDF_multiplePhenotypes_cdc14.Cluster.map(str) + \"_\" + FinalDF_multiplePhenotypes_cdc14.Motif + \"_\" + FinalDF_multiplePhenotypes_cdc14.Cdc14 + \"_\" + FinalDF_multiplePhenotypes_cdc14.cdc14\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "'''This section of code appends the above mutant dataframes together (ie, FinalDF_multiplePhenotypes_cdc14, etc.) (contained \":\"). The result is Ppeps with phenotypes in more than one strain are listed on multiple lines rather than a single line'''\n",
    "\n",
    "FinalDF_mutants=FinalDF_multiplePhenotypes_ire1.append(FinalDF_multiplePhenotypes_ire1) \n",
    "FinalDF_mutants_Final=FinalDF_mutants.append(FinalDF_multiplePhenotypes_mkk1_2)\n",
    "\n",
    "# if you have more than 2 gene names add them here after Peptide\n",
    "FinalDF_mutants_Final=FinalDF_mutants_Final[['Ppep','Cluster','Motif','Peptide','ire1','mkk1_2','freq','Contribution','Phenotype','subModule']] # Only retain these columns \n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Drop from the original dataframe rows containing Ppeps with multiple mutant phenotypes. \n",
    "FinalDF_minus_multiPhenotypePpeps=FinalDF[FinalDF.Contribution.str.contains(\":\")==False] # Removing all rows that contain \":\", and thus are phospho-peptides with multiple mutant phenotypes\n",
    "\n",
    "\n",
    "# Generate the final submodule names\n",
    "FinalDF_minus_multiPhenotypePpeps['subModule']=FinalDF_minus_multiPhenotypePpeps.Cluster.map(str) + \"_\" + FinalDF_minus_multiPhenotypePpeps.Motif + \"_\" + FinalDF_minus_multiPhenotypePpeps.Contribution + \"_\" + FinalDF_minus_multiPhenotypePpeps.Phenotype\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Ppeps_with_PhenotypesDF=FinalDF_minus_multiPhenotypePpeps.append(FinalDF_mutants_Final)  # Appending together the dataframes that originally had single mutant phenotypes, and the dataframe that started with multiple mutant Phentoypes, but now contains single listings for each Ppep-mutant phenotype\n",
    "\n",
    "\n",
    "\n",
    "# Remove any submodule that only has a single Ppep constituent, since by default a submodule must contain 2 Ppeps. \n",
    "Ppeps_with_PhenotypesDF_subModules=Ppeps_with_PhenotypesDF[Ppeps_with_PhenotypesDF.duplicated(['subModule'], keep='last') | Ppeps_with_PhenotypesDF.duplicated(['subModule'])]  # only retain duplicates, get rid of single entries \n",
    "\n",
    "\n",
    "\n",
    "# Append to the dataframe with phenotype subModules, all No-Phenotype submodules\n",
    "Ppeps_with_Phenotypes_subModules_and_noPhenotypes_DF=Ppeps_with_PhenotypesDF_subModules.append(FinalDFV2) # append to dataframe\n",
    "Ppeps_with_Phenotypes_subModules_and_noPhenotypes_DF=Ppeps_with_Phenotypes_subModules_and_noPhenotypes_DF[['Ppep', 'Cluster', 'Motif', 'Peptide', 'ire1', 'mkk1_2', 'freq', 'Contribution', 'Phenotype', 'subModule']]\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "''' Create a column with the 'Module' name '''\n",
    "Ppeps_with_Phenotypes_subModules_and_noPhenotypes_DF['Module']=Ppeps_with_Phenotypes_subModules_and_noPhenotypes_DF.Cluster.map(str) + \"_\" + Ppeps_with_Phenotypes_subModules_and_noPhenotypes_DF.Motif \n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# define a function that will write out a dataframe as a tab separated file\n",
    "def Dataframe_to_Tsv (dataframe, NewFileName):\n",
    "    dataframe.to_csv (NewFileName,sep='\\t')\n",
    "\n",
    "Dataframe_to_Tsv(Ppeps_with_Phenotypes_subModules_and_noPhenotypes_DF, 'Modules_pPep.csv') \n",
    "# The above file contains all modules and subModules with and without mutant phenotypes. \n",
    "\n",
    "# OUTPUT: Modules_pPep.csv\n",
    "#   for the case of 2 genes ire1, mkk1_2, header looks like\n",
    "#   Ppep    Cluster Motif   Peptide ire1    mkk1_2  freq    Contribution    Phenotype       subModule       Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for Identify Shared Interactors \n",
    "\n",
    "## ONLY USE FOR CASES IN WHICH THERE IS MANUAL CURATION OF SUBMODULES\n",
    "\n",
    "   Kevin has motifx files where he is working w/ Strains.  He has already grouped his submodules.\n",
    "   His files look like: \n",
    "    \n",
    "    YJL082W_S(187),KNSSSPSPSEKSQ,Group_1,......SP.....\n",
    "    YPL112C_S(304),KDDGSQSPIRKQL,Group_1,......SP.....\n",
    "    YJL128C_S(83),DKGSSQSPKHIQQ,Group_1,......SP.....\n",
    "    YNL118C_S(750),VSSNQQSPKSQHL,Group_1,......SP.....\n",
    "    YAL035W_S(395),PTPSSASPNKKDL,Group_1,......SP.....\n",
    "\n",
    "input file : \n",
    "Submodule,ORF\n",
    "Induced_......TP....._cdc14_Repressed_Amplified,YLR319C\n",
    "Induced_......TP....._cdc14_Repressed_Amplified,YJL070C\n",
    "\n",
    "#### NOTE: ORF names have need to have the '-' removed,  YER074W-A becomes YER074A.\n",
    "\n",
    "The other input files are provided.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##  CHANGE INPUT FILE HERE   ##\n",
    "inputFile = 'Modules_pPep.csv'\n",
    "\n",
    "# create the input file based on the output of the previous step.\n",
    "with open('Submodule_constituents.csv', 'w') as out:\n",
    "    out.write('Submodule,ORF\\n')\n",
    "    with open(inputFile,'r') as f:\n",
    "        f.readline()                            # skip header\n",
    "        for line in f:\n",
    "            data = line.rstrip().split('\\t')    # CHECK THE FILE DELIMITER \n",
    "            name = data[1].split('_')[0]   \n",
    "            name = re.sub('-', '', name)\n",
    "            row  = data[10] + ',' + name + '\\n'\n",
    "            out.write(row)\n",
    "out.close()\n",
    "# OUTPUT: Submodule_constituents.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Shared Interactors \n",
    "\n",
    "This script identifies proteins enriched for interactions with Submodule constituent proteins, based on known interactions in the background network. We call these proteins 'Shared Interactors'. The background network is a protein\n",
    "interaction network curated in yeast under mostly nutrient replete conditions that contains 4638 proteins and ~ 25,000 interactions, including directed (ex; kinase-substrate), and \n",
    "non-directed. \n",
    "\n",
    "Proteins enriched for interactions with Submodule proteins at a 5% FDR, determined by a hypergeometric test and BH correction, are considered shared interactors.\n",
    "\n",
    "Shared Interactors represent numerous functional classes, including kinases and phosphatases. Kinase and phosphatase shared interactors represent potential Submodule regulators.\n",
    " \n",
    "HyperG function:\n",
    "distrib=hypergeom(N,M,n)\n",
    "distrib.pmf(m)\n",
    "\n",
    "* N - population size (4638 unique proteins in Background network file - phospho_v4_bgnet_siflike_withdirections_Matt_Modified.csv)\n",
    "\n",
    "* M - total number of successes  (# of interactions for a given protein. ie. Protein A has 200 known interactions in the background network).\n",
    "\n",
    "* n - the number of trials (also called sample size) -  ie. (Number of proteins that reside within a submdoule)\n",
    "\n",
    "* m - the number of successes - for example: Protein A, a shared interactor, has 35 interactions with proteins in Submodule B. \n",
    " \n",
    " \n",
    " Final shared interactor file:   __Final_enriched.csv__  , this contains the significant Shared Interactors based on the\n",
    " BH_significance test.\n",
    " \n",
    " A list of all shared interactors can be found:  __Network_Submodule_Nodes_background_Network.csv__\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Submodule_DF   = pd.read_csv(current_dir + '/Submodule_constituents.csv')                                                                       # File that contains Submodule names and their protein constituents\n",
    "BgNet          = pd.read_csv(current_dir + '/SI_Identification_Input_Files/Background_Network.csv')                                                                                   # Background network of protein interactions\n",
    "Num_Prot_Inter = pd.read_csv(current_dir + '/SI_Identification_Input_Files/Number_Interactions_Each_Protein.csv')                                              # Number of protein interactions for each protein in the background network\n",
    "Annotation_DF  = pd.read_csv(current_dir + '/SI_Identification_Input_Files/Annotation.csv')                                                   # Yeast protein annotation file\n",
    " \n",
    "Submodule_List=Submodule_DF['Submodule'].unique().tolist()                                                                                                  # Send the Submodules to a list, but filter out duplicates, which there will be many, since the Submodules will have been found in many proteins.\n",
    "\n",
    "dicOrfs={}\n",
    "for Submodule in Submodule_List:                                                                                                                            # Key (Submodule), Value (Yeast ORFs that are Submodule constituents). Filter ORFs found twice to single occurence (important for enrichment analysis)\n",
    "    dicOrfs[Submodule]=(Submodule_DF.loc[Submodule_DF['Submodule'] == Submodule])['ORF'].unique().tolist()\n",
    "        \n",
    "\n",
    "dicOrfsCounts={}  \n",
    "for k,v in dicOrfs.items():  \n",
    "    if k not in dicOrfsCounts:  \n",
    "        value=len(v)            \n",
    "        dicOrfsCounts[k]=value\n",
    "        \n",
    "df_Submodule_Size=pd.DataFrame(list(dicOrfsCounts.items()),                                                                                                  # convert dict to dataframe.\n",
    "                      columns=['Submodule','n'])\n",
    "\n",
    "def SliceDataframe():\n",
    "    ''' For each Submodule identify all proteins that interact with the Submodule proteins in the backgroudn network '''\n",
    "    lst = []\n",
    "    for key in dicOrfs.keys():                                                                                                                             #Select the key, which is a Submodule, from the dict\n",
    "        CurrentDF=BgNet.copy() \n",
    "        x=CurrentDF[CurrentDF['Protein1'].isin(dicOrfs[key])].rename(columns={'Protein1':'Submodule_Containing_Proteins', 'Protein2':'Possible_Shared_Interactors'})                              #Create a new dataframe that is a slice of the salt background network, and only contains proteins that were passed in \"dicOrfs[key]\". At the same time, rename the columns                                \n",
    "        x['Submodule']=key \n",
    "        lst.append(x)\n",
    "        \n",
    "    return lst\n",
    "\n",
    "Sliced_dataframe_list= SliceDataframe()\n",
    "      \n",
    "def Add_n():    \n",
    "    ''' Function adds 'n', the number of proteins in the Submodule, to each dataframe'''\n",
    "    lst= []\n",
    "    for df in Sliced_dataframe_list:\n",
    "        NewDF=df.merge(df_Submodule_Size)\n",
    "        lst.append(NewDF)\n",
    "        \n",
    "    return lst\n",
    "\n",
    "Sliced_dataframe_list= Add_n()\n",
    "\n",
    "def Identify_Shared_Interactors():\n",
    "    ''' Function identifies proteins that interact with at least 2 protein constituents of each submodule'''\n",
    "    \n",
    "    lst=[] \n",
    "    for df in Sliced_dataframe_list: \n",
    "        NewDF=df.copy()\n",
    "        NewDF2=NewDF[NewDF.duplicated(['Possible_Shared_Interactors'], keep = 'last')| NewDF.duplicated(['Possible_Shared_Interactors'])]                  # Only retain proteins that interact with at least 2 submodule protein constituents\n",
    "        x=NewDF2.sort_values(by='Possible_Shared_Interactors', ascending=True) \n",
    "        lst.append(x)\n",
    "       \n",
    "    return lst\n",
    "\n",
    "Shared_Interactors_lst=Identify_Shared_Interactors()\n",
    "\n",
    "def AppendDFs_that_Contain_AllSharedInteractors_and_their_targets():\n",
    "    ''' Function appends all submodules and their shared interactors together into a single file'''\n",
    "    EmptyDF = pd.DataFrame() \n",
    "    for df in Shared_Interactors_lst:  \n",
    "        df=df.copy() \n",
    "        EmptyDF=EmptyDF.append(df)\n",
    "    return EmptyDF\n",
    "\n",
    "SI_andTargets=AppendDFs_that_Contain_AllSharedInteractors_and_their_targets()\n",
    "\n",
    "SI_andTargets_FINAL=pd.merge(left=SI_andTargets, right=Annotation_DF, how='left',\n",
    "                              left_on='Possible_Shared_Interactors', right_on='systematic_name_dash_removed')                                               # complete a merge so I can get the dashes back in the names, which are not included in the background network\n",
    "del SI_andTargets_FINAL['Possible_Shared_Interactors']                                                                                                      # drop because  lacks the dashes which are needed for the correct naming convention\n",
    "del SI_andTargets_FINAL['systematic_name_dash_removed']                                                                                                     # drop because carried over from the merge\n",
    "del SI_andTargets_FINAL['Directed']\n",
    "\n",
    "SI_andTargets_FINAL.columns = ['Submodule_Containing_Proteins', 'Interaction', 'Submodule', 'n','Possible_Shared_Interactors']                        # rename columns\n",
    "\n",
    "myDF = pd.DataFrame(SI_andTargets_FINAL)\n",
    "# OUTPUT NAME FOR SHARED INTERACTORS\n",
    "filename = 'SI_Identification_SubmoduleS__SIs_and_Targets_FDR.csv'\n",
    "myDF.to_csv(filename, index=False, encoding='utf-8' )              # All interactions between SIs and their submodule constituent proteins. No enrichment at this step.\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "''' Preparing dataframe for Hypergeometric test'''\n",
    "\n",
    "def Add_N_and_m():\n",
    "    ''' Function adds 'N' and calculates 'm' values, which are inputs for the hypergeometric test, to the datframe'''\n",
    "    lst=[]\n",
    "    for df in Shared_Interactors_lst:\n",
    "        NewDF=df.copy()\n",
    "        NewDF['N'] = 4638          # THIS IS THE LENGTH OF THE DATA FRAME, *******************************                                                                                                                         # of proteins in the background network\n",
    "        NewDF['m'] = NewDF.groupby('Possible_Shared_Interactors')['Possible_Shared_Interactors'].transform('count')\n",
    "        lst.append(NewDF)\n",
    "    \n",
    "    return lst\n",
    "\n",
    "Dataframes_list_with_n_N_m=Add_N_and_m()\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def Drop_dups():\n",
    "    ''' For each dataframe, which contains a single submodule, it's protein constituents, and shared interactors, drop duplicate entries for identified SI proteins\n",
    "    . This leaves a single entry for each shared interactor protein. '''\n",
    "    lst=[]\n",
    "    for df in Dataframes_list_with_n_N_m:\n",
    "        NewDF=df.copy()\n",
    "        Final_DF=NewDF.drop_duplicates('Possible_Shared_Interactors')\n",
    "        Final_DF=Final_DF.rename(columns={'Possible_Shared_Interactors':'Shared_Interactor'})\n",
    "        lst.append(Final_DF)\n",
    "        \n",
    "    return lst\n",
    "\n",
    "Drop_Dups_lst=Drop_dups()\n",
    "\n",
    "\n",
    "def Return_M():\n",
    "    ''' Function identifies 'M' (the total number of interactions for each Shared Interactor protein in the background network) and adds that number\n",
    "    to the dataframe'''\n",
    "    lst=[]\n",
    "    for df in Drop_Dups_lst:\n",
    "        NewDF=df.copy()\n",
    "        NewDF2=df.copy()\n",
    "        NewDF_lst=NewDF['Shared_Interactor'].tolist()                                                                                                            # place all proteins in the 'Shared_Interactor' column in a list \n",
    "        Shared_Interactors=Num_Prot_Inter[Num_Prot_Inter['Protein'].isin(NewDF_lst)].rename(columns={'Protein':'Shared_Interactor', 'Total':'M'})\n",
    "        Shared_Interactor_merge=Shared_Interactors.merge(NewDF2, on='Shared_Interactor')\n",
    "        Shared_Interactor_merge=Shared_Interactor_merge.sort_values(by='Shared_Interactor', ascending=True)\n",
    "        lst.append(Shared_Interactor_merge)\n",
    "        \n",
    "    return lst\n",
    "\n",
    "Return_M_lst=Return_M()\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "def hyper(N,M,n,m): \n",
    "    ''' Function defines the parameters for a hypergeometric test that returns a p-value representing the chances of identifying >= x, where x is the number of successes '''  \n",
    "    frozendist=hypergeom(N,M,n)\n",
    "    ms=np.arange(m, min(n+1, M+1))\n",
    "    rv=0;\n",
    "    for single_m in ms: rv=rv+frozendist.pmf(single_m)\n",
    "    return rv\n",
    "\n",
    "def run_hyper():\n",
    "    ''' Function calls the hypergeometric function above  on each shared interactor for each submodule'''\n",
    "    lst=[]\n",
    "    for df in Return_M_lst:\n",
    "        if not df.empty:\n",
    "            NewDF=df.copy()\n",
    "            NewDF['p-value'] = NewDF.apply(lambda row: hyper(row['N'], row['M'], row['n'], row['m']), axis=1)\n",
    "            lst.append(NewDF)\n",
    "        \n",
    "    return lst \n",
    "\n",
    "run_hyper_lst=run_hyper()\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def AppendDFs():\n",
    "    ''' Append DFs for each submodule and it's SIs together into a single DF'''   \n",
    "    EmptyDF = pd.DataFrame() #\n",
    "    for df in run_hyper_lst: \n",
    "        df=df.copy() \n",
    "        EmptyDF=EmptyDF.append(df)\n",
    "    return EmptyDF\n",
    "\n",
    "Final=AppendDFs()\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "''' Prepping for Benjamini Hochberg procedure. Below code is ranking p-values from 1 to n based on lowest to highest p-value score'''\n",
    "\n",
    "Final=Final.sort_values(by=['p-value'],ascending=[True])                                                                                              # Sort p-values from lowest to highest\n",
    "Final_resetIndex=Final.reset_index()                                                                                                        # Reset the index after the sort\n",
    "Final_resetIndex.index +=1                                                                                                                  # start numbering at 1 for index\n",
    "       \n",
    "NewDF=Final_resetIndex\n",
    "NewDF_Allp_values=Final_resetIndex\n",
    "NewDF=NewDF[['p-value']]                                                                                                                    # select only the p-value column of the dataframe \n",
    "NewDF_dropdups=NewDF.drop_duplicates('p-value')                                                                                             # drop duplicate p-values\n",
    "NewDF_dropdups=NewDF_dropdups.reset_index()                                                                                                 # reset the index\n",
    "NewDF_dropdups.index +=1                                                                                                                    # start numbering at 1 for index\n",
    "NewDF_dropdups['Rank(i)'] = NewDF_dropdups.index                                                                                            # #Add a rank column that will be filled with index values. \n",
    "NewDF_dropdups=NewDF_dropdups.drop('index', 1)                                                                                              # Drop the additional column 'index' that is not sorted.\n",
    "NewDF_merge=NewDF_Allp_values.merge(NewDF_dropdups, on='p-value')                                                                           # create a new dataframe that is a merge of the dataframe with all p-values, and the dataframe with unique p-values and their ranks. \n",
    "NewDF_merge=NewDF_merge.drop('index',1)                                                                                                     # drop the index that was added from the merge. This leaves all p-values ordered from lowest to highest with their ranking.\n",
    "\n",
    "'''Add parameters necessary for completing Benjamini-Hochberg procedure '''\n",
    "\n",
    "NewDF=NewDF_merge\n",
    "NewDF['m_(number_of_tests)']=(len(NewDF))                                                                                                   # Add 'm (number of tests)' column \n",
    "NewDF['Q_(FDR)']=0.05      # THIS IS THE FDR VALUE, USER CAN CHANGE **************************************                                                                                                                 # Add Q (FDR) column. This can be changed manually.\n",
    "NewDF['(i/m)Q']=((NewDF['Rank(i)']/NewDF['m_(number_of_tests)'])*NewDF['Q_(FDR)'])                                                          # add the (i/m)Q column \n",
    "NewDF['BH_significant']=NewDF.apply(lambda x: 1 if x['p-value']<x['(i/m)Q'] else 0, axis=1)                                                 # Identify which proteins are  significant. \n",
    "NewDF=pd.merge(left=NewDF, right=Annotation_DF, how='left', left_on='Shared_Interactor', right_on='systematic_name_dash_removed')           # complete a merge to recover dashed version of YORFs\n",
    "del NewDF['Shared_Interactor'] \n",
    "del NewDF['systematic_name_dash_removed']\n",
    "del NewDF['Directed']\n",
    "NewDF.columns = ['M','Submodule_Containing_Proteins', 'Interaction', 'Submodule', 'n','N','m','p-value','Rank(i)', 'm_(number_of_tests)', 'Q_(FDR)','(i/m)Q','BH_significant', 'Shared_Interactor'] # rename columns\n",
    "\n",
    "myDF = pd.DataFrame(NewDF)\n",
    "filename = 'Network_Submodule_Nodes_background_Network.csv'\n",
    "myDF.to_csv(filename, index=False, encoding='utf-8' )       # Write out final file with enriched shared interactors for each submodule\n",
    "\n",
    "\n",
    "# FILTER FOR THE FINAL Shared Interactors.\n",
    "# Open and parse Network_Submodule_Nodes_background_Network.csv \n",
    "# Only keep the identified Shared Interactors about the first zero that appears in the BH_Significant column.\n",
    "with open('Final_enriched.csv', 'w') as outfile, open('Network_Submodule_Nodes_background_Network.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('M,'):\n",
    "            outfile.write(line)\n",
    "            continue\n",
    "        dat = line.split(',')\n",
    "        if dat[12] == '0':\n",
    "            break\n",
    "        else:\n",
    "            outfile.write(line)\n",
    "\n",
    "f.close()\n",
    "outfile.close()\n",
    "\n",
    "# OUTPUT: SI_Identification_SubmoduleS__SIs_and_Targets_FDR.csv, \n",
    "#         Network_Submodule_Nodes_background_Network.csv\n",
    "#         Final_enriched.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Shared Interactors Inputs Outputs\n",
    "\n",
    "For each SI and it's connections with submodule protein constituents, determine if the SI acts upon the submodule (that is, the Shared Interactor has at least 1 directional interaction, or ppi interaction, with a submodule protein), or if the submodule acts upon the SI (that is, all interactions between the SI and submodule proteins have the 'Reverse' designation', indicating that the submodule proteins act upon the SI).\n",
    "\n",
    "- If all of the interactions are reversed, then the script will define the relationship between the SI and the submodule as \"Output\"\n",
    "\n",
    "- If there is at least one interaction that is directed from SI towards submodule, or is a ppi, the relationship between the SI and the submodule is defined as \"Input\"\n",
    "\n",
    "This script takes an input file that contains the following:\n",
    "\n",
    "- All enriched Shared Interactors (SIs) (according to HyperG) and their connections to submodules.\n",
    "- All known protein interactions for each SI (ppi, kinase-substrate, etc)\n",
    "- Many of these interactions are directed (kinase-substrate, metabolic pathway, etc). PPI are not a directed interaction.\n",
    "\n",
    "Input: plain csv text file\n",
    "\n",
    "Csv format:\n",
    "SI_submodule,Shared_Interactor,SI_name,Motif_Containing_Proteins,submodule_Name\n",
    ",Interaction_Directionality\n",
    "\n",
    "YLR164C_Repressed_..RR.s.No_Phenotype_Exists,YLR164C,Tpk1,YDR207C,\n",
    "Repressed_..RR.s.No_Phenotype_Exists, kinase_substrate\n",
    "\n",
    "Column order is unimportant, column names must match above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import yeast_Gene_name_to_ORF as yg          # useSI_Identification_SubmoduleS__SIs_and_Targets_FDR.csv'd to get standard name\n",
    "\n",
    "# create input files \n",
    "# SI_Identification_SubmoduleS__SIs_and_Targets_FDR.csv - input from ID shared interactors\n",
    "submod = dict()\n",
    "with open('SI_Identification_SubmoduleS__SIs_and_Targets_FDR.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        row = line.rstrip().split(',')\n",
    "        submod[row[0] + '_' + row[2]] = row\n",
    "\n",
    "f.close()\n",
    "\n",
    "# get network information\n",
    "with open('classify_sharedInteractors_input.csv', 'w') as out:\n",
    "    header = '%s,%s,%s,%s,%s,%s\\n' %('SI_submodule','Shared_Interactor','SI_name','Motif_Containing_Proteins','submodule_Name'\n",
    ",'Interaction_Directionality')\n",
    "    out.write(header)\n",
    "    with open('Final_enriched.csv') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('M'):\n",
    "                continue\n",
    "            row = line.rstrip().split(',')\n",
    "            if int(row[12]) != 1:\n",
    "                continue\n",
    "            name = row[1] + '_' + row[3]\n",
    "            if name in submod:\n",
    "                if row[1].endswith(('A','B')):\n",
    "                    tmp = list(row[1])\n",
    "                    tmp.insert(-1,'-')\n",
    "                    row[1] = \"\".join(tmp)\n",
    "                n = re.sub('-', '', row[1])\n",
    "                ln = name + ',' + n + ',' + yg.sc_orfToGene[row[1]] + ',' + row[-1] + ',' + row[3] + ',' + row[2] + '\\n'\n",
    "                out.write(ln)\n",
    "\n",
    "Input_df=pd.read_csv('classify_sharedInteractors_input.csv')\n",
    "\n",
    "def Split_based_on_SI_submodule_Column():\n",
    "    ''' Function splits the input DF into independent DFs based on the SI-submodule column pairs. Thus, each SI and it's submodule protein interactions are\n",
    "    in independent dataframes '''\n",
    "    DF_lst =[]\n",
    "    for SI_submodule in Input_df['SI_submodule'].unique():\n",
    "        DF=Input_df.loc[Input_df['SI_submodule']==SI_submodule]\n",
    "        DF_lst.append(DF)\n",
    "    return DF_lst\n",
    "\n",
    "DF_lst=Split_based_on_SI_submodule_Column()\n",
    "\n",
    "def Count_Instances_of_Reverse_Interaction():\n",
    "    ''' Function counts, for each DF, and thus each SI-submodule pair, how many of the interactions are 'reversed', or facing from submodule TOWARDS SI. \n",
    "        It also counts the length of the dataframe, and then subtracts the the length of the dataframe from the counts. If the resultant value is 0, then all of the interactions \n",
    "        were reversed '''\n",
    "    DF_Counts_lst=[]\n",
    "    for df in DF_lst:\n",
    "        df=df.copy()\n",
    "        df['Counts']=df.Interaction_Directionality.str.contains('Reversed').sum()                                                               # Count the number of interactions that are \"Reversed\"\n",
    "        x=len(df)\n",
    "        df['Length']=x\n",
    "        df['Counts_Length']=df['Counts']-df['Length']\n",
    "        \n",
    "        DF_Counts_lst.append(df)\n",
    "    return DF_Counts_lst\n",
    "\n",
    "DF_Counts_lst=Count_Instances_of_Reverse_Interaction()\n",
    "\n",
    "def Only_Reverse_Interactions_Move_to_Outgoing_Columns():\n",
    "    '''Function assigns 'Input' and 'Output' classifications based on the 'Counts_Length' column in the dataframe. '0' values are 'outputs', all other's are 'inputs' '''\n",
    "    df_Modified_Outgoing_lst=[]\n",
    "    for df in DF_Counts_lst:\n",
    "        for value in df['Counts_Length'].unique():\n",
    "           \n",
    "            if value == 0:\n",
    "                df['Shared_Interactor_submodule_Relationship']= 'Output'\n",
    "                df_Modified_Outgoing_lst.append(df)\n",
    "            else:\n",
    "                df['Shared_Interactor_submodule_Relationship']= 'Input'\n",
    "                df_Modified_Outgoing_lst.append(df)\n",
    "           \n",
    "    return df_Modified_Outgoing_lst\n",
    "            \n",
    "df_Modified_Outgoing_lst=Only_Reverse_Interactions_Move_to_Outgoing_Columns()\n",
    "\n",
    "\n",
    "def AppendDFs(): \n",
    "    '''Function appends all dataframes back together '''\n",
    "    EmptyDF = pd.DataFrame()\n",
    "    for df in df_Modified_Outgoing_lst: \n",
    "        df=df.copy() \n",
    "        EmptyDF=EmptyDF.append(df) \n",
    "    return EmptyDF\n",
    "\n",
    "Final=AppendDFs()    \n",
    "\n",
    "Final_Keep_Columns_Needed_For_SIF=Final[['SI_submodule', 'Shared_Interactor', 'submodule_Name', 'Shared_Interactor_submodule_Relationship']]  \n",
    "Final_Keep_Columns_Needed_For_SIF=Final_Keep_Columns_Needed_For_SIF.drop_duplicates('SI_submodule')                                                                     # Dropping duplicates entries, which are created because for each SI-submodule interaction there are numerous interactions with protein constituent. Only want a single interaction, input or output, for each SI and it's submodule. \n",
    "\n",
    "# create a new dataframe and write results to file\n",
    "myDF = pd.DataFrame(Final_Keep_Columns_Needed_For_SIF)\n",
    "filename = 'SIs_submodule_Relationships_Define_ClassA_Network.csv'\n",
    "myDF.to_csv(filename, index=False, encoding='utf-8',sep='\\t') \n",
    "    \n",
    "# OUTPUT:  classify_sharedInteractors_input.csv\n",
    "#          SIs_submodule_Relationships_Define_ClassA_Network.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Fasta file\n",
    "\n",
    "Since Kevin identified submodules manually, we use his input file:  Group_1_Motifx-results.txt \n",
    "\n",
    "This file is parsed to produce a file which looks like:\n",
    "\n",
    "    Module,Name,Sequence\n",
    "    Group_1_......SP.....,YJL082W_S187,KNSSSPSPSEKSQ\n",
    "\n",
    "All peptide sequences should be the same length (13 amino acids).\n",
    "\n",
    "Module constituents should be used here, not submodules. \n",
    "Fasta Files for each module will be created in a dir called: FastaFiles_Modules/\n",
    "\n",
    "The output Fasta format files are named with their module designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open & parse file\n",
    "with open('pwm_input.csv', 'w') as out:\n",
    "    header = 'Module,Name,Sequence\\n'\n",
    "    out.write(header)\n",
    "    with open('Modules_pPep.csv','r') as f:               # here we used Kevin's Group_#_Motifx-results.txt\n",
    "        for line in f:\n",
    "            if line.startswith('\\tPpep'):\n",
    "                continue\n",
    "            dat = line.rstrip().split('\\t')      # CHECK DELIMITER usually , or tab\n",
    "            outrow = '%s,%s,%s\\n' %(dat[10],dat[1], dat[4])\n",
    "            out.write(outrow)\n",
    "\n",
    "\n",
    "Input_df=pd.read_csv('pwm_input.csv')\n",
    "\n",
    "def Split_Into_SeparateDFs():\n",
    "    ''' Function splits the input dataframe, based on the module name, into independent dataframes for each module'''\n",
    "    df_lst=[]\n",
    "    for Module in Input_df['Module'].unique():\n",
    "        DF=Input_df.loc[Input_df['Module']==Module]\n",
    "        df_lst.append(DF)\n",
    "        \n",
    "    return df_lst\n",
    "\n",
    "df_lst=Split_Into_SeparateDFs()\n",
    "#print (df_lst)\n",
    "\n",
    "if not os.path.exists('FastaFiles_Modules'):\n",
    "    os.mkdir('FastaFiles_Modules')\n",
    "\n",
    "def CreateIndividualFastaFiles():\n",
    "    '''Function creates individual fasta files for each module nd writes them out to a user defined directory'''\n",
    "    for df in df_lst:                \n",
    "        Module_lst=df[\"Module\"].tolist()    \n",
    "        for name in Module_lst:          \n",
    "        # open a new file that contains the module name. USER can Change directory here.\n",
    "            ofile= open(\"FastaFiles_Modules/\"+name+\".fasta\", \"w\") \n",
    "        \n",
    "            df_lstName=df['Name'].tolist()             # send the module names to a list\n",
    "            df_lstSeq=df['Sequence'].tolist()          # send the peptide sequences to a list \n",
    "            \n",
    "            for i in range(len(df_lstSeq)):                    \n",
    "                \n",
    "                ofile.write(\">\" + df_lstName[i] + \"\\n\" + df_lstSeq[i] + \"\\n\")                                            # create a fasta file where the peptide name will be followed by the peptide sequence, on a new line\n",
    "           \n",
    "        df_lstName=[]                                                                                                    # empty each of the lists for the next iteration\n",
    "        df_lstSeq=[]\n",
    "        Module_lst=[]\n",
    "        ofile.close           \n",
    "        \n",
    "    return \n",
    "      \n",
    "CreateIndividualFastaFiles()\n",
    "\n",
    "# OUTPUT: pwm_input.csv\n",
    "#         FastaFiles_Modules/*.fasta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PWMs from Module Fasta\n",
    "\n",
    "Generate PWMs for each module, using the module Fasta files. Module PWMs\n",
    "can then be compared to PWMs for 63 known kinase recognition motifs (Mok et al.,\n",
    "2010).\n",
    "\n",
    "## Always run on the Module level, i.e. Induced_sp, not Induced_sp mutant phenotype\n",
    "\n",
    "Input: A directory containing files in Fasta format.\n",
    "\n",
    "Script uses BioPython to generate position weight matrices from a directory containing Fasta files for\n",
    "each modules phospho-peptides. \n",
    "\n",
    "### Note: \n",
    "Duplicate amino acid sequences should be removed from the Fasta files before running this script, if they exist, to prevent overweighting the matrix. No value can be zero in the pwm, if the script fails check.\n",
    "\n",
    "\n",
    "    \n",
    "output file should look like:\n",
    "\n",
    "    Motif,AA,0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "    Induced_...R.NS......,A:,0.044444444444444446,0.044444444444444446,0.044444444444444446, etc...\n",
    "    Induced_...R.NS......,C:,0.022222222222222223,0.022222222222222223,0.022222222222222223, etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file: FastaFiles_Modules/Induced_......SP....._ire1_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_......SP....._ire1_Induced_Amplified.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...RR.S......_mkk1_2_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_......SP....._No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...RR.S......_No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Repressed_......TP....._No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...R..S......_No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...K..SP....._mkk1_2_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...R..S......_ire1_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...K..SP....._ire1_Induced_Amplified.fasta \n",
      "processing file: FastaFiles_Modules/Induced_....R.S......_No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...R..S......_mkk1_2_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...K..TP....._mkk1_2_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...K..TP....._No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Repressed_...R..S......_ire1_Repressed_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_......SP....._mkk1_2_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Repressed_...R..S......_mkk1_2_Repressed_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Repressed_......TP....._ire1_Repressed_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...RR.S......_ire1_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...R..TP....._mkk1_2_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_......TP....._mkk1_2_Induced_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Repressed_...R..S......_No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...K..S......_No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Repressed_......TP....._mkk1_2_Repressed_Defective.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...R..TP....._No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Induced_......TP....._No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Induced_...K..SP....._No_Phenotype_Exists.fasta \n",
      "processing file: FastaFiles_Modules/Induced_......TP....._ire1_Induced_Defective.fasta \n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate sequences from each fasta file\n",
    "\n",
    "\n",
    "clean = dict()\n",
    "\n",
    "for fasta in glob.glob('FastaFiles_Modules/*'):\n",
    "    print('processing file: %s ' %(fasta))\n",
    "    for seq_record in SeqIO.parse(fasta, 'fasta'):   # create Seq objects\n",
    "        s = str(seq_record.seq)\n",
    "        if s not in clean:\n",
    "            clean[s] = seq_record                    # only keep unique sequences\n",
    "            \n",
    "    out_handle = open('tmp.fasta', 'w')              \n",
    "    \n",
    "    for k,v in clean.items():                        # write unique sequences to tmp file  \n",
    "        SeqIO.write(v, out_handle, 'fasta')\n",
    "    out_handle.close()\n",
    "            \n",
    "    shutil.move('tmp.fasta', fasta)                  # overwrite original fasta file    \n",
    "\n",
    "# OUTPUT: FastaFiles_Modules/*.fasta  file have duplicates removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphabet = IUPAC.protein           # use protein alphabet\n",
    "instances = []\n",
    "# list of amino acids used to print the position weight matrix\n",
    "AminoList = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y' ]\n",
    "# column numbers for printing pwm, length of peptide, assumed to be 13, if different change last value\n",
    "pep_Header = ','.join([str(i) for i in range(0,13)])     \n",
    "\n",
    "# user defined directory containing Fasta files\n",
    "#os.chdir(\"/home/mplace/projects/forMatt/Phospho_Network/\")  \n",
    "\n",
    "def CreatePWM():\n",
    "    ''' Function creates PWMs for each Module '''\n",
    "    instances = []\n",
    "    with open('position_weight_matrix.txt', 'w') as out:\n",
    "        out.write('Motif,AA,%s\\n' %(pep_Header))                   \n",
    "        for x in os.listdir('FastaFiles_Modules/'):                 # Iterate through the Fasta files in the directory\n",
    "            if x.endswith('.fasta'):\n",
    "                with open('FastaFiles_Modules/' + x, \"r\") as f:\n",
    "                    for line in f:\n",
    "                        if line.startswith('>'):                                       \n",
    "                            continue\n",
    "                        line = line.rstrip()                                                 \n",
    "                        instances.append(Seq(line, IUPAC.protein))  # add amino acid sequence to instances\n",
    "                    m = motifs.create(instances)\n",
    "                    pwm = m.counts.normalize(pseudocounts = 1)      # Add a +1 pseudocount\n",
    "                    instances = []\n",
    "                    name = re.sub('.fasta', '', x)                  # use file name for 1st column          \n",
    "                    for aa in AminoList :\n",
    "                        score = [ str(i) for i in pwm[aa]]\n",
    "                        score = ','.join(score)\n",
    "                        out.write('%s,%s:,%s\\n' %(name,aa,score))\n",
    "    out.close()\n",
    "                    \n",
    "CreatePWM()\n",
    "\n",
    "# OUTPUT: position_weight_matrix.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Kullback-Leibler Module to Each Kinase\n",
    "\n",
    "Purpose:  \n",
    "\n",
    "To quantify similarity between the Mok et. al. kinase PWMs and the module\n",
    "PWMs. Script employs a previously described quantitative motif comparison method\n",
    "called Kullback-Leibler divergence (KLD) (Thijs et al., 2002, Gupta et al., 2007).\n",
    "KLD generates a similarity measure by comparing the Kullback-Leiber distance, or\n",
    "information content, for each amino acid at each position between a query and\n",
    "comparison PWM. The more alike two PWMs are, the closer to zero the score approaches.\n",
    "\n",
    "    KLD(X,Y) = 1/2 (E Xalog(Xa/Ya) + E Yalog(Ya/Xa))\n",
    "\n",
    "Where X represents a query PWM position and Y a comparison PWM position.\n",
    "Xa indicates the probability of a given amino acid a  A in X. \n",
    "The symbol A represents the length of the motif alphabet, which is 20, \n",
    "representing each of the naturally occurring amino acids. \n",
    "\n",
    "\n",
    "\n",
    "Input:\n",
    "A plain text .csv file that contains all module position weight matrices. Each\n",
    "module PWM should have 20 rows, representing each of the 20 naturally occurring\n",
    "amino acids. They are in a column called \"AA\" which stands for amino acid. There\n",
    "should also be 13 columns, labeled 0-12 (representing the 13 amino acid sequence length\n",
    "of the phospho-peptides used to build the position weight matrix) that contain the\n",
    "frequency of each amino acid at each position.\n",
    "\n",
    "Csv file format\n",
    "Motif,AA,0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "Induced_...sP.,P:,0.05,0.05,0.03, 0.05,0.05,0.03,0.05,0.05,0.03, 0.05,0.05,0.03\n",
    "\n",
    "In addition, a directory that contains the Mok et al kinase PWMs. They have the identical\n",
    "format as above. They have been pre-generated and are available for download on Github.\n",
    "The repository is titled, \"Mok_kinase_PWMs\"\n",
    "\n",
    "Required Parameters: Pandas must be installed on your machine.\n",
    "\n",
    "Output: A directory containing plain text .csv files named after each module (ie.\n",
    "Induced_...sP..txt). Within the .csv files are 63 KLD scores representing how well the\n",
    "63 Mok et al kinases match the module motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Compare_To=pd.read_csv('position_weight_matrix.txt')   # input module pwm                                                                                    # The PWMs for the Modules.\n",
    "\n",
    "def DF_to_TSV(dataframe, NewFileName): \n",
    "    ''' Function writes out dataframes as TSV files'''\n",
    "    #path ='' \n",
    "    dataframe.to_csv (NewFileName,sep='\\t')  \n",
    "\n",
    "def SplitCompareTOMotifs_df():\n",
    "    ''' Function splits the Compare_To DF by Motif, which is listed in the \"Motif\" column, \n",
    "        and puts the new dataframes into a list\n",
    "    '''\n",
    "    DF_CompareTo_lst =[]\n",
    "    for Motif in Compare_To['Motif'].unique():\n",
    "        DF=Compare_To.loc[Compare_To['Motif']==Motif]\n",
    "        DF_CompareTo_lst.append(DF)\n",
    "    return DF_CompareTo_lst\n",
    "\n",
    "DF_CompareTo_lst=SplitCompareTOMotifs_df()\n",
    "\n",
    "def SplitInput_df_byMotif():\n",
    "    ''' Split the Input dataframe by Motif and create indpendent dataframes'''\n",
    "    DF_Input_lst =[]\n",
    "    for Motif in Input['Motif'].unique():\n",
    "        DF=Input.loc[Input['Motif']==Motif]\n",
    "        DF_Input_lst.append(DF)\n",
    "    return DF_Input_lst\n",
    "\n",
    "def Copy(df):\n",
    "    ''' Function makes a copy of a dataframe.  '''\n",
    "    df=df.copy()\n",
    "    return df\n",
    "\n",
    "def mergeInputMotifFile_withDF_CompareTo(df_Input,df_CompareTo):\n",
    "    ''' Merge the query and comparison PWMs so that KLD can be calculated by comparing column values'''\n",
    "    df_merged=df_Input.merge(df_CompareTo, on='AA')\n",
    "  \n",
    "    return df_merged\n",
    "\n",
    "def Calculate_log_x_y(df):\n",
    "        ''' Function takes the log2 value of the amino acid frequency at each position of the query/comparison motifs'''\n",
    "        df['0_log(x/y)'] = df.apply(lambda x: math.log(x['0_x'],2) - math.log(x['0_y'],2), axis=1)\n",
    "        df['1_log(x/y)'] = df.apply(lambda x: math.log(x['1_x'],2) - math.log(x['1_y'],2), axis=1)\n",
    "        df['2_log(x/y)'] = df.apply(lambda x: math.log(x['2_x'],2) - math.log(x['2_y'],2), axis=1)\n",
    "        df['3_log(x/y)'] = df.apply(lambda x: math.log(x['3_x'],2) - math.log(x['3_y'],2), axis=1)\n",
    "        df['4_log(x/y)'] = df.apply(lambda x: math.log(x['4_x'],2) - math.log(x['4_y'],2), axis=1)\n",
    "        df['5_log(x/y)'] = df.apply(lambda x: math.log(x['5_x'],2) - math.log(x['5_y'],2), axis=1)\n",
    "        df['6_log(x/y)'] = df.apply(lambda x: math.log(x['6_x'],2) - math.log(x['6_y'],2), axis=1)\n",
    "        df['7_log(x/y)'] = df.apply(lambda x: math.log(x['7_x'],2) - math.log(x['7_y'],2), axis=1)\n",
    "        df['8_log(x/y)'] = df.apply(lambda x: math.log(x['8_x'],2) - math.log(x['8_y'],2), axis=1)\n",
    "        df['9_log(x/y)'] = df.apply(lambda x: math.log(x['9_x'],2) - math.log(x['9_y'],2), axis=1)\n",
    "        df['10_log(x/y)'] = df.apply(lambda x: math.log(x['10_x'],2) - math.log(x['10_y'],2), axis=1)\n",
    "        df['11_log(x/y)'] = df.apply(lambda x: math.log(x['11_x'],2) - math.log(x['11_y'],2), axis=1)\n",
    "        df['12_log(x/y)'] = df.apply(lambda x: math.log(x['12_x'],2) - math.log(x['12_y'],2), axis=1)\n",
    "        return df\n",
    "\n",
    "\n",
    "def Calculate_log_y_x(df):\n",
    "        ''' Function takes the log2 value of the amino acid frequency at each position of the comparison/query motifs'''\n",
    "        df['0_log(y/x)'] = df.apply(lambda x: math.log(x['0_y'],2) - math.log(x['0_x'],2), axis=1)\n",
    "        df['1_log(y/x)'] = df.apply(lambda x: math.log(x['1_y'],2) - math.log(x['1_x'],2), axis=1)\n",
    "        df['2_log(y/x)'] = df.apply(lambda x: math.log(x['2_y'],2) - math.log(x['2_x'],2), axis=1)\n",
    "        df['3_log(y/x)'] = df.apply(lambda x: math.log(x['3_y'],2) - math.log(x['3_x'],2), axis=1)\n",
    "        df['4_log(y/x)'] = df.apply(lambda x: math.log(x['4_y'],2) - math.log(x['4_x'],2), axis=1)\n",
    "        df['5_log(y/x)'] = df.apply(lambda x: math.log(x['5_y'],2) - math.log(x['5_x'],2), axis=1)\n",
    "        df['6_log(y/x)'] = df.apply(lambda x: math.log(x['6_y'],2) - math.log(x['6_x'],2), axis=1)\n",
    "        df['7_log(y/x)'] = df.apply(lambda x: math.log(x['7_y'],2) - math.log(x['7_x'],2), axis=1)\n",
    "        df['8_log(y/x)'] = df.apply(lambda x: math.log(x['8_y'],2) - math.log(x['8_x'],2), axis=1)\n",
    "        df['9_log(y/x)'] = df.apply(lambda x: math.log(x['9_y'],2) - math.log(x['9_x'],2), axis=1)\n",
    "        df['10_log(y/x)'] = df.apply(lambda x: math.log(x['10_y'],2) - math.log(x['10_x'],2), axis=1)\n",
    "        df['11_log(y/x)'] = df.apply(lambda x: math.log(x['11_y'],2) - math.log(x['11_x'],2), axis=1)\n",
    "        df['12_log(y/x)'] = df.apply(lambda x: math.log(x['12_y'],2) - math.log(x['12_x'],2), axis=1)\n",
    "        return df\n",
    "\n",
    "def Calculate_Faax_times_log_x_y(df):\n",
    "    ''' Function multiplies the frequency of an amino acid (Faax) \"Xa\" at a specific position in the query motif against the log(Xa/Ya) for that amino acid\n",
    "     It is calculating this part of the function  \"Xalog(Xa/Ya)\" '''\n",
    "\n",
    "    df['F(aax)*0_log(x/y)']=df['0_x']*df['0_log(x/y)']\n",
    "    df['F(aax)*1_log(x/y)']=df['1_x']*df['1_log(x/y)']\n",
    "    df['F(aax)*2_log(x/y)']=df['2_x']*df['2_log(x/y)']\n",
    "    df['F(aax)*3_log(x/y)']=df['3_x']*df['3_log(x/y)']\n",
    "    df['F(aax)*4_log(x/y)']=df['4_x']*df['4_log(x/y)']\n",
    "    df['F(aax)*5_log(x/y)']=df['5_x']*df['5_log(x/y)']\n",
    "    df['F(aax)*6_log(x/y)']=df['6_x']*df['6_log(x/y)']\n",
    "    df['F(aax)*7_log(x/y)']=df['7_x']*df['7_log(x/y)']\n",
    "    df['F(aax)*8_log(x/y)']=df['8_x']*df['8_log(x/y)']\n",
    "    df['F(aax)*9_log(x/y)']=df['9_x']*df['9_log(x/y)']\n",
    "    df['F(aax)*10_log(x/y)']=df['10_x']*df['10_log(x/y)']\n",
    "    df['F(aax)*11_log(x/y)']=df['11_x']*df['11_log(x/y)']\n",
    "    df['F(aax)*12_log(x/y)']=df['12_x']*df['12_log(x/y)']\n",
    "    return df\n",
    "\n",
    "def Calculate_Faay_times_log_y_x(df):\n",
    "    ''' Function multiplies the frequency of an amino acid (Faay) \"Ya\" at a specific position in the query motif against the log(Ya/Xa) for that amino acid\n",
    "     It is calculating this part of the function  \"Yalog(Ya/Xa)\" '''\n",
    "    df['F(aay)*0_log(y/x)']=df['0_y']*df['0_log(y/x)']\n",
    "    df['F(aay)*1_log(y/x)']=df['1_y']*df['1_log(y/x)']\n",
    "    df['F(aay)*2_log(y/x)']=df['2_y']*df['2_log(y/x)']\n",
    "    df['F(aay)*3_log(y/x)']=df['3_y']*df['3_log(y/x)']\n",
    "    df['F(aay)*4_log(y/x)']=df['4_y']*df['4_log(y/x)']\n",
    "    df['F(aay)*5_log(y/x)']=df['5_y']*df['5_log(y/x)']\n",
    "    df['F(aay)*6_log(y/x)']=df['6_y']*df['6_log(y/x)']\n",
    "    df['F(aay)*7_log(y/x)']=df['7_y']*df['7_log(y/x)']\n",
    "    df['F(aay)*8_log(y/x)']=df['8_y']*df['8_log(y/x)']\n",
    "    df['F(aay)*9_log(y/x)']=df['9_y']*df['9_log(y/x)']\n",
    "    df['F(aay)*10_log(y/x)']=df['10_y']*df['10_log(y/x)']\n",
    "    df['F(aay)*11_log(y/x)']=df['11_y']*df['11_log(y/x)']\n",
    "    df['F(aay)*12_log(y/x)']=df['12_y']*df['12_log(y/x)']\n",
    "    return df\n",
    "\n",
    "def Column_SUM(df):\n",
    "    ''' Function sums the values calculated by the previous two functions for each position, or column, in the PWMs  '''\n",
    "    df['sum_0']=sum(df['F(aax)*0_log(x/y)'])+sum(df['F(aay)*0_log(y/x)'])\n",
    "    df['sum_1']=sum(df['F(aax)*1_log(x/y)'])+sum(df['F(aay)*1_log(y/x)'])\n",
    "    df['sum_2']=sum(df['F(aax)*2_log(x/y)'])+sum(df['F(aay)*2_log(y/x)'])\n",
    "    df['sum_3']=sum(df['F(aax)*3_log(x/y)'])+sum(df['F(aay)*3_log(y/x)'])\n",
    "    df['sum_4']=sum(df['F(aax)*4_log(x/y)'])+sum(df['F(aay)*4_log(y/x)'])\n",
    "    df['sum_5']=sum(df['F(aax)*5_log(x/y)'])+sum(df['F(aay)*5_log(y/x)'])\n",
    "    df['sum_6']=sum(df['F(aax)*6_log(x/y)'])+sum(df['F(aay)*6_log(y/x)'])\n",
    "    df['sum_7']=sum(df['F(aax)*7_log(x/y)'])+sum(df['F(aay)*7_log(y/x)'])\n",
    "    df['sum_8']=sum(df['F(aax)*8_log(x/y)'])+sum(df['F(aay)*8_log(y/x)'])\n",
    "    df['sum_9']=sum(df['F(aax)*9_log(x/y)'])+sum(df['F(aay)*9_log(y/x)'])\n",
    "    df['sum_10']=sum(df['F(aax)*10_log(x/y)'])+sum(df['F(aay)*10_log(y/x)'])\n",
    "    df['sum_11']=sum(df['F(aax)*11_log(x/y)'])+sum(df['F(aay)*11_log(y/x)'])\n",
    "    df['sum_12']=(sum(df['F(aax)*12_log(x/y)'])+sum(df['F(aay)*12_log(y/x)']))\n",
    "    return df\n",
    "\n",
    "def TotalScore(df):\n",
    "    ''' Function calculates the total score by summing the summed values for each position in the PWM (13 positions)'''\n",
    "    df['FinalScore']=df['sum_0']+df['sum_1']+df['sum_2']+df['sum_3']+df['sum_4']+df['sum_5']+df['sum_6']+df['sum_7']+df['sum_8']+df['sum_9']+df['sum_10']+df['sum_11']+df['sum_12']\n",
    "    Lst=df['FinalScore'].unique()\n",
    "    n=Lst[0]\n",
    "    return n\n",
    "\n",
    "# Import the Mok Kinases PWM .csv files individually and create dataframes\n",
    "path=r\"Mok_kinase_PWMs/\"\n",
    "filenames = glob.glob(path + \"*.csv\")\n",
    "\n",
    "dfs_lst = []\n",
    "for filename in filenames:\n",
    "    dfs_lst.append(pd.read_csv(filename, sep=\",\"))\n",
    "    \n",
    "ITER_NUM=1                                          # One iteration of the below function. \n",
    "dict_Final={}\n",
    "for df2 in dfs_lst:                                 # This is the dataframe that has Module PWMs\n",
    "    \n",
    "    subModule_name=df2['Motif'].unique()\n",
    "    for df in DF_CompareTo_lst:                     # select one of the compare to dataframes (Mok Kinase PWM)\n",
    "        Kinase_name=[]\n",
    "        Kinase_name=df['Motif'].unique()\n",
    " \n",
    "        for iteration in range (ITER_NUM):                                      # for the first iteration \n",
    "\n",
    "            Copied=Copy(df2)                                                    # Copy Dataframe\n",
    "            # Create a merged version of the dataframe for each Kinase PWM and each Module PWM\n",
    "            df_merged=mergeInputMotifFile_withDF_CompareTo(Copied, df)  \n",
    "\n",
    "            DF_1=Calculate_log_x_y(df_merged)                                   \n",
    "            DF_2=Calculate_log_y_x(DF_1)\n",
    "            DF_3=Calculate_Faax_times_log_x_y(DF_2)\n",
    "            DF_4=Calculate_Faay_times_log_y_x(DF_3)\n",
    "            DF_5=Column_SUM(DF_4)\n",
    "        \n",
    "            n=TotalScore(DF_5)                                                  \n",
    "            #print (n)\n",
    "            test_tup = (n, subModule_name[0])\n",
    "            if Kinase_name[0] in dict_Final:\n",
    "                dict_Final[Kinase_name[0]].append(test_tup)\n",
    "            else:\n",
    "                lst=[]\n",
    "                dict_Final[Kinase_name[0]] = lst\n",
    "                dict_Final[Kinase_name[0]].append(test_tup)\n",
    "\n",
    "\n",
    "# write out the final dictionary to a folder where each key and value pair is an independent csv file. \n",
    "if not os.path.exists('ClassA_NoShuffle_KL'):\n",
    "    os.mkdir('ClassA_NoShuffle_KL')\n",
    "    \n",
    "path=\"ClassA_NoShuffle_KL/\"              # this is the path to the folder where the output files will be housed\n",
    "\n",
    "for k, v in dict_Final.items():           # select each key and value pair in the dict \n",
    "    newFile=path+ k +'.csv'               # create newFile, that will have the path and name (the key, which is the kinase) associated with it\n",
    "    #print (newFile)\n",
    "    with open(newFile, 'w') as output:  \n",
    "        output.write(k)\n",
    "        output.write(\"\\n\")\n",
    "        for x in v:\n",
    "           \n",
    "            output.write(str(x))\n",
    "            output.write(\"\\n\")\n",
    "\n",
    "# OUTPUT: ClassA_NoShuffle_KL/*.csv    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kullback-Leibler Module to Each Kinase Shuffled 1000x\n",
    "\n",
    "\n",
    "Purpose:  The same algorithm as the last step is used but w/ 1000 Shuffles of the Mok Kinase PWMs are performed by the script, generating randomized PWMs that are compared against the Module PWMs, producing a distribution of scores.\n",
    "\n",
    "Output: A directory containing plain text .csv files named after each module. Within\n",
    "the .csv files are 63,000 KLD scores representing how well the 63 Mok et al kinases\n",
    "match the module motif after 1000 permutations of each Mok kinase.\n",
    "\n",
    "# NUMBER OF ITERATIONS SET TO 25 for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compare_To=pd.read_csv('position_weight_matrix.txt')\n",
    "Input=pd.read_csv('position_weight_matrix.txt')\n",
    "\n",
    "def SplitCompareTOMotifs_df():\n",
    "    ''' Function splits the Compare_To DF by Motif, which is listed in the \"Motif\" column, and puts the new dataframes into a list'''\n",
    "    DF_CompareTo_lst =[]\n",
    "    for Motif in Compare_To['Motif'].unique():\n",
    "        DF=Compare_To.loc[Compare_To['Motif']==Motif]\n",
    "        DF_CompareTo_lst.append(DF)\n",
    "    return DF_CompareTo_lst\n",
    "\n",
    "DF_CompareTo_lst=SplitCompareTOMotifs_df()\n",
    "\n",
    "\n",
    "def SplitInput_df_byMotif():\n",
    "    ''' Split the Input dataframe by Motif and create indpendent dataframes'''\n",
    "    DF_Input_lst =[]\n",
    "    for Motif in Input['Motif'].unique():\n",
    "        DF=Input.loc[Input['Motif']==Motif]\n",
    "        DF_Input_lst.append(DF)\n",
    "    return DF_Input_lst\n",
    "\n",
    "#DF_Input_lst=SplitInput_df_byMotif()\n",
    "#Unique_Input_Motif_Names_lst=Input['Motif'].unique()\n",
    "\n",
    "def Shuffle(df):\n",
    "    '''Shuffle each column by row, after first creating independent dataframes for each column (position within the PWM)''' \n",
    "\n",
    "    df_Index = df[['Motif','AA']]  \n",
    "    df_data_0 = df['0']#,'1','2','3','4','5','7','8','9','10','11','12']]\n",
    "    df_data_1 = df['1']#'2','3','4','5','7','8','9','10','11','12']]\n",
    "    df_data_2 = df['2']\n",
    "    df_data_3 = df['3']\n",
    "    df_data_4 = df['4']\n",
    "    df_data_5 = df['5']\n",
    "    df_data_6 = df['6']\n",
    "    df_data_7 = df['7']\n",
    "    df_data_8 = df['8']\n",
    "    df_data_9 = df['9']\n",
    "    df_data_10 = df['10']\n",
    "    df_data_11 = df['11']\n",
    "    df_data_12 = df['12']\n",
    "    Shuffled_Input_0=df_data_0.iloc[np.random.permutation(len(df_data_0))] \n",
    "    Shuffled_Input_1=df_data_1.iloc[np.random.permutation(len(df_data_1))]                                  # Shuffle the data by row\n",
    "    Shuffled_Input_2=df_data_2.iloc[np.random.permutation(len(df_data_2))] \n",
    "    Shuffled_Input_3=df_data_3.iloc[np.random.permutation(len(df_data_3))] \n",
    "    Shuffled_Input_4=df_data_4.iloc[np.random.permutation(len(df_data_4))] \n",
    "    Shuffled_Input_5=df_data_5.iloc[np.random.permutation(len(df_data_5))] \n",
    "    Shuffled_Input_6=df_data_6.iloc[np.random.permutation(len(df_data_6))] \n",
    "    Shuffled_Input_7=df_data_7.iloc[np.random.permutation(len(df_data_7))] \n",
    "    Shuffled_Input_8=df_data_8.iloc[np.random.permutation(len(df_data_8))]\n",
    "    Shuffled_Input_9=df_data_9.iloc[np.random.permutation(len(df_data_9))] \n",
    "    Shuffled_Input_10=df_data_10.iloc[np.random.permutation(len(df_data_10))] \n",
    "    Shuffled_Input_11=df_data_11.iloc[np.random.permutation(len(df_data_11))] \n",
    "    Shuffled_Input_12=df_data_12.iloc[np.random.permutation(len(df_data_12))] \n",
    "\n",
    "    Shuffled_Input_0_reset_Index= Shuffled_Input_0.reset_index(drop=True)                                   # reset the index for a later merge\n",
    "    Shuffled_Input_1_reset_Index= Shuffled_Input_1.reset_index(drop=True)\n",
    "    Shuffled_Input_2_reset_Index= Shuffled_Input_2.reset_index(drop=True) \n",
    "    Shuffled_Input_3_reset_Index= Shuffled_Input_3.reset_index(drop=True)\n",
    "    Shuffled_Input_4_reset_Index= Shuffled_Input_4.reset_index(drop=True) \n",
    "    Shuffled_Input_5_reset_Index= Shuffled_Input_5.reset_index(drop=True)\n",
    "    Shuffled_Input_6_reset_Index= Shuffled_Input_6.reset_index(drop=True) \n",
    "    Shuffled_Input_7_reset_Index= Shuffled_Input_7.reset_index(drop=True)\n",
    "    Shuffled_Input_8_reset_Index= Shuffled_Input_8.reset_index(drop=True) \n",
    "    Shuffled_Input_9_reset_Index= Shuffled_Input_9.reset_index(drop=True)\n",
    "    Shuffled_Input_10_reset_Index= Shuffled_Input_10.reset_index(drop=True)\n",
    "    Shuffled_Input_11_reset_Index= Shuffled_Input_11.reset_index(drop=True) \n",
    "    Shuffled_Input_12_reset_Index= Shuffled_Input_12.reset_index(drop=True)\n",
    "    \n",
    "    result = pd.concat([df_Index, Shuffled_Input_0_reset_Index, Shuffled_Input_1_reset_Index, Shuffled_Input_2_reset_Index, Shuffled_Input_3_reset_Index,\n",
    "                       Shuffled_Input_4_reset_Index, Shuffled_Input_5_reset_Index, Shuffled_Input_6_reset_Index, Shuffled_Input_7_reset_Index,\n",
    "                       Shuffled_Input_8_reset_Index, Shuffled_Input_9_reset_Index, Shuffled_Input_10_reset_Index, Shuffled_Input_11_reset_Index, Shuffled_Input_12_reset_Index], axis=1) # concatenate the dataframes - they will sit side by side since have the same index (numbering)\n",
    "    result_reordered=result[[ 'Motif', 'AA','0','1', '2','3','4','5','6','7','8','9','10','11','12']]       # reorder the columns so in the correct PWM order.\n",
    "    \n",
    "    result_reordered_Index=result_reordered[['Motif','AA']]\n",
    "    result_reordered_Frame=result_reordered[['0','1', '2','3','4','5','6','7','8','9','10','11','12']]\n",
    "    cols = result_reordered_Frame.columns.tolist()                                                          # send column headers to a list\n",
    "   \n",
    "    random.shuffle(cols)                                                                                    # shuffle the columns, which are in a list by name, and return a different order\n",
    " \n",
    "    \n",
    "    \n",
    "    FinalDF=result_reordered_Frame[cols]                                                                    # make a new dataframe with randomly shuffled columns\n",
    "    FinalDF.columns = ['0','1', '2','3','4','5','6','7','8','9','10','11','12']                             # reset the column names, so that they have the original names\n",
    "    FinalDataframe= pd.concat([result_reordered_Index, FinalDF],axis=1)\n",
    "    return FinalDataframe\n",
    "\n",
    "Shuffled=Shuffle(Input)\n",
    "\n",
    "def mergeInputMotifFile_withDF_CompareTo(df_Input,df_CompareTo):\n",
    "    ''' Merge the query and comparison PWMs so that KLD can be calculated by comparing column values'''\n",
    "    df_merged=df_Input.merge(df_CompareTo, on='AA')\n",
    "    #df_lst.append(df_merged)\n",
    "    return df_merged\n",
    "   \n",
    "df_merged=mergeInputMotifFile_withDF_CompareTo(Shuffled, Compare_To)\n",
    "\n",
    "def Calculate_log_x_y(df):\n",
    "        ''' Function takes the log2 value of the amino acid frequency at each position of the query/comparison motifs'''\n",
    "        df['0_log(x/y)'] = df.apply(lambda x: math.log(x['0_x'],2) - math.log(x['0_y'],2), axis=1)\n",
    "        df['1_log(x/y)'] = df.apply(lambda x: math.log(x['1_x'],2) - math.log(x['1_y'],2), axis=1)\n",
    "        df['2_log(x/y)'] = df.apply(lambda x: math.log(x['2_x'],2) - math.log(x['2_y'],2), axis=1)\n",
    "        df['3_log(x/y)'] = df.apply(lambda x: math.log(x['3_x'],2) - math.log(x['3_y'],2), axis=1)\n",
    "        df['4_log(x/y)'] = df.apply(lambda x: math.log(x['4_x'],2) - math.log(x['4_y'],2), axis=1)\n",
    "        df['5_log(x/y)'] = df.apply(lambda x: math.log(x['5_x'],2) - math.log(x['5_y'],2), axis=1)\n",
    "        df['6_log(x/y)'] = df.apply(lambda x: math.log(x['6_x'],2) - math.log(x['6_y'],2), axis=1)\n",
    "        df['7_log(x/y)'] = df.apply(lambda x: math.log(x['7_x'],2) - math.log(x['7_y'],2), axis=1)\n",
    "        df['8_log(x/y)'] = df.apply(lambda x: math.log(x['8_x'],2) - math.log(x['8_y'],2), axis=1)\n",
    "        df['9_log(x/y)'] = df.apply(lambda x: math.log(x['9_x'],2) - math.log(x['9_y'],2), axis=1)\n",
    "        df['10_log(x/y)'] = df.apply(lambda x: math.log(x['10_x'],2) - math.log(x['10_y'],2), axis=1)\n",
    "        df['11_log(x/y)'] = df.apply(lambda x: math.log(x['11_x'],2) - math.log(x['11_y'],2), axis=1)\n",
    "        df['12_log(x/y)'] = df.apply(lambda x: math.log(x['12_x'],2) - math.log(x['12_y'],2), axis=1)\n",
    "        return df\n",
    "\n",
    "DF_1=Calculate_log_x_y(df_merged)\n",
    "\n",
    "\n",
    "def Calculate_log_y_x(df):\n",
    "        ''' Function takes the log2 value of the amino acid frequency at each position of the comparison/query motifs'''\n",
    "        df['0_log(y/x)'] = df.apply(lambda x: math.log(x['0_y'],2) - math.log(x['0_x'],2), axis=1)\n",
    "        df['1_log(y/x)'] = df.apply(lambda x: math.log(x['1_y'],2) - math.log(x['1_x'],2), axis=1)\n",
    "        df['2_log(y/x)'] = df.apply(lambda x: math.log(x['2_y'],2) - math.log(x['2_x'],2), axis=1)\n",
    "        df['3_log(y/x)'] = df.apply(lambda x: math.log(x['3_y'],2) - math.log(x['3_x'],2), axis=1)\n",
    "        df['4_log(y/x)'] = df.apply(lambda x: math.log(x['4_y'],2) - math.log(x['4_x'],2), axis=1)\n",
    "        df['5_log(y/x)'] = df.apply(lambda x: math.log(x['5_y'],2) - math.log(x['5_x'],2), axis=1)\n",
    "        df['6_log(y/x)'] = df.apply(lambda x: math.log(x['6_y'],2) - math.log(x['6_x'],2), axis=1)\n",
    "        df['7_log(y/x)'] = df.apply(lambda x: math.log(x['7_y'],2) - math.log(x['7_x'],2), axis=1)\n",
    "        df['8_log(y/x)'] = df.apply(lambda x: math.log(x['8_y'],2) - math.log(x['8_x'],2), axis=1)\n",
    "        df['9_log(y/x)'] = df.apply(lambda x: math.log(x['9_y'],2) - math.log(x['9_x'],2), axis=1)\n",
    "        df['10_log(y/x)'] = df.apply(lambda x: math.log(x['10_y'],2) - math.log(x['10_x'],2), axis=1)\n",
    "        df['11_log(y/x)'] = df.apply(lambda x: math.log(x['11_y'],2) - math.log(x['11_x'],2), axis=1)\n",
    "        df['12_log(y/x)'] = df.apply(lambda x: math.log(x['12_y'],2) - math.log(x['12_x'],2), axis=1)\n",
    "        return df\n",
    "\n",
    "def Calculate_Faax_times_log_x_y(df):\n",
    "    ''' Function multiplies the frequency of an amino acid (Faax) \"Xa\" at a specific position in the query motif against the log(Xa/Ya) for that amino acid\n",
    "     It is calculating this part of the function  \"Xalog(Xa/Ya)\" '''\n",
    "    df['F(aax)*0_log(x/y)']=df['0_x']*df['0_log(x/y)']\n",
    "    df['F(aax)*1_log(x/y)']=df['1_x']*df['1_log(x/y)']\n",
    "    df['F(aax)*2_log(x/y)']=df['2_x']*df['2_log(x/y)']\n",
    "    df['F(aax)*3_log(x/y)']=df['3_x']*df['3_log(x/y)']\n",
    "    df['F(aax)*4_log(x/y)']=df['4_x']*df['4_log(x/y)']\n",
    "    df['F(aax)*5_log(x/y)']=df['5_x']*df['5_log(x/y)']\n",
    "    df['F(aax)*6_log(x/y)']=df['6_x']*df['6_log(x/y)']\n",
    "    df['F(aax)*7_log(x/y)']=df['7_x']*df['7_log(x/y)']\n",
    "    df['F(aax)*8_log(x/y)']=df['8_x']*df['8_log(x/y)']\n",
    "    df['F(aax)*9_log(x/y)']=df['9_x']*df['9_log(x/y)']\n",
    "    df['F(aax)*10_log(x/y)']=df['10_x']*df['10_log(x/y)']\n",
    "    df['F(aax)*11_log(x/y)']=df['11_x']*df['11_log(x/y)']\n",
    "    df['F(aax)*12_log(x/y)']=df['12_x']*df['12_log(x/y)']\n",
    "    return df\n",
    "\n",
    "def Calculate_Faay_times_log_y_x(df):\n",
    "    ''' Function multiplies the frequency of an amino acid (Faay) \"Ya\" at a specific position in the query motif against the log(Ya/Xa) for that amino acid\n",
    "     It is calculating this part of the function  \"Yalog(Ya/Xa)\" '''\n",
    "    df['F(aay)*0_log(y/x)']=df['0_y']*df['0_log(y/x)']\n",
    "    df['F(aay)*1_log(y/x)']=df['1_y']*df['1_log(y/x)']\n",
    "    df['F(aay)*2_log(y/x)']=df['2_y']*df['2_log(y/x)']\n",
    "    df['F(aay)*3_log(y/x)']=df['3_y']*df['3_log(y/x)']\n",
    "    df['F(aay)*4_log(y/x)']=df['4_y']*df['4_log(y/x)']\n",
    "    df['F(aay)*5_log(y/x)']=df['5_y']*df['5_log(y/x)']\n",
    "    df['F(aay)*6_log(y/x)']=df['6_y']*df['6_log(y/x)']\n",
    "    df['F(aay)*7_log(y/x)']=df['7_y']*df['7_log(y/x)']\n",
    "    df['F(aay)*8_log(y/x)']=df['8_y']*df['8_log(y/x)']\n",
    "    df['F(aay)*9_log(y/x)']=df['9_y']*df['9_log(y/x)']\n",
    "    df['F(aay)*10_log(y/x)']=df['10_y']*df['10_log(y/x)']\n",
    "    df['F(aay)*11_log(y/x)']=df['11_y']*df['11_log(y/x)']\n",
    "    df['F(aay)*12_log(y/x)']=df['12_y']*df['12_log(y/x)']\n",
    "    return df\n",
    "\n",
    "def Column_SUM(df):\n",
    "    ''' Function sums the values calculated by the previous two functions for each position, or column, in the PWMs  '''\n",
    "    df['sum_0']=sum(df['F(aax)*0_log(x/y)'])+sum(df['F(aay)*0_log(y/x)'])\n",
    "    df['sum_1']=sum(df['F(aax)*1_log(x/y)'])+sum(df['F(aay)*1_log(y/x)'])\n",
    "    df['sum_2']=sum(df['F(aax)*2_log(x/y)'])+sum(df['F(aay)*2_log(y/x)'])\n",
    "    df['sum_3']=sum(df['F(aax)*3_log(x/y)'])+sum(df['F(aay)*3_log(y/x)'])\n",
    "    df['sum_4']=sum(df['F(aax)*4_log(x/y)'])+sum(df['F(aay)*4_log(y/x)'])\n",
    "    df['sum_5']=sum(df['F(aax)*5_log(x/y)'])+sum(df['F(aay)*5_log(y/x)'])\n",
    "    df['sum_6']=sum(df['F(aax)*6_log(x/y)'])+sum(df['F(aay)*6_log(y/x)'])\n",
    "    df['sum_7']=sum(df['F(aax)*7_log(x/y)'])+sum(df['F(aay)*7_log(y/x)'])\n",
    "    df['sum_8']=sum(df['F(aax)*8_log(x/y)'])+sum(df['F(aay)*8_log(y/x)'])\n",
    "    df['sum_9']=sum(df['F(aax)*9_log(x/y)'])+sum(df['F(aay)*9_log(y/x)'])\n",
    "    df['sum_10']=sum(df['F(aax)*10_log(x/y)'])+sum(df['F(aay)*10_log(y/x)'])\n",
    "    df['sum_11']=sum(df['F(aax)*11_log(x/y)'])+sum(df['F(aay)*11_log(y/x)'])\n",
    "    df['sum_12']=(sum(df['F(aax)*12_log(x/y)'])+sum(df['F(aay)*12_log(y/x)']))\n",
    "    return df\n",
    "\n",
    "def TotalScore(df):\n",
    "    ''' Function calculates the total score by summing the summed values for each position in the PWM (13 positions)'''\n",
    "    df['FinalScore']=df['sum_0']+df['sum_1']+df['sum_2']+df['sum_3']+df['sum_4']+df['sum_5']+df['sum_6']+df['sum_7']+df['sum_8']+df['sum_9']+df['sum_10']+df['sum_11']+df['sum_12']\n",
    "    Lst=df['FinalScore'].unique()\n",
    "    n=Lst[0]\n",
    "    return n\n",
    "\n",
    "# Import the Mok Kinases PWM .csv files individually and create dataframes\n",
    "path=r\"Mok_kinase_PWMs/\"\n",
    "filenames = glob.glob(path + \"*.csv\")\n",
    "\n",
    "dfs_lst = []\n",
    "for filename in filenames:\n",
    "    dfs_lst.append(pd.read_csv(filename, sep=\",\"))\n",
    "    \n",
    "# CHANGE THE NUMBER OF ITERATIONS HERE IF DESIRED\n",
    "ITER_NUM=25                                                                         # 1000 interations of this function\n",
    "dict_Final={}\n",
    "for df2 in dfs_lst:                                                                 # this is the dataframe that has Mok Kinase PWMs\n",
    "    \n",
    "    subModule_name=df2['Motif'].unique()\n",
    "    for df in DF_CompareTo_lst:                                                     # select one of the compare to dataframes (Modules)\n",
    "        Kinase_name=[]\n",
    "        Kinase_name=df['Motif'].unique()\n",
    "   \n",
    "        for iteration in range (ITER_NUM):                                          # for iteration x \n",
    "    \n",
    "            Shuffled=Shuffle(df2)                                                   # shuffle the dataframe by row and column\n",
    "            df_merged=mergeInputMotifFile_withDF_CompareTo(Shuffled, df)   \n",
    "            DF_1=Calculate_log_x_y(df_merged)\n",
    "            DF_2=Calculate_log_y_x(DF_1)\n",
    "            DF_3=Calculate_Faax_times_log_x_y(DF_2)\n",
    "            DF_4=Calculate_Faay_times_log_y_x(DF_3)\n",
    "            DF_5=Column_SUM(DF_4)\n",
    "        \n",
    "            n=TotalScore(DF_5)\n",
    "            #print (n)\n",
    "            test_tup = (n, subModule_name[0])\n",
    "            if Kinase_name[0] in dict_Final:\n",
    "                dict_Final[Kinase_name[0]].append(test_tup)\n",
    "            else:\n",
    "                lst=[]\n",
    "                dict_Final[Kinase_name[0]] = lst\n",
    "                dict_Final[Kinase_name[0]].append(test_tup)\n",
    "\n",
    "# write out the final dictionary to a folder where each key and value pair is an independent csv file. \n",
    "if not os.path.exists('Shuffle_KL'):\n",
    "    os.mkdir('Shuffle_KL')\n",
    "    \n",
    "path=r\"Shuffle_KL/\"  # path to output directory\n",
    "              \n",
    "for k, v in dict_Final.items():  \n",
    "    newFile=path+ k +'.csv'       \n",
    "    #print (newFile)\n",
    "    with open(newFile, 'w') as output:  \n",
    "        output.write(k)\n",
    "        output.write(\"\\n\")\n",
    "        for x in v:\n",
    "            #for subModule_name in filenames:\n",
    "            output.write(str(x))\n",
    "            output.write(\"\\n\")\n",
    "\n",
    "print('Kullback-Leibler Module to Each Kinase Shuffled 1000x complete')\n",
    "\n",
    "# OUTPUT: Shuffle_KL/*.csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate FDR Each Module \n",
    "Purpose: Identify FDR scores for each Mok et. al. kinase and each module by comparing\n",
    "the non-shuffled scores to the distribution of shuffled scores. The user can then manually\n",
    "define the FDR cutoff to call kinases \"motif-match\" or \"non-match\" for a given module.\n",
    "\n",
    "Input: Two directories and a single plain text .csv file, called \"Kinases_Not_In_Mok.csv\"\n",
    "that is provided on the Github page. The first directory contains plain text .csv files with\n",
    "KLD scores for non-shuffled Mok et al kinases and Modules. The second directory\n",
    "contains plain text .csv files containing KLD scores for shuffled Mok et. al. kinases and\n",
    "Modules.\n",
    "\n",
    "Csv format (For both Input Directories)\n",
    "\n",
    "Scores,Kinase,Module,\n",
    "13.25,cdc15,Induced.sP.\n",
    "\n",
    "\n",
    "Output: A table that contains for each module, all yeast kinases, including those found in\n",
    "the Mok et al dataset and those that were absent, and their FDR scores for each module.\n",
    "Kinases not found in the Mok et al dataset are given an FDR score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' This script is calculates an FDR for each Mok Kinase to each Module. \n",
    "The script takes the 63,000 shuffled Mok et al kinase-module scores and determines for each kinase where that unshuffled\n",
    "kinase-module score falls in the shuffled distribution.For example,if a Kinase has an shuffled score of 14.7 to a module,\n",
    "and only 63 unshuffled kinase-module scores are below that value, then this kinase has has an FDR of 0.1% \n",
    "(63/63,000 scores). We can then use the FDR values for all kinases to a module to determine an FDR cutoff for that\n",
    "module. Thus, we can say only these x kinases are a good match to the module. Calling an FDR threshold is \n",
    "done manually by the user.\n",
    "'''\n",
    "\n",
    "#Read in input files (which are the non-shuffled scores for all Mok kinases compared to each Module) \n",
    "path=r\"ClassA_NoShuffle_KL/\"\n",
    "filenames = glob.glob(path + \"*.csv\")\n",
    "\n",
    "labels = ['Scores','Kinase','Module']                # column header\n",
    "\n",
    "def load_data(filenames, dfs_input_lst):\n",
    "    ''' Read in files and parse to produce input data  '''\n",
    "    for i in filenames:\n",
    "        with open(i, 'r') as f:\n",
    "            mod_name = f.readline().rstrip()\n",
    "            for ln in f:\n",
    "                ln = ln.rstrip()\n",
    "                ln = re.sub('\\(', '', re.sub('\\)', '', re.sub('\\'','', re.sub('\\s', '', ln))))\n",
    "                row = (ln + ',' +mod_name).split(',')\n",
    "                dfs_input_lst.append(row)\n",
    "        f.close()\n",
    "    return dfs_input_lst\n",
    "\n",
    "dfs_input_lst = []\n",
    "Input = load_data(filenames, dfs_input_lst)\n",
    "Input = pd.DataFrame(dfs_input_lst, columns=labels)\n",
    "\n",
    "def SplitInput_df_byModule(data):\n",
    "    ''' Function splits the input dataframe, by Module, into independent dataframes'''\n",
    "    DF_Input_lst =[]\n",
    "    for Module in data['Module'].unique():\n",
    "        DF=data.loc[data['Module']==Module]\n",
    "        DF_Input_lst.append(DF)\n",
    "    return DF_Input_lst\n",
    "\n",
    "DF_Input_lst=SplitInput_df_byModule(Input)\n",
    "\n",
    "\n",
    "# Importing the Shuffled Mok kinase-Module Score csv files individually and creating dataframes\n",
    "path=r\"Shuffle_KL/\"\n",
    "filenames = glob.glob(path + \"*.csv\")\n",
    "\n",
    "dfs_lst = []\n",
    "shuffledData = load_data(filenames, dfs_lst)\n",
    "shuffledData = pd.DataFrame(dfs_lst, columns=labels)\n",
    "\n",
    "dfs_lst2= SplitInput_df_byModule(shuffledData)\n",
    "\n",
    "\n",
    "def CountScores_Below():\n",
    "    '''Function is calculating the number of scores in the shuffled distribution below a non-shuffled Kinase_Module score '''\n",
    "    Final_DFs_lst=[]   #\n",
    "    for DF_shuffled in dfs_lst2:  \n",
    "        DF_shuffled=DF_shuffled.copy()\n",
    "       \n",
    "        for df_noShuffle in DF_Input_lst:  \n",
    "            df_noShuffle=df_noShuffle.copy()\n",
    "       \n",
    "            if df_noShuffle['Module'].unique().all() == DF_shuffled['Module'].unique().all():      # if all of the values match in the module column for each df, then and only then, perform the below steps\n",
    "                Input_Score_lst=df_noShuffle['Scores'].tolist()  \n",
    "                \n",
    "                Scores_lst=[]  \n",
    "                for score in Input_Score_lst: \n",
    "                    Scores_lst_individual=[]\n",
    "                    num_smaller_items = (DF_shuffled['Scores']<score).sum()                        # create a variable that is the sum of all scores below the score in the Shuffled_Scores dataframe\n",
    "                 \n",
    "                    Scores_lst_individual.append(num_smaller_items)                                # append the number of scores below a given kinase-module score to the individual list.\n",
    "                    Scores_lst.append(Scores_lst_individual)                                       # append the individual scores to a list.\n",
    "                    merged = list(itertools.chain(*Scores_lst))                                    # Flatten the list of lists. \n",
    "                    \n",
    "                df_noShuffle['Counts_Less_Than']=merged\n",
    "                df_noShuffle['Number_of_Scores']=len(DF_shuffled)                                  # take all of the summed scores, one per kinase from the kinase-module no-shuffle dataframe, and create a new column.\n",
    "                Final_DFs_lst.append(df_noShuffle)  \n",
    "    return Final_DFs_lst\n",
    "\n",
    "DFs_with_CountsBelow_lst=CountScores_Below()\n",
    "   \n",
    "def Calculate_FDR():\n",
    "    ''' Function calculates an FDR value by dividing the number of shuffled scores for a kinase-module\n",
    "    that are smaller than the non-shuffled kinase-module score by all shuffled scores (63,000)  '''\n",
    "    DFs_with_CountsBelow_lst2=[]\n",
    "    for DF in DFs_with_CountsBelow_lst:\n",
    "        DF['FDR']=DF['Counts_Less_Than']/DF['Number_of_Scores']\n",
    "        DF=DF.sort_values(by=['FDR'], ascending=[True])\n",
    "        DFs_with_CountsBelow_lst2.append(DF)\n",
    "    return DFs_with_CountsBelow_lst2\n",
    " \n",
    "DFs_with_CountsBelow_lst2=Calculate_FDR()\n",
    "\n",
    "# Import the kinases not in the Mok et al dataset.\n",
    "Kinases_Not_In_Mok_DF=pd.read_csv('Kinases_Not_In_Mok.csv')\n",
    "\n",
    "\n",
    "def ConcatenateDFs_with_Kinases_Not_In_Mok():\n",
    "    '''Function adds the kinases not in the Mok et al dataset to the dataframes for each module'''\n",
    "    DFs_with_CountsBelow_lst3=[]\n",
    "    for DF in DFs_with_CountsBelow_lst2:\n",
    "        DF=DF.copy()\n",
    "        FinalDF=DF.append(Kinases_Not_In_Mok_DF)\n",
    "        DFs_with_CountsBelow_lst3.append(FinalDF)\n",
    "    return DFs_with_CountsBelow_lst3\n",
    "\n",
    "DFs_with_CountsBelow_lst3=ConcatenateDFs_with_Kinases_Not_In_Mok() \n",
    "  \n",
    "\n",
    "def ConcatenateDFs(): \n",
    "    '''Function appends all of the dataframes, for each module, together into one dataframe''' \n",
    "    EmptyDF = pd.DataFrame() \n",
    "    for df in DFs_with_CountsBelow_lst3: \n",
    "        df=df.copy() \n",
    "        EmptyDF=EmptyDF.append(df) \n",
    "    return EmptyDF\n",
    "\n",
    "Final=ConcatenateDFs()\n",
    "\n",
    "def DF_to_CSV(dataframe, NewFileName): \n",
    "    ''' Write out dataframe as a tab separated file.'''\n",
    "    dataframe.to_csv (NewFileName,sep='\\t') \n",
    "    \n",
    "DF_to_CSV(Final, 'FDR_Scores.csv')\n",
    "\n",
    "# OUTPUT: FDR_Scores.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Merge_SI_subModule_relationships_with_FDR_Scores\n",
    "\n",
    "Input\n",
    "\n",
    "FDR Scores input file:\n",
    "\n",
    "> Scores,Kinase,Group (According to Mok),Module,Counts_Less_Than,Number_of_Scores,FDR\n",
    "> 11.44097292,pho85-pho80,Proline_directed,Induced_......SP.....,0,63000,0\n",
    "> 11.92968433,fus3,Proline_directed,Induced_......SP.....,0,63000,0\n",
    "> 11.02325264,cdc28,Proline_directed,Induced_......SP.....,0,63000,0\n",
    "\n",
    "\n",
    "SI (Shared Interactors file) Final_enriched.csv from __Identify Shared Interactors__ Step\n",
    "NOTE: the shared interactor name will which is last in the Final_enriched.csv file has to be moved to the\n",
    "start of the line.  This is done in the next cell.\n",
    "\n",
    "> Shared_Interactor,M,Motif_Containing_Proteins,Motif,n,N,m,p-value,Rank(i),m_(number_of_tests),Q_(FDR),>(i/m)Q,BH_significant\n",
    "> YBR160W,304,YKL168C,Induced_......SP....._No_Phenotype_Exists,90,4638,24,1.37E-09,1,894,0.05,5.59E-05,1\n",
    "> YNL293W,16,YLR319C,Induced_......SP....._mkk1_2_Induced_Defective,31,4638,4,2.81E-06,2,894,0.05,0.000111857,1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'Submodule_Containing_Proteins', 'Interaction', 'Submodule', 'n', 'N', 'm', 'p-value', 'Rank(i)', 'm_(number_of_tests)', 'Q_(FDR)', '(i/m)Q', 'BH_significant', 'Shared_Interactor']\n",
      "['304', 'YOR188W', 'kinase_substrate:Reversed', 'Induced_......SP.....', '117', '4638', '29', '1.6549691069793215e-10', '1', '919', '0.05', '5.44069640914037e-05', '1', 'YBR160W']\n",
      "['298', 'YJR049C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '12', '2.891946623756871e-08', '2', '919', '0.05', '0.0001088139281828074', '1', 'YJL164C']\n",
      "['212', 'YJR049C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '10', '1.3749551891468198e-07', '3', '919', '0.05', '0.00016322089227421111', '1', 'YJR059W']\n",
      "['49', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '10', '2.5463103225217233e-07', '4', '919', '0.05', '0.0002176278563656148', '1', 'YBL007C']\n",
      "['17', 'YLR337C', 'ppi', 'Induced_......SP.....', '117', '4638', '6', '2.2362673666729923e-06', '5', '919', '0.05', '0.0002720348204570185', '1', 'YKL129C']\n",
      "['18', 'YDL161W', 'ppi', 'Induced_......SP.....', '117', '4638', '6', '3.2856968644047574e-06', '6', '919', '0.05', '0.00032644178454842223', '1', 'YBL047C']\n",
      "['12', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '6.449726337479547e-06', '7', '919', '0.05', '0.00038084874863982595', '1', 'YDL223C']\n",
      "['20', 'YJL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '6', '6.5822165288698995e-06', '8', '919', '0.05', '0.0004352557127312296', '1', 'YJR092W']\n",
      "['21', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '6', '9.026516802474138e-06', '9', '919', '0.05', '0.0004896626768226333', '1', 'YBR108W']\n",
      "['33', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '7', '1.3473172804660778e-05', '10', '919', '0.05', '0.000544069640914037', '1', 'YER122C']\n",
      "['39', 'YNL267W', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '6', '1.625114404455699e-05', '11', '919', '0.05', '0.0005984766050054407', '1', 'YLR248W']\n",
      "['15', 'YLR096W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '2.3011506194231395e-05', '12', '919', '0.05', '0.0006528835690968445', '1', 'YLR257W']\n",
      "['16', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '3.279979914649163e-05', '13', '919', '0.05', '0.0007072905331882481', '1', 'YNL293W']\n",
      "['27', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '6', '4.349994278629271e-05', '14', '919', '0.05', '0.0007616974972796519', '1', 'YML037C']\n",
      "['9', 'YIR006C', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '4.396761624065774e-05', '15', '919', '0.05', '0.0008161044613710556', '1', 'YDL161W']\n",
      "['9', 'YJL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '4.396761624065774e-05', '15', '919', '0.05', '0.0008161044613710556', '1', 'YNL125C']\n",
      "['9', 'YIL095W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '4.396761624065774e-05', '15', '919', '0.05', '0.0008161044613710556', '1', 'YGR241C']\n",
      "['17', 'YAL017W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '4.553460405468152e-05', '16', '919', '0.05', '0.0008705114254624592', '1', 'YMR184W']\n",
      "['93', 'YKL171W', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '8', '4.770613978447747e-05', '17', '919', '0.05', '0.000924918389553863', '1', 'YGL059W']\n",
      "['41', 'YPL150W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '7', '5.998761280748211e-05', '18', '919', '0.05', '0.0009793253536452666', '1', 'YNL186W']\n",
      "['24', 'YGR162W', 'ppi', 'Induced_....R.S......', '18', '4638', '3', '9.444420675934914e-05', '19', '919', '0.05', '0.0010337323177366704', '1', 'YNL020C']\n",
      "['212', 'YBR059C', 'kinase_substrate:Reversed', 'Induced_....R.S......', '18', '4638', '6', '9.938292283318172e-05', '20', '919', '0.05', '0.001088139281828074', '1', 'YJR059W']\n",
      "['76', 'YDR359C', 'ppi', 'Induced_......SP.....', '117', '4638', '9', '0.00010474365306210073', '21', '919', '0.05', '0.0011425462459194776', '1', 'YFL039C']\n",
      "['21', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '0.0001380970289080487', '22', '919', '0.05', '0.0011969532100108815', '1', 'YBL024W']\n",
      "['21', 'YPL141C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '0.0001380970289080487', '22', '919', '0.05', '0.0011969532100108815', '1', 'YDL006W']\n",
      "['16', 'YBL007C', 'ppi', 'Induced_...K..S......', '32', '4638', '3', '0.00015724503735501614', '23', '919', '0.05', '0.0012513601741022853', '1', 'YCR088W']\n",
      "['12', 'YBL085W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.0001628555413439106', '24', '919', '0.05', '0.001305767138193689', '1', 'YDR162C']\n",
      "['93', 'YIL135C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '5', '0.00016568536713772747', '25', '919', '0.05', '0.0013601741022850925', '1', 'YGL059W']\n",
      "['22', 'YJL128C', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.0001751380573968683', '26', '919', '0.05', '0.0014145810663764961', '1', 'YIL070C']\n",
      "['4', 'YNR031C', 'ppi', 'Induced_...RR.S......', '27', '4638', '2', '0.00019444318484097234', '27', '919', '0.05', '0.0014689880304679', '1', 'YLR287C']\n",
      "['39', 'YLR258W', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '5', '0.00021300414140868729', '28', '919', '0.05', '0.0015233949945593038', '1', 'YMR139W']\n",
      "['23', 'YDR490C', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.00021931196254776467', '29', '919', '0.05', '0.0015778019586507074', '1', 'YMR109W']\n",
      "['13', 'YIL095W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.00023067121537186712', '30', '919', '0.05', '0.0016322089227421112', '1', 'YLR342W']\n",
      "['36', 'YJL128C', 'given_gasch:Reversed', 'Induced_......SP.....', '117', '4638', '6', '0.0002377751729906231', '31', '919', '0.05', '0.0016866158868335146', '1', 'YLR362W']\n",
      "['47', 'YER114C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '4', '0.00023843724930975723', '32', '919', '0.05', '0.0017410228509249185', '1', 'YER177W']\n",
      "['21', 'YGR086C', 'ppi', 'Induced_......TP.....', '28', '4638', '3', '0.00024376713304578013', '33', '919', '0.05', '0.0017954298150163223', '1', 'YMR086W']\n",
      "['24', 'YOR056C', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.00027148790121708734', '34', '919', '0.05', '0.001849836779107726', '1', 'YPL012W']\n",
      "['24', 'YPL141C', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.00027148790121708734', '34', '919', '0.05', '0.001849836779107726', '1', 'YOL041C']\n",
      "['14', 'YJL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.0003166776191728272', '35', '919', '0.05', '0.0019042437431991298', '1', 'YPR137C-A']\n",
      "['14', 'YBL011W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.0003166776191728272', '35', '919', '0.05', '0.0019042437431991298', '1', 'YPR091C']\n",
      "['21', 'YGR152C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '3', '0.00033156074301564424', '36', '919', '0.05', '0.001958650707290533', '1', 'YAL041W']\n",
      "['54', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '7', '0.00036034393475864343', '37', '919', '0.05', '0.002013057671381937', '1', 'YFL023W']\n",
      "['39', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '6', '0.0003744453908249417', '38', '919', '0.05', '0.002067464635473341', '1', 'YLL008W']\n",
      "['126', 'YKL171W', 'ppi', 'Induced_...R..S......', '67', '4638', '8', '0.00040347752082270903', '39', '919', '0.05', '0.002121871599564744', '1', 'YPL204W']\n",
      "['26', 'YPL141C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '0.0004035411826225379', '40', '919', '0.05', '0.002176278563656148', '1', 'YGR276C']\n",
      "['55', 'YPL049C', 'ppi', 'Induced_......SP.....', '117', '4638', '7', '0.0004043862278487299', '41', '919', '0.05', '0.0022306855277475514', '1', 'YHR030C']\n",
      "['298', 'YCR077C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '18', '0.00040716077565072187', '42', '919', '0.05', '0.0022850924918389553', '1', 'YJL164C']\n",
      "['15', 'YAL017W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.0004234652966214899', '43', '919', '0.05', '0.002339499455930359', '1', 'YDR134C']\n",
      "['15', 'YCR030C', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.0004234652966214899', '43', '919', '0.05', '0.002339499455930359', '1', 'YNR047W']\n",
      "['5', 'YDR110W', 'ppi', 'Induced_...K..SP.....', '31', '4638', '2', '0.00042704373907875316', '44', '919', '0.05', '0.002393906420021763', '1', 'YDR026C']\n",
      "['40', 'YJL020C', 'ppi', 'Induced_......SP.....', '117', '4638', '6', '0.0004315600590074845', '45', '919', '0.05', '0.0024483133841131668', '1', 'YOR181W']\n",
      "['11', 'YJR059W', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '3', '0.0004377278854363946', '46', '919', '0.05', '0.0025027203482045706', '1', 'YLR133W']\n",
      "['11', 'YER164W', 'ppi', 'Induced_...K..TP.....', '14', '4638', '2', '0.00045826535562435366', '47', '919', '0.05', '0.002557127312295974', '1', 'YBL097W']\n",
      "['180', 'YDR169C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '6', '0.00047091152217999105', '48', '919', '0.05', '0.002611534276387378', '1', 'YFR014C']\n",
      "['27', 'YOL100W', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.0004853687371301958', '49', '919', '0.05', '0.002665941240478781', '1', 'YLR258W']\n",
      "['7', 'YJL095W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0005086362945511713', '50', '919', '0.05', '0.002720348204570185', '1', 'YOR201C']\n",
      "['7', 'YJL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0005086362945511713', '50', '919', '0.05', '0.002720348204570185', '1', 'YJR063W']\n",
      "['7', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0005086362945511713', '50', '919', '0.05', '0.002720348204570185', '1', 'YNL077W']\n",
      "['7', 'YLR096W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0005086362945511713', '50', '919', '0.05', '0.002720348204570185', '1', 'YJR044C']\n",
      "['27', 'YJL165C', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '4', '0.0005436794876929297', '51', '919', '0.05', '0.002774755168661589', '1', 'YGL105W']\n",
      "['28', 'YPL004C', 'ppi', 'Induced_......TP.....', '28', '4638', '3', '0.0005836749913758218', '52', '919', '0.05', '0.0028291621327529923', '1', 'YGR130C']\n",
      "['3', 'YLR258W', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.0006110737825224753', '53', '919', '0.05', '0.002883569096844396', '1', 'YPL219W']\n",
      "['419', 'YDL173W', 'kinase_substrate:Reversed', 'Induced_....R.S......', '18', '4638', '7', '0.0006156227994323732', '54', '919', '0.05', '0.0029379760609358', '1', 'YPL031C']\n",
      "['6', 'YHL007C', 'kinase_substrate', 'Induced_...K..SP.....', '31', '4638', '2', '0.0006378971896951371', '55', '919', '0.05', '0.0029923830250272038', '1', 'YOL112W']\n",
      "['29', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '0.0006857834377711319', '56', '919', '0.05', '0.0030467899891186076', '1', 'YGL245W']\n",
      "['27', 'YJL081C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '3', '0.00070963908078517', '57', '919', '0.05', '0.003101196953210011', '1', 'YGL150C']\n",
      "['17', 'YPL141C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.0007100417522009297', '58', '919', '0.05', '0.003155603917301415', '1', 'YNL284C-A']\n",
      "['17', 'YDL161W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.0007100417522009297', '58', '919', '0.05', '0.003155603917301415', '1', 'YNL243W']\n",
      "['29', 'YNL183C', 'ppi', 'Induced_...R..S......', '67', '4638', '4', '0.0007199715692811789', '59', '919', '0.05', '0.0032100108813928187', '1', 'YJL084C']\n",
      "['11', 'YCR088W', 'ppi', 'Induced_...R..TP.....', '18', '4638', '2', '0.0007665091609324785', '60', '919', '0.05', '0.0032644178454842225', '1', 'YNL106C']\n",
      "['212', 'YIL107C', 'kinase_substrate:Reversed', 'Induced_......SP.....', '117', '4638', '14', '0.0007915598187796434', '61', '919', '0.05', '0.0033188248095756255', '1', 'YJR059W']\n",
      "['202', 'YLR003C', 'kinase_substrate:Reversed', 'Induced_....R.S......', '18', '4638', '5', '0.0008029520266334819', '62', '919', '0.05', '0.0033732317736670293', '1', 'YGL180W']\n",
      "['115', 'YDL173W', 'kinase_substrate:Reversed', 'Induced_....R.S......', '18', '4638', '4', '0.0008389192547999454', '63', '919', '0.05', '0.003427638737758433', '1', 'YBL016W']\n",
      "['33', 'YIL135C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '3', '0.0008546955185544426', '64', '919', '0.05', '0.003482045701849837', '1', 'YCR091W']\n",
      "['7', 'YKL088W', 'ppi', 'Induced_...K..SP.....', '31', '4638', '2', '0.0008893371982945371', '65', '919', '0.05', '0.0035364526659412408', '1', 'YDR436W']\n",
      "['18', 'YOR208W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.0008952582003392204', '66', '919', '0.05', '0.0035908596300326446', '1', 'YER118C']\n",
      "['8', 'YPL004C', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.000962406803159665', '67', '919', '0.05', '0.003645266594124048', '1', 'YKL142W']\n",
      "['16', 'YCR088W', 'ppi', 'Induced_...K..TP.....', '14', '4638', '2', '0.0009912597759878402', '68', '919', '0.05', '0.003699673558215452', '1', 'YHR016C']\n",
      "['32', 'YPL115C', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.0010947675585057024', '69', '919', '0.05', '0.0037540805223068557', '1', 'YLR229C']\n",
      "['32', 'YCL032W', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.0010947675585057024', '69', '919', '0.05', '0.0037540805223068557', '1', 'YMR117C']\n",
      "['35', 'YHR102W', 'kinase_substrate', 'Induced_......TP.....', '28', '4638', '3', '0.0011335740792298825', '70', '919', '0.05', '0.0038084874863982595', '1', 'YNL161W']\n",
      "['15', 'YJR059W', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '3', '0.0011580839691817878', '71', '919', '0.05', '0.0038628944504896633', '1', 'YMR196W']\n",
      "['9', 'YOL100W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0011763232694027659', '72', '919', '0.05', '0.003917301414581066', '1', 'YHL009C']\n",
      "['9', 'YLR096W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0011763232694027659', '72', '919', '0.05', '0.003917301414581066', '1', 'YDL203C']\n",
      "['9', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0011763232694027659', '72', '919', '0.05', '0.003917301414581066', '1', 'YNL167C']\n",
      "['9', 'YMR109W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0011763232694027659', '72', '919', '0.05', '0.003917301414581066', '1', 'YDL019C']\n",
      "['9', 'YJL141C', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0011763232694027659', '72', '919', '0.05', '0.003917301414581066', '1', 'YKL091C']\n",
      "['9', 'YOL100W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0011763232694027659', '72', '919', '0.05', '0.003917301414581066', '1', 'YJR097W']\n",
      "['31', 'YER165W', 'ppi', 'Induced_...K..S......', '32', '4638', '3', '0.001176434935697158', '73', '919', '0.05', '0.00397170837867247', '1', 'YBL105C']\n",
      "['4', 'YDR074W', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.001210735616085523', '74', '919', '0.05', '0.004026115342763874', '1', 'YBR126C']\n",
      "['83', 'YJL084C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '4', '0.0012230430111663355', '75', '919', '0.05', '0.004080522306855278', '1', 'YGL179C']\n",
      "['14', 'YDL025C', 'ppi', 'Induced_...R..TP.....', '18', '4638', '2', '0.0012595016076341365', '76', '919', '0.05', '0.004134929270946682', '1', 'YOR177C']\n",
      "['85', 'YKL038W', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '6', '0.0012949305589643266', '77', '919', '0.05', '0.004189336235038085', '1', 'YPL203W']\n",
      "['85', 'YDR001C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '4', '0.001336928121327278', '78', '919', '0.05', '0.004243743199129488', '1', 'YPL203W']\n",
      "['20', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.001363260655194724', '79', '919', '0.05', '0.004298150163220892', '1', 'YPR160W']\n",
      "['39', 'YMR165C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '3', '0.0013987094021007812', '80', '919', '0.05', '0.004352557127312296', '1', 'YMR139W']\n",
      "['39', 'YDR169C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '3', '0.0013987094021007812', '80', '919', '0.05', '0.004352557127312296', '1', 'YLR248W']\n",
      "['9', 'YBR068C', 'metabolic_pathway', 'Induced_...K..SP.....', '31', '4638', '2', '0.0015119141250720578', '81', '919', '0.05', '0.0044069640914037', '1', 'YHR208W']\n",
      "['10', 'YNL027W', 'kinase_substrate:Reversed', 'Induced_......TP.....', '28', '4638', '2', '0.0015352040530837402', '82', '919', '0.05', '0.004461371055495103', '1', 'YOL001W']\n",
      "['10', 'YOL139C', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.0015352040530837402', '82', '919', '0.05', '0.004461371055495103', '1', 'YHR087W']\n",
      "['39', 'YPL004C', 'ppi', 'Induced_......TP.....', '28', '4638', '3', '0.0015574787773598503', '83', '919', '0.05', '0.004515778019586507', '1', 'YHR186C']\n",
      "['9', 'YNL020C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.0016110833843210942', '84', '919', '0.05', '0.0045701849836779105', '1', 'YGR241C']\n",
      "['10', 'YJL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0016496670129743135', '85', '919', '0.05', '0.004624591947769314', '1', 'YNL054W-A']\n",
      "['21', 'YBL105C', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.001651534449603453', '86', '919', '0.05', '0.004678998911860718', '1', 'YFR024C-A']\n",
      "['17', 'YLR258W', 'ppi', 'Induced_...R..S......', '67', '4638', '3', '0.0016953395732832437', '87', '919', '0.05', '0.004733405875952123', '1', 'YGL134W']\n",
      "['158', 'YKL168C', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '8', '0.001792845329972059', '88', '919', '0.05', '0.004787812840043526', '1', 'YNL307C']\n",
      "['3', 'YLR096W', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.0018618949880488576', '89', '919', '0.05', '0.00484221980413493', '1', 'YOR093C']\n",
      "['3', 'YPL141C', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.0018618949880488576', '89', '919', '0.05', '0.00484221980413493', '1', 'YEL055C']\n",
      "['17', 'YBR059C', 'kinase_substrate', 'Induced_....R.S......', '18', '4638', '2', '0.00186939074102975', '90', '919', '0.05', '0.0048966267682263335', '1', 'YPL106C']\n",
      "['17', 'YOR304W', 'ppi', 'Induced_...R..TP.....', '18', '4638', '2', '0.00186939074102975', '90', '919', '0.05', '0.0048966267682263335', '1', 'YJR060W']\n",
      "['36', 'YLR371W', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.0018912357214284142', '91', '919', '0.05', '0.004951033732317737', '1', 'YDR293C']\n",
      "['158', 'YIL135C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '5', '0.001892788531510212', '92', '919', '0.05', '0.005005440696409141', '1', 'YNL307C']\n",
      "['90', 'YMR196W', 'ppi', 'Induced_......TP.....', '28', '4638', '4', '0.001901221604180981', '93', '919', '0.05', '0.005059847660500544', '1', 'YLR096W']\n",
      "['22', 'YPL150W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.0019796225367637765', '94', '919', '0.05', '0.005114254624591948', '1', 'YNR006W']\n",
      "['5', 'YNR047W', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.0019990696450095753', '95', '919', '0.05', '0.005168661588683352', '1', 'YOR353C']\n",
      "['5', 'YNL183C', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.0019990696450095753', '95', '919', '0.05', '0.005168661588683352', '1', 'YER087W']\n",
      "['5', 'YLR258W', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.0019990696450095753', '95', '919', '0.05', '0.005168661588683352', '1', 'YJL137C']\n",
      "['12', 'YJL057C', 'ppi', 'Induced_...RR.S......', '27', '4638', '2', '0.0020782246220715735', '96', '919', '0.05', '0.005223068552774756', '1', 'YDL053C']\n",
      "['18', 'YKL126W', 'ppi', 'Induced_....R.S......', '18', '4638', '2', '0.0020982351262604326', '97', '919', '0.05', '0.0052774755168661595', '1', 'YPR041W']\n",
      "['18', 'YDR189W', 'ppi', 'Induced_....R.S......', '18', '4638', '2', '0.0020982351262604326', '97', '919', '0.05', '0.0052774755168661595', '1', 'YLR078C']\n",
      "['93', 'YGR008C', 'kinase_substrate:Reversed', 'Induced_......SP.....', '117', '4638', '8', '0.0021980025860086727', '98', '919', '0.05', '0.005331882480957562', '1', 'YGL059W']\n",
      "['11', 'YBL105C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0022267720416805307', '99', '919', '0.05', '0.005386289445048966', '1', 'YLR133W']\n",
      "['11', 'YOL082W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0022267720416805307', '99', '919', '0.05', '0.005386289445048966', '1', 'YMR104C']\n",
      "['11', 'YKL168C', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0022267720416805307', '99', '919', '0.05', '0.005386289445048966', '1', 'YJL138C']\n",
      "['12', 'YOL139C', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.0022348712419878684', '100', '919', '0.05', '0.00544069640914037', '1', 'YDR206W']\n",
      "['11', 'YOR109W', 'metabolic_pathway', 'Induced_...K..SP.....', '31', '4638', '2', '0.0022906959156534564', '101', '919', '0.05', '0.005495103373231774', '1', 'YNL106C']\n",
      "['11', 'YBR068C', 'metabolic_pathway', 'Induced_...K..SP.....', '31', '4638', '2', '0.0022906959156534564', '101', '919', '0.05', '0.005495103373231774', '1', 'YGR094W']\n",
      "['95', 'YOL139C', 'kinase_substrate:Reversed', 'Induced_......TP.....', '28', '4638', '4', '0.002320111317345022', '102', '919', '0.05', '0.005549510337323178', '1', 'YPL141C']\n",
      "['23', 'YJL095W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.002350214236604257', '103', '919', '0.05', '0.005603917301414581', '1', 'YML074C']\n",
      "['23', 'YOL100W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.002350214236604257', '103', '919', '0.05', '0.005603917301414581', '1', 'YOL082W']\n",
      "['13', 'YJL057C', 'ppi', 'Induced_...RR.S......', '27', '4638', '2', '0.0024472796996161967', '104', '919', '0.05', '0.0056583242655059846', '1', 'YAL016W']\n",
      "['42', 'YJL081C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '3', '0.00260254942234577', '105', '919', '0.05', '0.005712731229597388', '1', 'YBL003C']\n",
      "['47', 'YGR086C', 'kinase_substrate:Reversed', 'Induced_......TP.....', '28', '4638', '3', '0.0026755708819991195', '106', '919', '0.05', '0.005767138193688792', '1', 'YOL100W']\n",
      "['12', 'YDR110W', 'ppi', 'Induced_...K..SP.....', '31', '4638', '2', '0.0027374094089656895', '107', '919', '0.05', '0.005821545157780196', '1', 'YDR088C']\n",
      "['12', 'YER114C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '2', '0.0027374094089656895', '107', '919', '0.05', '0.005821545157780196', '1', 'YDR162C']\n",
      "['12', 'YOR123C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '2', '0.0027374094089656895', '107', '919', '0.05', '0.005821545157780196', '1', 'YFL013C']\n",
      "['20', 'YKL171W', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '3', '0.0027554988846202762', '108', '919', '0.05', '0.0058759521218716', '1', 'YPR160W']\n",
      "['24', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.0027659595036960594', '109', '919', '0.05', '0.005930359085963004', '1', 'YIR006C']\n",
      "['24', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.0027659595036960594', '109', '919', '0.05', '0.005930359085963004', '1', 'YDL070W']\n",
      "['14', 'YCL011C', 'ppi', 'Induced_...RR.S......', '27', '4638', '2', '0.0028449282336530856', '110', '919', '0.05', '0.0059847660500544075', '1', 'YNL112W']\n",
      "['50', 'YIL135C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '3', '0.002874545926333846', '111', '919', '0.05', '0.006039173014145811', '1', 'YPL026C']\n",
      "['76', 'YDL173W', 'ppi', 'Induced_....R.S......', '18', '4638', '3', '0.002890841375463768', '112', '919', '0.05', '0.006093579978237215', '1', 'YDR381W']\n",
      "['12', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.002914744208489944', '113', '919', '0.05', '0.006147986942328619', '1', 'YDR169C']\n",
      "['12', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.002914744208489944', '113', '919', '0.05', '0.006147986942328619', '1', 'YAR014C']\n",
      "['12', 'YPL242C', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.002914744208489944', '113', '919', '0.05', '0.006147986942328619', '1', 'YDR264C']\n",
      "['14', 'YGR086C', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.0030584894377033173', '114', '919', '0.05', '0.006202393906420022', '1', 'YMR031C']\n",
      "['212', 'YKL168C', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '9', '0.0031160782550766113', '115', '919', '0.05', '0.006256800870511426', '1', 'YJR059W']\n",
      "['22', 'YHL007C', 'kinase_substrate', 'Induced_...R..TP.....', '18', '4638', '2', '0.003138934062526811', '116', '919', '0.05', '0.00631120783460283', '1', 'YLR314C']\n",
      "['47', 'YDL156W', 'ppi', 'Induced_...K..SP.....', '31', '4638', '3', '0.0035939380748231716', '117', '919', '0.05', '0.0063656147986942335', '1', 'YBL002W']\n",
      "['22', 'YLR258W', 'ppi', 'Induced_...R..S......', '67', '4638', '3', '0.003646368533189137', '118', '919', '0.05', '0.006420021762785637', '1', 'YAL017W']\n",
      "['4', 'YLR096W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YLR375W']\n",
      "['4', 'YJL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YOR196C']\n",
      "['4', 'YNL298W', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YGL162W']\n",
      "['4', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YDL099W']\n",
      "['4', 'YLR096W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YJR056C']\n",
      "['4', 'YMR261C', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YBR126C']\n",
      "['4', 'YCR030C', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YLR332W']\n",
      "['4', 'YPL141C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YDL135C']\n",
      "['4', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.0036623283076163407', '119', '919', '0.05', '0.006474428726877041', '1', 'YGR100W']\n",
      "['13', 'YOL100W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0037199661063995184', '120', '919', '0.05', '0.006528835690968445', '1', 'YOR260W']\n",
      "['13', 'YPL141C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0037199661063995184', '120', '919', '0.05', '0.006528835690968445', '1', 'YML035C']\n",
      "['13', 'YJL095W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.0037199661063995184', '120', '919', '0.05', '0.006528835690968445', '1', 'YLR196W']\n",
      "['13', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.0037199661063995184', '120', '919', '0.05', '0.006528835690968445', '1', 'YLR410W']\n",
      "['42', 'YAL017W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '0.0037840425649311982', '121', '919', '0.05', '0.006583242655059849', '1', 'YAR019C']\n",
      "['54', 'YMR291W', 'ppi', 'Induced_......TP.....', '28', '4638', '3', '0.00397888210017004', '122', '919', '0.05', '0.006637649619151251', '1', 'YDR328C']\n",
      "['16', 'YPL004C', 'kinase_substrate:Reversed', 'Induced_......TP.....', '28', '4638', '2', '0.004003187321901316', '123', '919', '0.05', '0.006692056583242655', '1', 'YDR490C']\n",
      "['7', 'YJR059W', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '2', '0.0041202117792734395', '124', '919', '0.05', '0.006746463547334059', '1', 'YBR035C']\n",
      "['7', 'YNL183C', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.0041202117792734395', '124', '919', '0.05', '0.006746463547334059', '1', 'YLL018C']\n",
      "['23', 'YJR059W', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '3', '0.004150347596176444', '125', '919', '0.05', '0.006800870511425462', '1', 'YOL128C']\n",
      "['15', 'YBR068C', 'metabolic_pathway', 'Induced_...K..SP.....', '31', '4638', '2', '0.00430092982770496', '126', '919', '0.05', '0.006855277475516866', '1', 'YJR148W']\n",
      "['27', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.004309854511973705', '127', '919', '0.05', '0.00690968443960827', '1', 'YKL042W']\n",
      "['26', 'YGR162W', 'ppi', 'Induced_....R.S......', '18', '4638', '2', '0.004375857653874379', '128', '919', '0.05', '0.006964091403699674', '1', 'YOL139C']\n",
      "['26', 'YBR172C', 'ppi', 'Induced_...R..TP.....', '18', '4638', '2', '0.004375857653874379', '128', '919', '0.05', '0.006964091403699674', '1', 'YOL139C']\n",
      "['62', 'YJL128C', 'given_gasch', 'Induced_......SP.....', '117', '4638', '6', '0.004405006906916277', '129', '919', '0.05', '0.007018498367791078', '1', 'YLR113W']\n",
      "['47', 'YNL267W', 'ppi', 'Induced_...R..S......', '67', '4638', '4', '0.0044496796579146245', '130', '919', '0.05', '0.0070729053318824816', '1', 'YER177W']\n",
      "['17', 'YNL103W', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.004520056717057756', '131', '919', '0.05', '0.007127312295973885', '1', 'YJR060W']\n",
      "['89', 'YDL229W', 'ppi', 'Induced_....R.S......', '18', '4638', '3', '0.004524656321856009', '132', '919', '0.05', '0.007181719260065289', '1', 'YDR432W']\n",
      "['116', 'YOR227W', 'ppi', 'Induced_...K..TP.....', '14', '4638', '3', '0.004537072666305511', '133', '919', '0.05', '0.007236126224156692', '1', 'YER133W']\n",
      "['15', 'YNL020C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.00457910095652422', '134', '919', '0.05', '0.007290533188248096', '1', 'YNL084C']\n",
      "['15', 'YBL047C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.00457910095652422', '134', '919', '0.05', '0.007290533188248096', '1', 'YCR030C']\n",
      "['15', 'YER165W', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.00457910095652422', '134', '919', '0.05', '0.007290533188248096', '1', 'YMR146C']\n",
      "['14', 'YNL225C', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.004648135693839373', '135', '919', '0.05', '0.0073449401523395', '1', 'YOR177C']\n",
      "['14', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.004648135693839373', '135', '919', '0.05', '0.0073449401523395', '1', 'YPL257W-A']\n",
      "['14', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.004648135693839373', '135', '919', '0.05', '0.0073449401523395', '1', 'YPR152C']\n",
      "['14', 'YPL049C', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.004648135693839373', '135', '919', '0.05', '0.0073449401523395', '1', 'YKL161C']\n",
      "['14', 'YER167W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.004648135693839373', '135', '919', '0.05', '0.0073449401523395', '1', 'YHR158C']\n",
      "['14', 'YJL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.004648135693839373', '135', '919', '0.05', '0.0073449401523395', '1', 'YDR034C-C']\n",
      "['14', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.004648135693839373', '135', '919', '0.05', '0.0073449401523395', '1', 'YKL062W']\n",
      "['24', 'YPL085W', 'ppi', 'Induced_...R..S......', '67', '4638', '3', '0.0046946699451646525', '136', '919', '0.05', '0.007399347116430904', '1', 'YIL109C']\n",
      "['27', 'YCR088W', 'ppi', 'Induced_...R..TP.....', '18', '4638', '2', '0.004715086650290065', '137', '919', '0.05', '0.0074537540805223075', '1', 'YGL206C']\n",
      "['18', 'YJL057C', 'ppi', 'Induced_...RR.S......', '27', '4638', '2', '0.004715086650303246', '138', '919', '0.05', '0.007508161044613711', '1', 'YJL019W']\n",
      "['52', 'YGR152C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '3', '0.004789057269034741', '139', '919', '0.05', '0.007562568008705115', '1', 'YBR200W']\n",
      "['304', 'YDR169C', 'kinase_substrate:Reversed', 'Induced_....R.S......', '18', '4638', '5', '0.004931532484119252', '140', '919', '0.05', '0.007616974972796519', '1', 'YHR135C']\n",
      "['28', 'YPL141C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.00493164794129079', '141', '919', '0.05', '0.007671381936887923', '1', 'YOR210W']\n",
      "['61', 'YMR165C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '3', '0.005058259108615029', '142', '919', '0.05', '0.007725788900979327', '1', 'YOR351C']\n",
      "['18', 'YFL042C', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.005066140530102449', '143', '919', '0.05', '0.007780195865070729', '1', 'YDL145C']\n",
      "['16', 'YER165W', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.00521079465921996', '144', '919', '0.05', '0.007834602829162133', '1', 'YDR395W']\n",
      "['16', 'YJL176C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.00521079465921996', '144', '919', '0.05', '0.007834602829162133', '1', 'YDR073W']\n",
      "['16', 'YER165W', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.00521079465921996', '144', '919', '0.05', '0.007834602829162133', '1', 'YGL044C']\n",
      "['29', 'YHL007C', 'kinase_substrate', 'Induced_...R..TP.....', '18', '4638', '2', '0.005428932870963226', '145', '919', '0.05', '0.007889009793253536', '1', 'YGL245W']\n",
      "['8', 'YBR059C', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.005442529153694207', '146', '919', '0.05', '0.00794341675734494', '1', 'YOL066C']\n",
      "['8', 'YLR386W', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.005442529153694207', '146', '919', '0.05', '0.00794341675734494', '1', 'YFR019W']\n",
      "['202', 'YDR169C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '5', '0.005496967162414307', '147', '919', '0.05', '0.007997823721436344', '1', 'YGL180W']\n",
      "['63', 'YNL027W', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '3', '0.005538216303540582', '148', '919', '0.05', '0.008052230685527748', '1', 'YMR216C']\n",
      "['55', 'YFL013C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '3', '0.005608735904737472', '149', '919', '0.05', '0.008106637649619152', '1', 'YDR225W']\n",
      "['29', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.005610986261819242', '150', '919', '0.05', '0.008161044613710556', '1', 'YNL027W']\n",
      "['19', 'YMR291W', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.005641092945006173', '151', '919', '0.05', '0.00821545157780196', '1', 'YGL137W']\n",
      "['15', 'YIR006C', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.005704303293198689', '152', '919', '0.05', '0.008269858541893363', '1', 'YNL084C']\n",
      "['15', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.005704303293198689', '152', '919', '0.05', '0.008269858541893363', '1', 'YMR196W']\n",
      "['15', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.005704303293198689', '152', '919', '0.05', '0.008269858541893363', '1', 'YCR030C']\n",
      "['15', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.005704303293198689', '152', '919', '0.05', '0.008269858541893363', '1', 'YDR188W']\n",
      "['15', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.005704303293198689', '152', '919', '0.05', '0.008269858541893363', '1', 'YER155C']\n",
      "['15', 'YIL095W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.005704303293198689', '152', '919', '0.05', '0.008269858541893363', '1', 'YGL051W']\n",
      "['15', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.005704303293198689', '152', '919', '0.05', '0.008269858541893363', '1', 'YDR153C']\n",
      "['30', 'YDR189W', 'ppi', 'Induced_....R.S......', '18', '4638', '2', '0.005803377679430138', '153', '919', '0.05', '0.008324265505984767', '1', 'YIL004C']\n",
      "['17', 'YNL020C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.005880227801147508', '154', '919', '0.05', '0.00837867247007617', '1', 'YNL243W']\n",
      "['26', 'YKL171W', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '3', '0.005907897733630982', '155', '919', '0.05', '0.008433079434167573', '1', 'YGR276C']\n",
      "['26', 'YJR059W', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '3', '0.005907897733630982', '155', '919', '0.05', '0.008433079434167573', '1', 'YGL008C']\n",
      "['26', 'YGL049C', 'ppi', 'Induced_...R..S......', '67', '4638', '3', '0.005907897733630982', '155', '919', '0.05', '0.008433079434167573', '1', 'YHL034C']\n",
      "['51', 'YBR273C', 'ppi', 'Induced_...R..S......', '67', '4638', '4', '0.005971074788264725', '156', '919', '0.05', '0.008487486398258977', '1', 'YDL126C']\n",
      "['5', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YKR100C']\n",
      "['5', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YML080W']\n",
      "['5', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YNR039C']\n",
      "['5', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YOR070C']\n",
      "['5', 'YPL141C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YJR142W']\n",
      "['5', 'YPR173C', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YKL002W']\n",
      "['5', 'YLL021W', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YER149C']\n",
      "['5', 'YPL141C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YJR105W']\n",
      "['5', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.006003331953372931', '157', '919', '0.05', '0.00854189336235038', '1', 'YDR251W']\n",
      "['47', 'YMR165C', 'kinase_substrate:Reversed', 'Induced_......SP.....', '117', '4638', '5', '0.006174697687064548', '158', '919', '0.05', '0.008596300326441784', '1', 'YGR052W']\n",
      "['47', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '5', '0.006174697687064548', '158', '919', '0.05', '0.008596300326441784', '1', 'YNL272C']\n",
      "['47', 'YNR006W', 'kinase_substrate:Reversed', 'Induced_......SP.....', '117', '4638', '5', '0.006174697687064548', '158', '919', '0.05', '0.008596300326441784', '1', 'YOL100W']\n",
      "['18', 'YFL013C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '2', '0.00618938938931956', '159', '919', '0.05', '0.008650707290533188', '1', 'YOR189W']\n",
      "['31', 'YBR059C', 'ppi', 'Induced_....R.S......', '18', '4638', '2', '0.00618938938934002', '160', '919', '0.05', '0.008705114254624592', '1', 'YBL105C']\n",
      "['57', 'YKL054C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '3', '0.006199317959092463', '161', '919', '0.05', '0.008759521218715996', '1', 'YOL012C']\n",
      "['20', 'YOL139C', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.006244570999287079', '162', '919', '0.05', '0.0088139281828074', '1', 'YOR361C']\n",
      "['27', 'YFR015C', 'ppi', 'Induced_...R..S......', '67', '4638', '3', '0.006578425014344109', '163', '919', '0.05', '0.008868335146898804', '1', 'YLR258W']\n",
      "['21', 'YHL007C', 'kinase_substrate', 'Induced_......TP.....', '28', '4638', '2', '0.006876234564179528', '164', '919', '0.05', '0.008922742110990206', '1', 'YBR108W']\n",
      "['19', 'YHL007C', 'kinase_substrate', 'Induced_...K..SP.....', '31', '4638', '2', '0.00688887465245048', '165', '919', '0.05', '0.00897714907508161', '1', 'YGR159C']\n",
      "['16', 'YNL298W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.006892907023269678', '166', '919', '0.05', '0.009031556039173013', '1', 'YKL023W']\n",
      "['16', 'YGR240C', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.006892907023269678', '166', '919', '0.05', '0.009031556039173013', '1', 'YPL140C']\n",
      "['16', 'YNL298W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.006892907023269678', '166', '919', '0.05', '0.009031556039173013', '1', 'YHR056C']\n",
      "['304', 'YDL189W', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '6', '0.006903330161782229', '167', '919', '0.05', '0.009085963003264417', '1', 'YBR160W']\n",
      "['9', 'YBL047C', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.006932533180668766', '168', '919', '0.05', '0.009140369967355821', '1', 'YGR241C']\n",
      "['9', 'YKL171W', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '2', '0.006932533180668766', '168', '919', '0.05', '0.009140369967355821', '1', 'YNL167C']\n",
      "['31', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.007151266311797181', '169', '919', '0.05', '0.009194776931447225', '1', 'YGL190C']\n",
      "['31', 'YBL047C', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.007151266311797181', '169', '919', '0.05', '0.009194776931447225', '1', 'YBL105C']\n",
      "['31', 'YAL017W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.007151266311797181', '169', '919', '0.05', '0.009194776931447225', '1', 'YKL168C']\n",
      "['113', 'YJL128C', 'kinase_substrate:Reversed', 'Induced_......SP.....', '117', '4638', '8', '0.00727444753771413', '170', '919', '0.05', '0.009249183895538629', '1', 'YPL153C']\n",
      "['107', 'YOR304W', 'ppi', 'Induced_...R..TP.....', '18', '4638', '3', '0.00756957610882562', '171', '919', '0.05', '0.009303590859630033', '1', 'YBR009C']\n",
      "['20', 'YOR054C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '2', '0.007622584567937737', '172', '919', '0.05', '0.009357997823721436', '1', 'YML016C']\n",
      "['108', 'YOR304W', 'ppi', 'Induced_...R..TP.....', '18', '4638', '3', '0.0077669493247910625', '173', '919', '0.05', '0.009412404787812842', '1', 'YNL030W']\n",
      "['35', 'YHL007C', 'kinase_substrate', 'Induced_...R..TP.....', '18', '4638', '2', '0.007847408773271839', '174', '919', '0.05', '0.009466811751904246', '1', 'YBR154C']\n",
      "['212', 'YMR291W', 'kinase_substrate', 'Induced_......TP.....', '28', '4638', '5', '0.007906598641778168', '175', '919', '0.05', '0.009521218715995648', '1', 'YJR059W']\n",
      "['29', 'YNL049C', 'ppi', 'Induced_...R..S......', '67', '4638', '3', '0.008050916751832376', '176', '919', '0.05', '0.009575625680087052', '1', 'YPR181C']\n",
      "['61', 'YBL007C', 'kinase_substrate:Reversed', 'Induced_...K..S......', '32', '4638', '3', '0.00818727079754198', '177', '919', '0.05', '0.009630032644178456', '1', 'YOR351C']\n",
      "['17', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.008217806724285862', '178', '919', '0.05', '0.00968443960826986', '1', 'YIL135C']\n",
      "['17', 'YCR077C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.008217806724285862', '178', '919', '0.05', '0.00968443960826986', '1', 'YIL033C']\n",
      "['23', 'YFL042C', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.008222771759518889', '179', '919', '0.05', '0.009738846572361263', '1', 'YNL287W']\n",
      "['23', 'YNL027W', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.008222771759518889', '179', '919', '0.05', '0.009738846572361263', '1', 'YOL128C']\n",
      "['116', 'YDR028C', 'ppi', 'Induced_......SP.....', '117', '4638', '8', '0.008484282815648716', '180', '919', '0.05', '0.009793253536452667', '1', 'YER133W']\n",
      "['62', 'YJR072C', 'ppi', 'Induced_...K..S......', '32', '4638', '3', '0.008563569111056', '181', '919', '0.05', '0.009847660500544071', '1', 'YGR218W']\n",
      "['10', 'YGL253W', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.008585249896373236', '182', '919', '0.05', '0.009902067464635475', '1', 'YKL038W']\n",
      "['10', 'YLR258W', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.008585249896373236', '182', '919', '0.05', '0.009902067464635475', '1', 'YIL045W']\n",
      "['37', 'YGR162W', 'ppi', 'Induced_....R.S......', '18', '4638', '2', '0.008743626259214463', '183', '919', '0.05', '0.009956474428726879', '1', 'YLR116W']\n",
      "['30', 'YGL197W', 'ppi', 'Induced_...R..S......', '67', '4638', '3', '0.008854155484119388', '184', '919', '0.05', '0.010010881392818282', '1', 'YLR377C']\n",
      "['6', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YKR041W']\n",
      "['6', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YKL114C']\n",
      "['6', 'YLR319C', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YOL112W']\n",
      "['6', 'YMR109W', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YHR114W']\n",
      "['6', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YFL050C']\n",
      "['6', 'YML100W', 'ppi', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YDR074W']\n",
      "['6', 'YPL150W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YDL128W']\n",
      "['6', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YHL021C']\n",
      "['6', 'YJR059W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YFL054C']\n",
      "['6', 'YHR135C', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '2', '0.008856951225875126', '185', '919', '0.05', '0.010065288356909684', '1', 'YMR081C']\n",
      "['21', 'YJL176C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.008925078458961679', '186', '919', '0.05', '0.010119695321001088', '1', 'YPR034W']\n",
      "['21', 'YJL176C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.008925078458961679', '186', '919', '0.05', '0.010119695321001088', '1', 'YMR033W']\n",
      "['21', 'YNL020C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.008925078458961679', '186', '919', '0.05', '0.010119695321001088', '1', 'YFR024C-A']\n",
      "['24', 'YMR196W', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.008936979122647702', '187', '919', '0.05', '0.010174102285092492', '1', 'YNL020C']\n",
      "['33', 'YAL017W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.008947777105504866', '188', '919', '0.05', '0.010228509249183896', '1', 'YDL153C']\n",
      "['33', 'YLL021W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.008947777105504866', '188', '919', '0.05', '0.010228509249183896', '1', 'YOR231W']\n",
      "['52', 'YBR102C', 'ppi', 'Induced_......SP.....', '117', '4638', '5', '0.00946973451595535', '189', '919', '0.05', '0.0102829162132753', '1', 'YBR200W']\n",
      "['18', 'YOL100W', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.009682316429123136', '190', '919', '0.05', '0.010337323177366704', '1', 'YPL133C']\n",
      "['18', 'YAL017W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '3', '0.009682316429123136', '190', '919', '0.05', '0.010337323177366704', '1', 'YHL024W']\n",
      "['18', 'YBR112C', 'ppi', 'Induced_......SP.....', '117', '4638', '3', '0.009682316429123136', '190', '919', '0.05', '0.010337323177366704', '1', 'YGL181W']\n",
      "['39', 'YDR169C', 'kinase_substrate:Reversed', 'Induced_....R.S......', '18', '4638', '2', '0.009683763173441554', '191', '919', '0.05', '0.010391730141458107', '1', 'YLR248W']\n",
      "['39', 'YGR162W', 'ppi', 'Induced_....R.S......', '18', '4638', '2', '0.009683763173441554', '191', '919', '0.05', '0.010391730141458107', '1', 'YKL074C']\n",
      "['298', 'YNL074C', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '10', '0.009688677195182986', '192', '919', '0.05', '0.010446137105549511', '1', 'YJL164C']\n",
      "['26', 'YJL057C', 'ppi', 'Induced_...RR.S......', '27', '4638', '2', '0.009732867064387954', '193', '919', '0.05', '0.010500544069640915', '1', 'YGR167W']\n",
      "['22', 'YOL123W', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.009775544539831973', '194', '919', '0.05', '0.010554951033732319', '1', 'YMR080C']\n",
      "['22', 'YNR051C', 'ppi', 'Induced_...K..S......', '32', '4638', '2', '0.009775544539831973', '194', '919', '0.05', '0.010554951033732319', '1', 'YBR034C']\n",
      "['34', 'YBR079C', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.009947065527840741', '195', '919', '0.05', '0.010609357997823723', '1', 'YIL106W']\n",
      "['23', 'YFL013C', 'ppi', 'Induced_...K..SP.....', '31', '4638', '2', '0.010024499718507105', '196', '919', '0.05', '0.010663764961915125', '1', 'YDL002C']\n",
      "['202', 'YOR123C', 'kinase_substrate:Reversed', 'Induced_...K..SP.....', '31', '4638', '5', '0.010048188318409246', '197', '919', '0.05', '0.010718171926006529', '1', 'YGL180W']\n",
      "['40', 'YDR189W', 'ppi', 'Induced_....R.S......', '18', '4638', '2', '0.010170096145558015', '198', '919', '0.05', '0.010772578890097933', '1', 'YLR268W']\n",
      "['79', 'YIL135C', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '3', '0.010367326123322121', '199', '919', '0.05', '0.010826985854189336', '1', 'YJL106W']\n",
      "['11', 'YKL168C', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.010395810343153603', '200', '919', '0.05', '0.01088139281828074', '1', 'YJL138C']\n",
      "['11', 'YBR059C', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '2', '0.010395810343153603', '200', '919', '0.05', '0.01088139281828074', '1', 'YKR092C']\n",
      "['11', 'YNL267W', 'ppi', 'Induced_...R..S......', '67', '4638', '2', '0.010395810343153603', '200', '919', '0.05', '0.01088139281828074', '1', 'YDR170C']\n",
      "['11', 'YJR059W', 'kinase_substrate', 'Induced_...R..S......', '67', '4638', '2', '0.010395810343153603', '200', '919', '0.05', '0.01088139281828074', '1', 'YHR207C']\n",
      "['26', 'YHR066W', 'ppi', 'Induced_......TP.....', '28', '4638', '2', '0.010445626404497277', '201', '919', '0.05', '0.010935799782372144', '1', 'YNL002C']\n",
      "['27', 'YNR031C', 'ppi', 'Induced_...RR.S......', '27', '4638', '2', '0.01047397605190116', '202', '919', '0.05', '0.010990206746463548', '1', 'YCR073C']\n",
      "['237', 'YMR184W', 'kinase_substrate:Reversed', 'Induced_...RR.S......', '27', '4638', '5', '0.010699077097682436', '203', '919', '0.05', '0.011044613710554952', '1', 'YNL154C']\n",
      "['35', 'YDL065C', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.011016159347841182', '204', '919', '0.05', '0.011099020674646356', '1', 'YOR326W']\n",
      "['35', 'YOL036W', 'ppi', 'Induced_......SP.....', '117', '4638', '4', '0.011016159347841182', '204', '919', '0.05', '0.011099020674646356', '1', 'YNL161W']\n",
      "['35', 'YNL298W', 'kinase_substrate', 'Induced_......SP.....', '117', '4638', '4', '0.011016159347841182', '204', '919', '0.05', '0.011099020674646356', '1', 'YJR076C']\n",
      "['304', 'YPL155C', 'kinase_substrate:Reversed', 'Induced_...R..S......', '67', '4638', '10', '0.0110724499810532', '205', '919', '0.05', '0.01115342763873776', '1', 'YBR160W']\n"
     ]
    }
   ],
   "source": [
    "# Prep input files\n",
    "# add group classification according to Mok to FDR_Scores.\n",
    "Mok = dict()\n",
    "with open('required/Mok_Kinase_Groups_Corrected.csv','r') as mk:\n",
    "    for kns in mk:\n",
    "        kns = kns.rstrip()\n",
    "        group = kns.split()\n",
    "        Mok[group[0]] = group[2]\n",
    "mk.close()\n",
    "\n",
    "grpName = ''\n",
    "\n",
    "with open('FDR_Scores_merged.csv', 'w') as outfile, open('FDR_Scores.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip()\n",
    "        dat = line.split()\n",
    "        if line.startswith('\\tScores'):               # setup header row\n",
    "            dat.insert(2,'Group (According to Mok)')\n",
    "            out = ','.join(dat) + '\\n'\n",
    "            outfile.write(out)\n",
    "            continue\n",
    "        if dat[2] in Mok:\n",
    "            grpName = dat[3]\n",
    "            dat.insert(3,Mok[dat[2]])\n",
    "            dat.pop(0)                 # removes data frame column number\n",
    "            out = ','.join(dat) + '\\n'\n",
    "            outfile.write(out)\n",
    "        else:\n",
    "            dat.insert(3, grpName)\n",
    "            dat.pop(0)                 # removes data frame column number\n",
    "            out =','.join(dat) + '\\n'\n",
    "            outfile.write(out)\n",
    "            \n",
    "outfile.close()\n",
    "f.close()\n",
    "\n",
    "# REORDER SHARED INTERACTOR w/in the line, file Network_Submodule_Nodes_background_Network.csv\n",
    "# use FINAL_enriched.csv\n",
    "# Shared_Interactor\tM\tMotif_Containing_Proteins\tInteraction\tMotif\tn\tN\tm\tp-value\tRank(i)\tm_(number_of_tests)\tQ_(FDR)\t(i/m)Q\tBH_significant\n",
    "\n",
    "\n",
    "with open('Final_enriched.csv','r') as f, open('All_SIs.csv','w') as outfile:\n",
    "    for line in f:\n",
    "        dat = line.rstrip().split(',')\n",
    "        if line.startswith('M'):\n",
    "            dat[1] = 'Motif_Containing_Proteins'\n",
    "            dat[3] = 'Motif'\n",
    "        last = dat.pop(-1)\n",
    "        dat.insert(0,last)\n",
    "        out = ','.join(dat) + '\\n'\n",
    "        outfile.write(out)\n",
    "        \n",
    "outfile.close()\n",
    "\n",
    "# OUTPUT: FDR_Scores_merged.csv\n",
    "#         All_SIs.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge_SI_subModule_relationships_with_FDR_Scores\n",
    "\n",
    "FDR_Scores_DF input file:\n",
    "> Scores,Kinase,Group (According to Mok),Module,Counts_Less_Than,Number_of_Scores,FDR\n",
    "> 11.44097292,pho85-pho80,Proline_directed,Induced_......SP.....,0,63000,0\n",
    "> 11.92968433,fus3,Proline_directed,Induced_......SP.....,0,63000,0\n",
    " \n",
    "SIs_DF input file:\n",
    " > Shared_Interactor,M,Motif_Containing_Proteins,Interaction,Motif,n,N,m,p-value,Rank(i),m_(number_of_tests),Q_(FDR),(i/m)Q\tBH_significant\n",
    ">YBR160W,304,YOR188W,kinase_substrate:Reversed,Induced_......SP.....,117,4638,29,1.65496910697932E-10,1,919,0.05,5.44069640914037E-05\t1\n",
    "\n",
    "\n",
    "Kinase_Names_DF file: ( does not change )\n",
    "\n",
    "> Kinase,Kinase_Pho85_renamed,Kinase_YORF,Mok <br>\n",
    "> yck3,yck3,YER123W,yes <br>\n",
    "> yck1,yck1,YHR135C,yes <br>\n",
    "> yck2,yck2,YNL154C,yes <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' This script takes the output of the KLD FDR script and adds these FDR scores to the identified SI-submodule pairs. \n",
    "'''\n",
    "# FDR_Scores_merged.csv\n",
    "FDR_Scores_DF=pd.read_csv('FDR_Scores_merged.csv') # All_SIs.csv  # All FDR scores for Mok kinase and module PWM comparison\n",
    "# All_SIs.csv\n",
    "SIs_DF=pd.read_csv('All_SIs.csv')  # SIs - All, enriched and not enriched\n",
    "# DO NOT CHANGE\n",
    "Kinase_Names_DF=pd.read_csv('required/Kinases_Mok_andNOT_In_Mok.csv') # Contains all kinases in Mok and not in Mok. Contains common names and YORFs, also contains modifications for Pho85 naming (ex: Pho85-Pcl is now Pho85 in one column)\n",
    "\n",
    "def DF_to_CSV(dataframe, NewFileName):  \n",
    "    dataframe.to_csv (current_dir + '/' + NewFileName,sep=',') \n",
    "####################################################################################################################################\n",
    "''' Merging the FDR_Scores_DF with the Kinase_Names_DF '''\n",
    "# This step is completed so that the correct Pho85 nomenclature is used for a subsquent merge with the SI dataframe. This is necessary because there are 3 pho85-cofactor variants in the Mok et al, dataset.\n",
    "\n",
    "FDR_Scores_DF_merged_left = pd.merge(left=FDR_Scores_DF,right=Kinase_Names_DF, how='left', left_on='Kinase', right_on='Kinase') # completing a merge so that all the kinase nomenclature from the Kinase_Names_DF\n",
    "\n",
    "####################################################################################################################################\n",
    "''' Merge the Kinase name (common name,ex. Hog1) with the Module name to create a new column called \"Candidate_Kinase_Regulators\" '''\n",
    "\n",
    "FDR_Scores_DF_merged_left['Candidate_Kinase_Regulators'] = FDR_Scores_DF_merged_left.Module.map(str) + \"_\" + FDR_Scores_DF_merged_left.Kinase_Pho85_renamed # creating a new column that is the result of a merge between Kinase_Pho85_renamed, and Module\n",
    "#print (FDR_Scores_DF_merged_left.head(1))\n",
    "DF_to_CSV(FDR_Scores_DF_merged_left, 'yay3.csv')\n",
    "####################################################################################################################################\n",
    "''' Filtering out non-enriched SIs'''\n",
    "\n",
    "SIs_Filtered=SIs_DF.loc[SIs_DF['BH_significant'] == 1] # Filter out non-significant shared interactors (anything with a \"0\") \n",
    "\n",
    "####################################################################################################################################\n",
    "''' Adding to the SIs file, the \"common\" name for the proteins, rather than just using the YORF designation'''\n",
    "SIs_Filtered_merged_left= pd.merge(left=SIs_Filtered,right=Kinase_Names_DF, how='left', left_on='Shared_Interactor', right_on='Kinase_YORF')\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "''' Splitting 'Motif' column and producing a new column, called \"Module\" that only lists the Induced/Repressed WT phenotype and the motif '''\n",
    "\n",
    "def Split_After_2nd_Occurence_In_A_String_Retaining_Beginning():\n",
    "    lst=[] # create an empty list \n",
    "    for string in SIs_Filtered_merged_left['Motif']: # Select the string from the \"Motif\" column \n",
    "        strip_character =\"_\"  # define character where strip will occur\n",
    "        lst.append(strip_character.join(string.split(strip_character)[:2])) # append to the list the text before the second occurence of the character \"_\"\n",
    "    Series_Object = pd.Series(lst) # put the list into a series \n",
    "    SIs_Filtered_merged_left['Module'] = Series_Object.values # append the series values to the already existing DF in a new column\n",
    "    return SIs_Filtered_merged_left\n",
    "        \n",
    "SIs_Filtered_merged_left_String_Split=Split_After_2nd_Occurence_In_A_String_Retaining_Beginning()\n",
    "#print (SIs_Filtered_merged_left_String_Split)\n",
    "\n",
    "####################################################################################################################################    \n",
    "####################################################################################################################################    \n",
    "'''Creating New Columns that can be used for a merge'''\n",
    "SIs_Filtered_merged_left_String_Split['Kinase_subModules'] = SIs_Filtered_merged_left_String_Split.Motif.map(str) + \"_\" + SIs_Filtered_merged_left_String_Split.Kinase_Pho85_renamed\n",
    "\n",
    "\n",
    "SIs_Filtered_merged_left_String_Split['Kinase_Modules'] = SIs_Filtered_merged_left_String_Split.Module.map(str) + \"_\" + SIs_Filtered_merged_left_String_Split.Kinase_Pho85_renamed\n",
    "\n",
    "#################################################################################################################################### \n",
    "''' Perform a merge where of the FDR Scores Dataframe with the SIs_Filtered_merged_left_String_Split DF. \n",
    "This will reveal if a kinase-Module relationship, from the FDR Score Dataframe, which contains all possible Kinase-Module relationships, exist in the users \n",
    "kinase-subModule file (so the SIs file)'''\n",
    "    \n",
    "merged_left= pd.merge(left=FDR_Scores_DF_merged_left,right=SIs_Filtered_merged_left_String_Split, how='left', left_on='Candidate_Kinase_Regulators', right_on='Kinase_Modules')\n",
    "\n",
    "#################################################################################################################################### \n",
    "''' Drop columns that are not needed or redundant '''\n",
    "\n",
    "merged_left=merged_left[['Scores', 'Kinase_x', 'Module_x', 'Candidate_Kinase_Regulators', 'Counts_Less_Than', 'Number_of_Scores', 'FDR', 'Kinase_subModules']]\n",
    "\n",
    "#################################################################################################################################### \n",
    "''' Drop NaN values '''\n",
    "merged_left=merged_left.dropna(subset=['Kinase_subModules']) # Drop the NaN values, so that the dataframe only contains Kinases that were connected to subModules.\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "''' Drop any duplicates that occur in TWO columns - this is done only because of Pho85 being listed 3 times (because of it's co-factor interactions) and that affects the merge'''\n",
    "merged_left=merged_left.drop_duplicates(subset=['Kinase_x', 'Kinase_subModules']) # only drop duplicates that are found in BOTH columns\n",
    "\n",
    "DF_to_CSV(merged_left, 'All_FDR_Scores_and_their_Kinase_SI_subModules.csv')\n",
    "\n",
    "# OUTPUT: All_FDR_Scores_and_their_Kinase_SI_subModules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Kullback_Leibler Shuffle results\n",
    "\n",
    "Input file:\n",
    "\n",
    "> Scores,Kinase_x,Module_x,Candidate_Kinase_Regulators,Counts_Less_Than,Number_of_Scores,FDR,Kinase_subModules <br>\n",
    "> 11.02325264,cdc28,Induced_......SP.....,Induced_......SP....._cdc28,0,63000,0,Induced_......SP....._No_Phenotype_Exists_cdc28\n",
    "> 11.02325264,cdc28,Induced_......SP.....,Induced_......SP....._cdc28,0,63000,0,Induced_......SP....._mkk1_2_Induced_Defective_cdc28\n",
    "> 12.51579799,slt2,Induced_......SP.....,Induced_......SP....._slt2,1,63000,1.59E-05, Induced_......SP....._mkk1_2_Induced_Defective_slt2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                       int64\n",
      "Scores                         float64\n",
      "Kinase_x                        object\n",
      "Module_x                        object\n",
      "Candidate_Kinase_Regulators     object\n",
      "Counts_Less_Than                 int64\n",
      "Number_of_Scores                 int64\n",
      "FDR                            float64\n",
      "Kinase_subModules               object\n",
      "dtype: object\n",
      "    Unnamed: 0     Scores     Kinase_x               Module_x  \\\n",
      "0            1  17.341918         ptk2  Induced_......TP.....   \n",
      "1           20  17.102829         ark1  Induced_......TP.....   \n",
      "2           46  17.558753         pkh2  Induced_......TP.....   \n",
      "3          380  10.381472         yck1  Induced_....R.S......   \n",
      "4          389  10.311257         rck2  Induced_....R.S......   \n",
      "5          405  12.761746         atg1  Induced_....R.S......   \n",
      "6          407   9.218274  pho85-pho80  Induced_....R.S......   \n",
      "7          411   9.676206   pho85-pcl2  Induced_....R.S......   \n",
      "8          415   9.804924         ark1  Induced_....R.S......   \n",
      "9          421   9.740459   pho85-pcl1  Induced_....R.S......   \n",
      "10         429   9.777757         ptk2  Induced_....R.S......   \n",
      "11         433   9.138251         fus3  Induced_....R.S......   \n",
      "12         756  12.752640         slt2  Induced_......SP.....   \n",
      "13         762  13.389583         hog1  Induced_......SP.....   \n",
      "14         767  15.836341         tpk1  Induced_......SP.....   \n",
      "15         768  15.990376      ynr047w  Induced_......SP.....   \n",
      "16         770  15.381286         ypk2  Induced_......SP.....   \n",
      "17         772  15.291598        fmp48  Induced_......SP.....   \n",
      "18         780  11.927527        cdc28  Induced_......SP.....   \n",
      "19         785  16.559688        rad53  Induced_......SP.....   \n",
      "20         790  17.077547         pkh2  Induced_......SP.....   \n",
      "21         801  17.358822         ptk2  Induced_......SP.....   \n",
      "22         806  18.060490        cdc15  Induced_......SP.....   \n",
      "23        1160  14.627900         mek1  Induced_...K..S......   \n",
      "24        2252  14.618443         tpk1  Induced_...R..S......   \n",
      "25        2257  17.256192         mck1  Induced_...R..S......   \n",
      "26        2260  13.639093         tpk2  Induced_...R..S......   \n",
      "27        2270  15.186760         rck2  Induced_...R..S......   \n",
      "28        2285  12.803286        cdc28  Induced_...R..S......   \n",
      "29        2297  16.089359        hrr25  Induced_...R..S......   \n",
      "30        2302  16.231045         ptk2  Induced_...R..S......   \n",
      "31        2676  18.483995         atg1  Induced_...K..SP.....   \n",
      "32        2999  14.316517         tpk1  Induced_...RR.S......   \n",
      "33        3002  13.753529         sky1  Induced_...RR.S......   \n",
      "34        3006  13.305038         tpk2  Induced_...RR.S......   \n",
      "35        3014  15.074008         rck2  Induced_...RR.S......   \n",
      "36        3019  16.385032         ptk2  Induced_...RR.S......   \n",
      "37        3023  14.830398         mek1  Induced_...RR.S......   \n",
      "38        3028  13.433954        cdc28  Induced_...RR.S......   \n",
      "39        3030  16.725896         tos3  Induced_...RR.S......   \n",
      "40        3040  16.546797         yck2  Induced_...RR.S......   \n",
      "41        3045  17.626105         mck1  Induced_...RR.S......   \n",
      "42        3049  18.077707         cmk1  Induced_...RR.S......   \n",
      "43        3050  18.208192         atg1  Induced_...RR.S......   \n",
      "\n",
      "      Candidate_Kinase_Regulators  Counts_Less_Than  Number_of_Scores  \\\n",
      "0      Induced_......TP....._ptk2                 0              1575   \n",
      "1      Induced_......TP....._ark1                 0              1575   \n",
      "2      Induced_......TP....._pkh2                 2              1575   \n",
      "3      Induced_....R.S......_yck1                 0              1575   \n",
      "4      Induced_....R.S......_rck2                 0              1575   \n",
      "5      Induced_....R.S......_atg1                20              1575   \n",
      "6     Induced_....R.S......_pho85              1575              1575   \n",
      "7     Induced_....R.S......_pho85              1575              1575   \n",
      "8      Induced_....R.S......_ark1              1575              1575   \n",
      "9     Induced_....R.S......_pho85              1575              1575   \n",
      "10     Induced_....R.S......_ptk2              1575              1575   \n",
      "11     Induced_....R.S......_fus3              1575              1575   \n",
      "12     Induced_......SP....._slt2                 0              1575   \n",
      "13     Induced_......SP....._hog1                 0              1575   \n",
      "14     Induced_......SP....._tpk1                 0              1575   \n",
      "15  Induced_......SP....._ynr047w                 0              1575   \n",
      "16     Induced_......SP....._ypk2                 0              1575   \n",
      "17    Induced_......SP....._fmp48                 0              1575   \n",
      "18    Induced_......SP....._cdc28                 0              1575   \n",
      "19    Induced_......SP....._rad53                 1              1575   \n",
      "20     Induced_......SP....._pkh2                 2              1575   \n",
      "21     Induced_......SP....._ptk2                 3              1575   \n",
      "22    Induced_......SP....._cdc15                 6              1575   \n",
      "23     Induced_...K..S......_mek1                 0              1575   \n",
      "24     Induced_...R..S......_tpk1                 0              1575   \n",
      "25     Induced_...R..S......_mck1                 0              1575   \n",
      "26     Induced_...R..S......_tpk2                 0              1575   \n",
      "27     Induced_...R..S......_rck2                 0              1575   \n",
      "28    Induced_...R..S......_cdc28                 0              1575   \n",
      "29    Induced_...R..S......_hrr25                 0              1575   \n",
      "30     Induced_...R..S......_ptk2                 0              1575   \n",
      "31     Induced_...K..SP....._atg1                 2              1575   \n",
      "32     Induced_...RR.S......_tpk1                 0              1575   \n",
      "33     Induced_...RR.S......_sky1                 0              1575   \n",
      "34     Induced_...RR.S......_tpk2                 0              1575   \n",
      "35     Induced_...RR.S......_rck2                 0              1575   \n",
      "36     Induced_...RR.S......_ptk2                 0              1575   \n",
      "37     Induced_...RR.S......_mek1                 0              1575   \n",
      "38    Induced_...RR.S......_cdc28                 0              1575   \n",
      "39     Induced_...RR.S......_tos3                 0              1575   \n",
      "40     Induced_...RR.S......_yck2                 0              1575   \n",
      "41     Induced_...RR.S......_mck1                 1              1575   \n",
      "42     Induced_...RR.S......_cmk1                 3              1575   \n",
      "43     Induced_...RR.S......_atg1                 3              1575   \n",
      "\n",
      "         FDR      Kinase_subModules  \n",
      "0   0.000000  Induced_......TP.....  \n",
      "1   0.000000  Induced_......TP.....  \n",
      "2   0.001270  Induced_......TP.....  \n",
      "3   0.000000  Induced_....R.S......  \n",
      "4   0.000000  Induced_....R.S......  \n",
      "5   0.012698  Induced_....R.S......  \n",
      "6   1.000000  Induced_....R.S......  \n",
      "7   1.000000  Induced_....R.S......  \n",
      "8   1.000000  Induced_....R.S......  \n",
      "9   1.000000  Induced_....R.S......  \n",
      "10  1.000000  Induced_....R.S......  \n",
      "11  1.000000  Induced_....R.S......  \n",
      "12  0.000000  Induced_......SP.....  \n",
      "13  0.000000  Induced_......SP.....  \n",
      "14  0.000000  Induced_......SP.....  \n",
      "15  0.000000  Induced_......SP.....  \n",
      "16  0.000000  Induced_......SP.....  \n",
      "17  0.000000  Induced_......SP.....  \n",
      "18  0.000000  Induced_......SP.....  \n",
      "19  0.000635  Induced_......SP.....  \n",
      "20  0.001270  Induced_......SP.....  \n",
      "21  0.001905  Induced_......SP.....  \n",
      "22  0.003810  Induced_......SP.....  \n",
      "23  0.000000  Induced_...K..S......  \n",
      "24  0.000000  Induced_...R..S......  \n",
      "25  0.000000  Induced_...R..S......  \n",
      "26  0.000000  Induced_...R..S......  \n",
      "27  0.000000  Induced_...R..S......  \n",
      "28  0.000000  Induced_...R..S......  \n",
      "29  0.000000  Induced_...R..S......  \n",
      "30  0.000000  Induced_...R..S......  \n",
      "31  0.001270  Induced_...K..SP.....  \n",
      "32  0.000000  Induced_...RR.S......  \n",
      "33  0.000000  Induced_...RR.S......  \n",
      "34  0.000000  Induced_...RR.S......  \n",
      "35  0.000000  Induced_...RR.S......  \n",
      "36  0.000000  Induced_...RR.S......  \n",
      "37  0.000000  Induced_...RR.S......  \n",
      "38  0.000000  Induced_...RR.S......  \n",
      "39  0.000000  Induced_...RR.S......  \n",
      "40  0.000000  Induced_...RR.S......  \n",
      "41  0.000635  Induced_...RR.S......  \n",
      "42  0.001905  Induced_...RR.S......  \n",
      "43  0.001905  Induced_...RR.S......  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mplace/anaconda3/lib/python3.4/site-packages/ipykernel/__main__.py:40: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' This is a quick script that cleans up the Output of the Kullback_Leibler Shuffle Script.\n",
    "It removes unwanted names that trail the subModule name-these are leftovers from a previous\n",
    "script. It then also sorts each subModule by ascending for the SI scores\n",
    "'''\n",
    "# Input=pd.read_csv('All_DTT_T120_Kinase_Module_FDR_Scores_and_their_Kinase_SI_subModules_Sept2017.csv')\n",
    "Input=pd.read_csv('All_FDR_Scores_and_their_Kinase_SI_subModules.csv')\n",
    "#print (Input.dtypes)\n",
    "\n",
    "# Remove the last occurrence of a character, and the text that follows\n",
    "def Remove_Text_After_Last_Occurence_of_Character():\n",
    "    Value_lst=[]\n",
    "    for value in Input['Kinase_subModules']:\n",
    "        value=\"_\".join(value.split(\"_\")[:-1]) # return everything minus the last occurrence of the \"_\" and what trailed\n",
    "        Value_lst.append(value)\n",
    "    Input['Kinase_subModules']=Value_lst\n",
    "        #sep = '_'\n",
    "        #value = value.split(sep, 5)[-1]\n",
    "    return (Input)\n",
    "        \n",
    "        \n",
    "Input=Remove_Text_After_Last_Occurence_of_Character()\n",
    "#print (Input)\n",
    "\n",
    "#Split the dataframe into separate dataframes by the subModule name\n",
    "def SplitInput_df_by_subModule():\n",
    "    DF_Input_lst =[]\n",
    "    for subModule in Input['Kinase_subModules'].unique():\n",
    "        DF=Input.loc[Input['Kinase_subModules']==subModule]\n",
    "        DF_Input_lst.append(DF)\n",
    "    return DF_Input_lst\n",
    "\n",
    "DF_Input_lst=SplitInput_df_by_subModule()\n",
    "\n",
    "#Sort each dataframe within the list of dataframes by ascending for the FDR column\n",
    "def Sort_by_Ascending():\n",
    "    DF_Input_lst2=[]\n",
    "    for DF in DF_Input_lst:\n",
    "        DF=DF.copy()\n",
    "        DF=DF.sort(['FDR'], ascending=[True])\n",
    "        DF_Input_lst2.append(DF)\n",
    "    return DF_Input_lst2\n",
    "\n",
    "DF_Input_lst2=Sort_by_Ascending()\n",
    "\n",
    "\n",
    "\n",
    "#Concatenate the dataframes back together into one so they can be printed out as a single dataframe.\n",
    "def ConcatenateDFs():    #Concatenate the DFs together \n",
    "    EmptyDF = pd.DataFrame() # create an empty dataframe\n",
    "    for df in DF_Input_lst2:  # select a dataframe in the list \n",
    "        df=df.copy() # make a copy of that dataframe \n",
    "        EmptyDF=EmptyDF.append(df) # append to the empty DF the dataframe selected and overwrite the empty dataframe\n",
    "    return EmptyDF\n",
    "\n",
    "Final=ConcatenateDFs()\n",
    "#print (Final)\n",
    "\n",
    "\n",
    "def DF_to_CSV(dataframe, NewFileName): \n",
    "    dataframe.to_csv (NewFileName,sep='\\t')\n",
    "    \n",
    "DF_to_CSV(Final, 'All_Module_FDR_Scores__Kinase_SI_subModules_Sorted.csv')\n",
    "\n",
    "# OUTPUT: All_Module_FDR_Scores__Kinase_SI_subModules_Sorted.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up All_SIs.csv from Prep Merge_SI_subModule_relationships_with_FDR_Scores step\n",
    "with open('All_SIs.csv','r') as f, open('only_enriched.csv','w') as outfile :\n",
    "    for line in f:\n",
    "        dat = line.rstrip().split(',')\n",
    "        if line.startswith('Shared'):\n",
    "            dat.pop(4)\n",
    "            dat[3] = 'subModule'\n",
    "        else:\n",
    "            dat[3],dat[4] = dat[4],dat[3]\n",
    "            dat[3] += dat[4]\n",
    "            dat.pop(4)\n",
    "        out = ','.join(dat) + '\\n'\n",
    "        outfile.write(out)\n",
    "\n",
    "f.close()\n",
    "outfile.close()\n",
    "        \n",
    "# OUTPUT: only_enriched.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remake the header for SI_Identification_SubmoduleS__SIs_and_Targets_FDR.csv (from Identify Shared Interactors step)\n",
    "# for the next script\n",
    "with open('SI_Identification_SubmoduleS__SIs_and_Targets_FDR.csv', 'r') as f, open('shared_Interactors.csv', 'w') as out:\n",
    "    f.readline()\n",
    "    newHeader = 'Motif_Containing_Proteins,Interaction,subModule,n,Possible_Shared_Interactors\\n'\n",
    "    out.write(newHeader)\n",
    "    for line in f:\n",
    "        out.write(line)\n",
    "f.close()\n",
    "out.close()    \n",
    "\n",
    "# OUTPUT: shared_Interactors.csv \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "''' \n",
    "\n",
    "The purpose of this script is to identify for each enriched SI (according to the hypergeometric and BH correction)\n",
    "what it's interacting proteins, and potential \"targets\"  are in the background network. Next, \n",
    "the script identifies the correct orientation for interactions between a Shared Interactor and it's \n",
    "partners, which are reversed in an earlier script. Thus, the script ensures all interactions are in \n",
    "the correct orientation. \n",
    "\n",
    "The output file from this script can then be used to determine if a Shared Interactor is acting as an input (all interactions going towards a subModule, or is an output (interactions go away), etc. An input is a potential regulator of a submodule whereas an output is unlikely to regulate a submodoule.\n",
    "\n",
    "'''\n",
    "##################################################################################################################################\n",
    "# FDR_Scores_merged.csv\n",
    "#Enriched_SIs_subModules_Only_Sig=pd.read_csv('DTT_T120_SIs_All_Sept2017_Enriched.csv')  # Import ONLY enriched SIs (drop non-enriched SIs)\n",
    "Enriched_SIs_subModules_Only_Sig=pd.read_csv('only_enriched.csv')  \n",
    "Enriched_SIs_subModules_Only_Sig[\"SI_subModule\"] = Enriched_SIs_subModules_Only_Sig[\"Shared_Interactor\"].map(str) + \"_\" + Enriched_SIs_subModules_Only_Sig[\"subModule\"] # creating a new column by merging two columns together.\n",
    "\n",
    "\n",
    "# I think this is from SI_Identification_SubmoduleS__SIs_and_Targets_FDR.csv  from step Identify Shared Interactors\n",
    "#All_enriched_and_not_SIs_andTargets=pd.read_csv('SI_Identification_T120_DTT_Sept2017_T120_Possible_SIs_and_Targets_Dashes_Removed_4638_proteins_BOTH_Reps_Ppeps_NORMALIZED.csv') # Import all identified Shared Interactors (both enriched and not) and their interacting partners from submodules.\n",
    "All_enriched_and_not_SIs_andTargets=pd.read_csv('shared_Interactors.csv')\n",
    "\n",
    "All_enriched_and_not_SIs_andTargets[\"SI_subModule\"] = All_enriched_and_not_SIs_andTargets[\"Possible_Shared_Interactors\"].map(str) + \"_\" + All_enriched_and_not_SIs_andTargets[\"subModule\"]\n",
    "\n",
    "Merged_left = pd.merge(left=Enriched_SIs_subModules_Only_Sig,right=All_enriched_and_not_SIs_andTargets, how='left', left_on='SI_subModule', right_on='SI_subModule') # \n",
    "\n",
    "Merged_left_FINAL=Merged_left[['SI_subModule', 'Shared_Interactor', 'Motif_Containing_Proteins_y', 'subModule_y']] # retain these columns only\n",
    "Merged_left_FINAL.columns=['SI_Module','Shared_Interactor', 'Motif_Containing_Proteins', 'subModule_Name'] # rename columns\n",
    "\n",
    "\n",
    "\n",
    "def DF_to_CSV(dataframe, NewFileName): \n",
    "    dataframe.to_csv (NewFileName,sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "''' Add the SI common name to the file  FILE DOES NOT CHANGE'''\n",
    "Annotation_File_DF=pd.read_csv('required/Annotation_file_dashes_remain_No_duplicate_Common_names.csv') \n",
    "\n",
    "Merged_left_Again = pd.merge(left=Merged_left_FINAL,right=Annotation_File_DF, how='left', left_on='Shared_Interactor', right_on='Protein_Name') # complete the merge toget the common names\n",
    "Merged_left_Again=Merged_left_Again[['SI_Module', 'Shared_Interactor', 'Common_Name', 'Motif_Containing_Proteins', 'subModule_Name']] # retain only these columns\n",
    "Merged_left_Again.columns=['SI_Module', 'Shared_Interactor', 'SI_Name', 'Motif_Containing_Proteins', 'subModule_Name'] # rename columns \n",
    "\n",
    "Merged_left_Again['Protein1:Protein2']=Merged_left_Again['Shared_Interactor'].map(str) + \":\" + Merged_left_Again['Motif_Containing_Proteins'] # adding column for merge section below.\n",
    "\n",
    "Merged_left_Again['Protein1:Protein2'] = Merged_left_Again['Protein1:Protein2'].str.replace('-', '') # Removing the dashes from the names because if they remain in this column, the merge below will fail, because the background network lacks dashes in the gene annotations. \n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "'''FILE DOES NOT CHANGE from Debbi Chasman'''\n",
    "Background_network_correct_Orientation=pd.read_csv('required/phospho_v4_bgnet_siflike_withdirections_fix_Matt_Modifications_ForPipeline.csv') # import the salt background network with the correct orientations (this file lacks dashes in gene annotations!)\n",
    "\n",
    "Merged_left_Again_Get_Correct_Protein_Orientiations=pd.merge(left=Merged_left_Again, right=Background_network_correct_Orientation, how='left', left_on='Protein1:Protein2', right_on='Protein1:Protein2') # merge based on the columns to the left\n",
    "\n",
    "Merged_left_Again_Get_Correct_Protein_Orientiations=Merged_left_Again_Get_Correct_Protein_Orientiations[['SI_Module', 'Shared_Interactor', 'SI_Name', 'Motif_Containing_Proteins', 'subModule_Name','Interaction']] # retain only these columns\n",
    "\n",
    "\n",
    "Merged_left_Again_Get_Correct_Protein_Orientiations.columns=['SI_Module', 'Shared_Interactor', 'SI_name', 'Motif_Containing_Proteins', 'subModule_Name','Interaction_Directionality'] # rename columns \n",
    "#print (Merged_left_Again_Get_Correct_Protein_Orientiations.head(2))\n",
    "\n",
    "DF_to_CSV(Merged_left_Again_Get_Correct_Protein_Orientiations, 'Orientation_Script.csv')\n",
    "\n",
    "# OUTPUT:  Orientation_Script.csv  this one of the inputs to the next script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = set()\n",
    "with open('Orientation_Script.csv') as f:\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          SI_Module  \\\n",
      "0           0  YBR160W_Induced_......SP.....kinase_substrate:...   \n",
      "1           1  YBR160W_Induced_......SP.....kinase_substrate:...   \n",
      "2           2  YBR160W_Induced_......SP.....kinase_substrate:...   \n",
      "3           3  YBR160W_Induced_......SP.....kinase_substrate:...   \n",
      "4           4  YBR160W_Induced_......SP.....kinase_substrate:...   \n",
      "\n",
      "  Shared_Interactor SI_name  Motif_Containing_Proteins  subModule_Name  \\\n",
      "0           YBR160W   CDC28                        NaN             NaN   \n",
      "1           YBR160W   CDC28                        NaN             NaN   \n",
      "2           YBR160W   CDC28                        NaN             NaN   \n",
      "3           YBR160W   CDC28                        NaN             NaN   \n",
      "4           YBR160W   CDC28                        NaN             NaN   \n",
      "\n",
      "   Interaction_Directionality  \n",
      "0                         NaN  \n",
      "1                         NaN  \n",
      "2                         NaN  \n",
      "3                         NaN  \n",
      "4                         NaN  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values, which use np.object_ dtype in pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-1698ecb838e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mDF_Counts_lst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mDF_Counts_lst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCount_Instances_of_Reverse_Interaction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mDF_Counts_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-1698ecb838e7>\u001b[0m in \u001b[0;36mCount_Instances_of_Reverse_Interaction\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDF_lst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Counts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteraction_Directionality\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reversed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Count the number of interactions that are \"Reversed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mplace/anaconda3/lib/python3.4/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2738\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[0;32m   2739\u001b[0m                 name in self._accessors):\n\u001b[1;32m-> 2740\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mplace/anaconda3/lib/python3.4/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;31m# this ensures that Series.str.<method> is well defined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccessor_cls\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mplace/anaconda3/lib/python3.4/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_make_str_accessor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1839\u001b[0m             \u001b[1;31m# (instead of test for object dtype), but that isn't practical for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[1;31m# performance reasons until we have a str dtype (GH 9343)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1841\u001b[1;33m             raise AttributeError(\"Can only use .str accessor with string \"\n\u001b[0m\u001b[0;32m   1842\u001b[0m                                  \u001b[1;34m\"values, which use np.object_ dtype in \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m                                  \"pandas\")\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values, which use np.object_ dtype in pandas"
     ]
    }
   ],
   "source": [
    "''' \n",
    "The function of this script is as follows: For each SI and it's interactions a submodules constituents,\n",
    "the script determines if the SI is a likely submodule regulator, the Shared Interactor has at least 1 \n",
    "directional interaction, or ppi interaction, with a subModule protein aimed from the SI to the submodule,\n",
    "or if the subModule proteins are act upon the SI , all interactions between the SI and subModule proteins\n",
    "have the 'Reverse' designation', indicating that the subModule proteins act upon the SI.  \n",
    "\n",
    "-If all of the interactions are reversed, then the script will define the relationship between the SI and the subModule\n",
    "as \"Output\", indicating that the SI is likely downstream of the submodule and is not likely regulating the submodule.\n",
    "\n",
    "-If there is at least one interaction that is NOT reverse (ie, kinase-substrate) or is and non-directed ppi, \n",
    "the relationship between the SI and the subMOdule is defined as \"Input\", suggesting there is a possibility \n",
    "that the SI can regulate the submodule protein phosphorylation state.\n",
    "\n",
    "\n",
    "This script takes an input file that contains the following:\n",
    "- All enriched Shared Interactors (SIs) (according to HyperG) and their connections to subModules.\n",
    "- All known protein interactions for each SI (ppi, kinase-substrate, etc)\n",
    "- Many of these interactions are directed (kinase-substrate, metabolic pathway, etc). PPI are not a directed interaction.\n",
    "\n",
    "'''\n",
    "Input_df=pd.read_csv('Orientation_Script.csv', delimiter='\\t')\n",
    "#Input_df=pd.read_csv('DTT_T120_Prep_for_Orientation_Script_Sept2017.csv', delimiter='\\t')\n",
    "print(Input_df.head(n=5))\n",
    "\n",
    "# Split the input DF into independent DFs based on the term in the SI_Module column (this columns contains the SI and it's connection to each subModule). \n",
    "def Split_based_on_SI_Module_Column():\n",
    "    DF_lst =[]\n",
    "    for SI_Module in Input_df['SI_Module'].unique():\n",
    "        DF=Input_df.loc[Input_df['SI_Module']==SI_Module]\n",
    "        DF_lst.append(DF)\n",
    "    return DF_lst\n",
    "\n",
    "DF_lst=Split_based_on_SI_Module_Column()\n",
    "\n",
    "# This function counts, for each DF, how many of the interactions are reversed. It also counts the length of the dataframe, and then\n",
    "# subtracts the the length of the dataframe from the counts. If the resultant value is 0, then all of the interactions were reversed.\n",
    "def Count_Instances_of_Reverse_Interaction():\n",
    "    DF_Counts_lst=[]\n",
    "    for df in DF_lst:\n",
    "        df=df.copy()\n",
    "        df['Counts']=df.Interaction_Directionality.str.contains('Reversed').sum()  # Count the number of interactions that are \"Reversed\"\n",
    "        x=len(df)\n",
    "        df['Length']=x\n",
    "        df['Counts_Length']=df['Counts']-df['Length']\n",
    "        \n",
    "        DF_Counts_lst.append(df)\n",
    "    return DF_Counts_lst\n",
    "\n",
    "DF_Counts_lst=Count_Instances_of_Reverse_Interaction()\n",
    "print (DF_Counts_lst)\n",
    "\n",
    "# This function assigns 'Input' and 'Output' classifications based on the 'Counts_Length' column in the dataframe. \n",
    "def Only_Reverse_Interactions_Move_to_Outgoing_Columns():\n",
    "    df_Modified_Outgoing_lst=[]\n",
    "    for df in DF_Counts_lst:\n",
    "        #print (df.dtypes)\n",
    "        for value in df['Counts_Length'].unique():\n",
    "            #print (value)\n",
    "            if value == 0:\n",
    "                df['Shared_Interactor_subModule_Relationship']= 'Output'\n",
    "                df_Modified_Outgoing_lst.append(df)\n",
    "            else:\n",
    "                df['Shared_Interactor_subModule_Relationship']= 'Input'\n",
    "                df_Modified_Outgoing_lst.append(df)\n",
    "                \n",
    "    return df_Modified_Outgoing_lst\n",
    "    \n",
    "df_Modified_Outgoing_lst=Only_Reverse_Interactions_Move_to_Outgoing_Columns()\n",
    "\n",
    "# This function concatenates the dataframes back together, leaving a single DF. \n",
    "def ConcatenateDFs():   \n",
    "    EmptyDF = pd.DataFrame() # create an empty dataframe\n",
    "    for df in df_Modified_Outgoing_lst:  # select a dataframe in the list \n",
    "        df=df.copy() # make a copy of that dataframe \n",
    "        EmptyDF=EmptyDF.append(df) # append to the empty DF the dataframe selected and overwrite the empty dataframe\n",
    "    return EmptyDF\n",
    "\n",
    "Final=ConcatenateDFs()\n",
    "\n",
    "print (Final)\n",
    "\n",
    "#Function writes out a Dataframe to a CSV file. \n",
    "def DF_to_CSV(dataframe, NewFileName): \n",
    "    dataframe.to_csv (NewFileName,sep='\\t') \n",
    "    \n",
    "\n",
    "Final_Keep_Columns_Needed_For_SIF=Final[['SI_Module', 'Shared_Interactor', 'subModule_Name', 'Shared_Interactor_subModule_Relationship']] \n",
    "Final_Keep_Columns_Needed_For_SIF=Final_Keep_Columns_Needed_For_SIF.drop_duplicates('SI_Module')\n",
    "\n",
    "\n",
    "DF_to_CSV(Final_Keep_Columns_Needed_For_SIF, 'SIs_subModule_Relationships_Defined_DTT_T120_Network_Input_for_making_SIF_Sept2017.csv')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "''' The function of this script is to produce a SIF file that Debbie can use to Infer a signaling network using an ILP progamming method. The output SIF file can also be opended with Cytoscape to view a signaling network that has NOT been inferred.  \n",
    "\n",
    "\n",
    "\n",
    "***Overview/Important Notes***\n",
    "-The final SIF file indicates directionality between interactions or information flow between entitites. For example, the protein in column \"A\" acts upon the protein/subModule in column \"B\". The submodule in column \"A\" contains the proteins listed in column \"B\"\n",
    "\n",
    "-There are 6 Interaction types in this file, listed below:\n",
    "\n",
    "A) Motif-matched: This is a Kinase-SI that recognizes the phosphorylation motif for a subModule at a predetermined FDR cutoff. This interaction type only exists for \n",
    "kinases that are Input for a subModule (and thus can potentially regulate them). If a kinase is a match to a subModule, but is an output, it is unlikely to regulate that subModule, since\n",
    "it is downstream of the subModule, and would be considered an Output (see below).\n",
    "\n",
    "B) Unknown-recognition-motif: A Kinase or Phoshphatase SI for which we have no information about the phosphorylation motif it recognizes (ie, not in the Mok et al Dataset)\n",
    "This interaction type is input only (Kinase/Phosphatase SI -> subModule)\n",
    "All of our SI-Phosphatase inputs fall into this group, since we do not know their recognized phosphorylation motif.\n",
    " \n",
    "C) Motif-unmatched: A Kinase SI which did NOT meet our FDR cutoff for a subModule. This is also only for Input Kinases.\n",
    "\n",
    "D) Output: subModule -> Kinase/Phosphatase SI. Key here is that all subModule-SI interactions face TOWARDS the SI, and thus the SI is an output and unlikely to regulate the submodule.\n",
    "\n",
    "E) Constituent: A subModule to it's protein constituents (proteins that are part of the subModule). For this group, many of the constituent proteins will NOT be SIs.\n",
    "   \n",
    "E) Shared_Interaction: Non-Kinase/Phosphatase SI connected to it's subModule. Can be either SI -> subModule or subModule -> SI (so an Input/Output based on interaction directionality)\n",
    "\n",
    "\n",
    "Files that will always be used to create the SIF file:\n",
    "# FILES DO NOT CHANGE\n",
    "-Annotation_kinases.csv = this file contains all kinases, including which kinases are in the Mok Dataset.\n",
    "-kinase_phosphatase_yeast.csv = this file contains all kinases and phosphatases in yeast (annotated as kinase/phosphatase catalytic-from Mike Tyers Kinome project)\n",
    "\n",
    "# User defined\n",
    "-List of enriched SIs and their subModules\n",
    "-List of subModules and their protein constituents \n",
    "-KL scoring system for kinases to their subModules (which is actually based on comparing Kinases to their Modules).\n",
    "\n",
    "\n",
    "'''\n",
    "# from previous step\n",
    "All_SI_subModule_relationships_DF= pd.read_csv('SIs_subModule_Relationships_Defined_DTT_T120_Network_Input_for_making_SIF_Sept2017.csv') \n",
    "\n",
    "\n",
    "subModule_Constituent_Proteins_DF= pd.read_csv('DTT_submodule_constituents_Sept2017.csv')\n",
    "\n",
    "# File does not change\n",
    "#DF contains all kinases, including the 3 Pho85-Co-activator varieties, and includes whether a kinase is in the Mok dataset or not.\n",
    "Annotation_Kinases_DF=pd.read_csv('required/Annotation_kinases_Updated_Correct.csv') \n",
    "\n",
    "# File does not change\n",
    "#DF contains all protein annotated as kinase catalytic or phosphatase catalytic from Mike Tyers Kinome project_base\n",
    "Kinases_Phosphatases_yeast_DF=pd.read_csv('required/kinase_phosphatase_yeast.csv')\n",
    "\n",
    "\n",
    "KL_Matching_Kinases_Modules_DF=pd.read_csv('MotifMatch_Scores_for_FASTA.csv')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "def DF_to_CSV(dataframe, NewFileName): \n",
    "    dataframe.to_csv (NewFileName,sep='\\t')  \n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "#Add a column to the SI_File\n",
    "All_SI_subModule_relationships_DF['SI']='Yes'\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "#Generating Interaction type: Output (subModule -> subModule constituent proteins)\n",
    "\n",
    "subModule_Constituent_Proteins_DF=subModule_Constituent_Proteins_DF[['Protein', 'subModule']]  # Only retain the listed columns in the dataframe\n",
    "subModule_Constituent_Proteins_DF['Protein_Constituent_subModule']=subModule_Constituent_Proteins_DF.Protein.map(str) + \"_\" + subModule_Constituent_Proteins_DF.subModule  # create a new column that merges the protein name and subModule name together\n",
    "subModule_Constituent_Proteins_DF_dupes_removed=subModule_Constituent_Proteins_DF.drop_duplicates(subset='Protein_Constituent_subModule') # drop duplicates, so only a single occurrence is listed for each SI-subModule\n",
    "subModule_Constituent_Proteins_DF_dupes_removed_reorganized=subModule_Constituent_Proteins_DF_dupes_removed.rename(columns={'subModule':'Interactor_A', 'Protein':'Interactor_B'}) # Change column names\n",
    "subModule_Constituent_Proteins_DF_dupes_removed_reorganized['Edge_Type']='Constituent'  # Add the Edge type (Interaction type-column). This line has been modified since the original script was created.\n",
    "subModule_Constituent_Proteins_DF_dupes_removed_reorganized=subModule_Constituent_Proteins_DF_dupes_removed_reorganized[['Interactor_A','Edge_Type','Interactor_B','Protein_Constituent_subModule']] # reorganize columns\n",
    "subModule_Constituent_Proteins_merged_left_DF=pd.merge(left=subModule_Constituent_Proteins_DF_dupes_removed_reorganized,right=Kinases_Phosphatases_yeast_DF, how='left', left_on='Interactor_B', right_on='ORF')  # do a merge, so I get information about which proteins are kinases/phosphatases\n",
    "subModule_Constituent_Proteins_merged_left_DF=subModule_Constituent_Proteins_merged_left_DF[['Interactor_A', 'Edge_Type', 'Interactor_B', 'Annotation', 'Protein_Constituent_subModule']]  # drop the columns I don't want \n",
    "subModule_Constituent_Proteins_merged_left_DF_Add_SI_Information=pd.merge(left=subModule_Constituent_Proteins_merged_left_DF, right=All_SI_subModule_relationships_DF, how='left', left_on='Protein_Constituent_subModule', right_on='SI_Module')\n",
    "subModule_Constituent_Proteins_merged_left_DF_Add_SI_Information=subModule_Constituent_Proteins_merged_left_DF_Add_SI_Information[['Interactor_A', 'Edge_Type', 'Interactor_B', 'Annotation', 'SI']]\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# Split the SI_subModule_relationships_DF by Input/Output\n",
    "\n",
    "#Splitting the Dataframe based on if the SI is acting as an Input or Output\n",
    "#If a SI_subModule relationship is an output, then it should be listed that Interactor_A is the subModule and Interactor_B is the SI. \n",
    "\n",
    "SIs_subModules_Output=All_SI_subModule_relationships_DF.loc[All_SI_subModule_relationships_DF['Shared_Interactor_subModule_Relationship']=='Output'] # All interactions that go from subModule -> SI\n",
    "SIs_subModules_Input=All_SI_subModule_relationships_DF.loc[All_SI_subModule_relationships_DF['Shared_Interactor_subModule_Relationship']=='Input']\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Generating Interaction type: Output (subModule -> SIs-Kinase (that have all Interactions facing from subModule to SI)    \n",
    "\n",
    "SIs_subModules_Output_renamed=SIs_subModules_Output.rename(columns={'subModule_Name':'Interactor_A','Shared_Interactor':'Interactor_B'}) #rename columns appropriately. \n",
    "#print (SIs_subModules_Output_renamed.head(5))\n",
    "SIs_subModules_Output_renamed['Edge_Type']='Output'  # Add the edge_type, which is output in this case \n",
    "\n",
    "SIs_subModules_Output_renamed=SIs_subModules_Output_renamed[['Interactor_A', 'Edge_Type', 'Interactor_B', 'SI_Module']] # drop unwanted columns\n",
    "SIs_subModules_Output_renamed_merge_left=pd.merge(left=SIs_subModules_Output_renamed,right=Kinases_Phosphatases_yeast_DF, how='left', left_on='Interactor_B', right_on='ORF')  # do a merge, so I get information about which proteins are kinases/phosphatases\n",
    "SIs_subModules_Output_renamed_merge_left=SIs_subModules_Output_renamed_merge_left[['Interactor_A', 'Edge_Type', 'Interactor_B', 'Annotation', 'SI_Module']] #Drop unwanted columns from the above merge \n",
    "\n",
    "SIs_subModules_Output_renamed_merge_left_left_again=pd.merge(left=SIs_subModules_Output_renamed_merge_left, right=All_SI_subModule_relationships_DF, how='left', left_on='SI_Module', right_on='SI_Module') # merge so we get SI information \n",
    "SIs_subModules_Output_renamed_merge_left_left_again=SIs_subModules_Output_renamed_merge_left_left_again[['Interactor_A', 'Edge_Type', 'Interactor_B', 'Annotation', 'SI']] # drop columns we don't want\n",
    "SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only=SIs_subModules_Output_renamed_merge_left_left_again.loc[SIs_subModules_Output_renamed_merge_left_left_again['Annotation']=='Kinase']\n",
    "SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only=SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only.loc[SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only['Annotation']=='Kinase'] # only keep annotations that are Kinases!\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Generating Interaction type: Output (subModule -> SIs_Phosphatase (that have all interactions facing from submodule to SI)\n",
    "SIs_subModules_Output_renamed_merge_left_left_Twice=pd.merge(left=SIs_subModules_Output_renamed_merge_left, right=All_SI_subModule_relationships_DF, how='left', left_on='SI_Module', right_on='SI_Module')\n",
    "SIs_subModules_Output_renamed_merge_left_left_Twice=SIs_subModules_Output_renamed_merge_left_left_Twice[['Interactor_A', 'Edge_Type', 'Interactor_B', 'Annotation', 'SI']] # drop columns we don't want\n",
    "SIs_subModules_Output_renamed_merge_left_left_Twice_Phosphatase_SIs_Only = SIs_subModules_Output_renamed_merge_left_left_Twice.loc[SIs_subModules_Output_renamed_merge_left_left_Twice['Annotation']=='Phosphatase']\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Generating Interaction type: Shared_Interaction: Non-Kinase/Phosphatase Shared Interactors and their Module associations. can be directed as follows: subModule -> non-kinase/phosphatase SI  or non-kinase/phosphatase SI -> subModule\n",
    "# Note: These are All Shared Interactors, so we can simply add a SI column to this file. \n",
    "\n",
    "# This section of code is making the subModule -> SI direction \n",
    "SIs_subModules_Output_renamed_merge_left=SIs_subModules_Output_renamed_merge_left[['Interactor_A', 'Edge_Type', 'Interactor_B', 'Annotation', 'SI_Module']] \n",
    "SIs_subModules_Output_renamed_merge_left_non_Kin_Phos=SIs_subModules_Output_renamed_merge_left.loc[SIs_subModules_Output_renamed_merge_left['Annotation']!='Kinase']\n",
    "SIs_subModules_Output_renamed_merge_left_non_Kin_Phos=SIs_subModules_Output_renamed_merge_left_non_Kin_Phos.loc[SIs_subModules_Output_renamed_merge_left_non_Kin_Phos['Annotation']!='Phosphatase'] # Return all proteins with annotations that are NOT kinases!\n",
    "SIs_subModules_Output_renamed_merge_left_non_Kin_Phos['SI']='Yes' # Since all of these proteins are SIs, add a column that indicates they are SIs\n",
    "SIs_subModules_Output_renamed_merge_left_non_Kin_Phos=SIs_subModules_Output_renamed_merge_left_non_Kin_Phos[['Interactor_A', 'Edge_Type', 'Interactor_B', 'Annotation', 'SI']]\n",
    "SIs_subModules_Output_renamed_merge_left_non_Kin_Phos['Edge_Type']='Shared_Interaction'\n",
    "#print (SIs_subModules_Output_renamed_merge_left_non_Kin_Phos)\n",
    "\n",
    "#This section of code is making the SI -> subModule direction \n",
    "\n",
    "#print (len(SIs_subModules_Input))\n",
    "SIs_subModules_Input_merge_left_left_again=pd.merge(left=SIs_subModules_Input,right=Kinases_Phosphatases_yeast_DF, how='left', left_on='Shared_Interactor', right_on='ORF') # Merge so we get Kinae/phosphatase information for SIs\n",
    "SIs_subModules_Input_merge_left_left_again_non_Kin_Phos=SIs_subModules_Input_merge_left_left_again.loc[SIs_subModules_Input_merge_left_left_again['Annotation']!='Kinase']  # Drop kinases\n",
    "SIs_subModules_Input_merge_left_left_again_non_Kin_Phos=SIs_subModules_Input_merge_left_left_again_non_Kin_Phos.loc[SIs_subModules_Input_merge_left_left_again_non_Kin_Phos['Annotation']!='Phosphatase'] # drop phosphatases \n",
    "SIs_subModules_Input_merge_left_left_again_non_Kin_Phos['Edge_Type']='Shared_Interaction' # add the edge type \n",
    "\n",
    "SIs_subModules_Input_merge_left_left_again_non_Kin_Phos=SIs_subModules_Input_merge_left_left_again_non_Kin_Phos[['Shared_Interactor', 'Edge_Type', 'subModule_Name', 'Annotation', 'SI']] # drop unwanted columns\n",
    "SIs_subModules_Input_merge_left_left_again_non_Kin_Phos_renamed=SIs_subModules_Input_merge_left_left_again_non_Kin_Phos.rename(columns={'Shared_Interactor':'Interactor_A', 'subModule_Name':'Interactor_B'}) # rename columns so I can merge all dataframes later on.\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Generating Interaction Type: Motif-Matched  (SI-Kinase -> subModule)\n",
    "\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only=SIs_subModules_Input_merge_left_left_again.loc[SIs_subModules_Input_merge_left_left_again['Annotation']== 'Kinase'] # subset the dataframe so we are only working with Kinases.['a'] = df['a'].apply(lambda x: x.split('-')[0])\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only['SI_V2']=SIs_subModules_Input_merge_left_left_again_Kinase_Only['SI_Module'].apply(lambda x: x.split('_')[0])  # Get term before the first \"_\"\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only['Cluster']=SIs_subModules_Input_merge_left_left_again_Kinase_Only['SI_Module'].apply(lambda x: x.split('_')[1]) # Get term after the first \"_\"\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only['motif']=SIs_subModules_Input_merge_left_left_again_Kinase_Only['SI_Module'].apply(lambda x: x.split('_')[2]) # Get term after the second \"_\"\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only['SI_MODULE']=SIs_subModules_Input_merge_left_left_again_Kinase_Only.SI_V2.map(str) + \"_\" + SIs_subModules_Input_merge_left_left_again_Kinase_Only.Cluster + \"_\" + SIs_subModules_Input_merge_left_left_again_Kinase_Only.motif\n",
    "DF_to_CSV(SIs_subModules_Input_merge_left_left_again_Kinase_Only, \"Test1.csv\")\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL=pd.merge(left=SIs_subModules_Input_merge_left_left_again_Kinase_Only, right=KL_Matching_Kinases_Modules_DF, how='left', left_on='SI_MODULE', right_on='Kinase_Module') # Perform a merge so I get information about matching Kinases to subModule motifs (KL script output).\n",
    "#print (SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL)\n",
    "#DF_to_CSV(SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL, 'Test2.csv')\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL=SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL[['Shared_Interactor', 'motif_match', 'subModule_Name', 'Annotation', 'SI', 'FDR']] # drop columns I don't want in the final version\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed=SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL.rename(columns={'Shared_Interactor':'Interactor_A', 'motif_match':'Edge_Type', 'subModule_Name':'Interactor_B'}) # rename columns so I can merge all dataframes in the future.\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed['Edge_Type']=SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed['Edge_Type'].map({'yes':'motif_match', 'no':'motif_unmatched', 'unknown_recognition_motif':'unknown_recognition_motif'})\n",
    "#print (SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed)\n",
    "#DF_to_CSV(SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed, 'New_Script_file_for_merge.csv')\n",
    "#print (KL_Matching_Kinases_Modules_DF.head(5))\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Generating Interaction Type: unknown-recognition motif  (SI-Phosphatase -> subModule)\n",
    "\n",
    "SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif=SIs_subModules_Input_merge_left_left_again.loc[SIs_subModules_Input_merge_left_left_again['Annotation']== 'Phosphatase'] # subset the dataframe so we are only working with Phosphatases.\n",
    "SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif['Edge_Type']='unknown_recognition_motif'  # add the edge type \n",
    "SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif=SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif[['Shared_Interactor', 'Edge_Type','subModule_Name', 'Annotation', 'SI']]\n",
    "SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif_renamed=SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif.rename(columns={'Shared_Interactor':'Interactor_A', 'subModule_Name':'Interactor_B'})\n",
    "#print (SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif_renamed)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "#Adding empty columns to a few of the dataframes so that the final append will work (requires that all files have the same column names,otherwise you'll end up with Column_X, Column_Y)\n",
    "\n",
    "subModule_Constituent_Proteins_merged_left_DF_Add_SI_Information['FDR_Score']=\"\"\n",
    "subModule_Constituent_Proteins_merged_left_DF_Add_SI_Information['Match_FDR']=\"\"\n",
    "#print (subModule_Constituent_Proteins_merged_left_DF_Add_SI_Information.head(5))\n",
    "\n",
    "\n",
    "SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only['FDR_Score']=\"\"\n",
    "#print (SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only.head(10))\n",
    "SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only['Match_FDR']=\"\"\n",
    "#print (SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only.head(2))\n",
    "\n",
    "SIs_subModules_Output_renamed_merge_left_non_Kin_Phos['FDR_Score']=\"\"\n",
    "SIs_subModules_Output_renamed_merge_left_non_Kin_Phos['Match_FDR']=\"\"\n",
    "#print (SIs_subModules_Output_renamed_merge_left_non_Kin_Phos.head(2))\n",
    "\n",
    "SIs_subModules_Input_merge_left_left_again_non_Kin_Phos_renamed['FDR_Score']=\"\"\n",
    "SIs_subModules_Input_merge_left_left_again_non_Kin_Phos_renamed['Match_FDR']=\"\"\n",
    "#print (SIs_subModules_Input_merge_left_left_again_non_Kin_Phos_renamed.head(4))\n",
    "\n",
    "\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed=SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed.rename(columns={'FDR':'FDR_Score'})\n",
    "SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed['Match_FDR']=\"\"\n",
    "#DF_to_CSV(SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed, 'Test101.csv')\n",
    "#print (SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed.head(4))\n",
    "\n",
    "SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif_renamed['FDR_Score']=\"\"\n",
    "SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif_renamed['Match_FDR']=\"\"\n",
    "#print (SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif_renamed.head(4))\n",
    "\n",
    "SIs_subModules_Output_renamed_merge_left_left_Twice_Phosphatase_SIs_Only['FDR_Score']=\"\"\n",
    "SIs_subModules_Output_renamed_merge_left_left_Twice_Phosphatase_SIs_Only['Match_FDR']=\"\"\n",
    "\n",
    "FinalDF=subModule_Constituent_Proteins_merged_left_DF_Add_SI_Information.append(SIs_subModules_Output_renamed_merge_left_left_again_Kinase_SIs_Only)\n",
    "#DF_to_CSV(FinalDF, \"Test.csv\")\n",
    "FinalDF_2=FinalDF.append(SIs_subModules_Output_renamed_merge_left_non_Kin_Phos)\n",
    "FinalDF_3=FinalDF_2.append(SIs_subModules_Input_merge_left_left_again_non_Kin_Phos_renamed)\n",
    "FinalDF_4=FinalDF_3.append(SIs_subModules_Input_merge_left_left_again_Kinase_Only_merge_left_KL_renamed)\n",
    "FinalDF_5=FinalDF_4.append(SIs_subModules_Input_merge_left_left_again_Phosphatase_Only_unknown_recogntion_motif_renamed)\n",
    "FinalDF_6=FinalDF_5.append(SIs_subModules_Output_renamed_merge_left_left_Twice_Phosphatase_SIs_Only)\n",
    "DF_to_CSV(FinalDF_6, 'DTT_T120_SIF_FINAL_Sept2017.csv')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
